{
  
    
        "post0": {
            "title": "Title",
            "content": "밑바닥부터 시작하는 딥러닝 review 2회독 | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/06/30/Untitled1.html",
            "relUrl": "/2022/06/30/Untitled1.html",
            "date": " • Jun 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "20220624",
            "content": "CHAPTER 2 : &#54140;&#49481;&#53944;&#47200; . 퍼셉트론이란? 다수의 신호를 입력으로 받아 하나의 신호를 출력 | 퍼셉트론 신호는 흐른다/안 흐른다의 두 가지 값을 가질 수 있다. | 입력 신호가 뉴런에 보내질 때는 각각 고유한 가중치가 곱해진다. | 뉴런에서 보내온 신호의 총합이 정해진 한계를 넘어설 때만 1을 출력한다. 이를 &#39;뉴런이 활성화한다&#39;라고 표현한다. 이때 그 한계를 임계값이라 하며 대개 $ theta$로 표현한다. | . | 퍼셉트론은 복수의 입력 신호 각각에 고유한 가중치를 부여한다. | 가중치는 각 신호가 결과에 주는 영향력을 조절하는 요소로 적용 즉 가중치가 클수록 해당 신호가 그만큼 더 중요함을 뜻함. | 퍼셉트론의 가중치는 그 값이 클수록 강한 신호를 흘려보낸다. | . | . | . 단순한 논리 회로 AND 게이트 입력이 둘이고 출력은 하나이다.(참고 : 입력 신호와 출력 신호의 대응 표를 진리표라 한다) | 두 입력이 모두 1일 때만 1을 출력하고, 그 외에는 0을 출력한다. | . | NAND 게이트와 OR 게이트 NAND 게이트 : AND 게이트의 출력을 뒤집은 것 | 두 입력이 모두 1일 때만 0을 출력하고 그 외에는 1을 출력한다. | 이때 매개변수의 조합은 AND 게이트를 구현하는 매개변수의 부호를 모두 반전하기만 하면 NAND 게이트가 된다. | OR 게이트 : 입력 신호 중 하나 이상이 1이면 출력이 1이 되는 논리 회로이다. | . | . | . . &#54140;&#49481;&#53944;&#47200;&#51032; &#44396;&#51312;&#45716; AND, NAND, OR &#44172;&#51060;&#53944; &#47784;&#46160;&#50640;&#49436; &#46609;&#44057;&#45796;. . &#49464; &#44032;&#51648; &#44172;&#51060;&#53944;&#50640;&#49436; &#45796;&#47480; &#44163;&#51008; &#47588;&#44060;&#48320;&#49688;(&#44032;&#51473;&#52824;&#50752; &#51076;&#44228;&#44050;)&#51032; &#44050; &#49104;&#51060;&#45796;. . &#51593;, &#46609;&#44057;&#51008; &#44396;&#51312;&#51032; &#54140;&#49481;&#53944;&#47200;&#51060; &#47588;&#44060;&#48320;&#49688;&#51032; &#44050;&#47564; &#51201;&#51208;&#55176; &#51312;&#51221;&#54616;&#50668; AND, NAND, OR&#47196; &#49324;&#50857;&#54624; &#49688; &#51080;&#44172; &#46108;&#45796;. . 퍼셉트론의 매개변수 값을 정하는 것은 컴퓨터가 아니라 인간이다. 인간이 직접 진리표라는 학습 데이터를 보면서 매개변수의 값을 생각한다. 기계학습 문제는 이 매개변수의 값을 정하는 작업을 컴퓨터가 자동으로 하도록 한다. 학습이란 적절한 매개변수 값을 정하는 작업이며, 사람은 퍼셉트론의 구조를 고민하고 컴퓨터에 학습할 데이터를 주는 일을 한다. . . 퍼셉트론 구현해보자 | . def AND(x1, x2): # 매개변수(가중치와 임계값)는 함수 안에서 초기화한다. w1, w2, theta = 0.5, 0.5, 0.7 tmp = x1*w1 + x2*w2 # 이때, 부등식에 등호가 어디에 들어가 있는지 중요!!! if tmp &lt;= theta: return 0 elif tmp&gt; theta: return 1 . print(AND(0,0)) print(AND(1,0)) print(AND(0,1)) print(AND(1,1)) . 0 0 0 1 . 위 AND 게이트를 좀 더 효율적인 방식으로 수정해보자 | 함수 AND에서 tmp &lt;= theta에서 theta를 좌항으로 옮겨서 정리한다. | 즉, b + x1w1 + x2w2 &lt;= 0 이 되고 | 이때, b를 편향이라고 바꿔부른다. 원래 b는 임계값! (=theta) | . | . 즉, 퍼셉트론은 입력 신호에 가중치를 곱한 값과 편향을 합하여 그 값이 0을 초과하면 1을 출력하고, 그렇지 않으면 0을 출력한다. . 넘파이를 이용하여 가중치와 편향 개념 구현해보자 | . import numpy as np x = np.array([0,1]) # 두 입력 값 w = np.array([0.5,0.5]) # 가중치 b = -0.7 # 편향 # 원래 우항에 있던 임계값을 좌항으로 옮겼기 때문에 마이너스! 그런데 이건 게이트마다 임계값이 다르기 때문에 좌항으로 옮겼을 때 # 음수일 수도 있고 양수일 수도 있음 np.sum(w*x) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy _distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs: C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll warnings.warn(&#34;loaded more than 1 DLL from .libs:&#34; . 0.5 . np.sum(w*x) + b . -0.19999999999999996 . 가중치와 편향을 도입한 AND 게이트를 구현해보자 | . def AND(x1,x2): x = np.array([x1,x2]) w = np.array([0.5,0.5]) b = -0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else : return 1 . 가중치는 각 입력 신호가 결과에 주는 영향력(중요도)을 조절하는 매개변수고, 편향은 뉴런이 얼마나 쉽게 활성화(결과로 1을 출력) 하느냐를 조정하는 매개변수이다. (책에 따라 셋 모두(가중치와 편향)를 가중치라고 할 때도 있다) . NAND 게이트와 OR 게이트 구현 | . def NAND(x1,x2): x = np.array([x1,x2]) w = np.array([-0.5,-0.5]) b = 0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else : return 1 def OR(x1,x2): x = np.array([x1,x2]) w = np.array([0.5,0.5]) b = -0.2 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else : return 1 . AND, NAND, OR 게이트 모두 같은 구조의 퍼셉트론이며, 차이는 가중치 매개변수의 값 뿐이다. | . . 퍼셉트론의 한계 무슨 한계? 직선 하나로 나눈 영역만 표현할 수 있다는 한계 | . | . | XOR 게이트 (배타적 논리합) 한쪽이 1일 때만 1을 출력 | 지금까지 본 퍼셉트론으로는 XOR 게이트를 구현할 수 없다. 왜? XOR 게이트는 한 쪽이 1일 때만 1을 출력한다고 했다. | 이 입력값들을 좌표평면에 나타내면 입력 값들을 하나의 직선으로 분리하는 것은 불가능하다. | 따라서 기존의 AND, NAND, OR 게이트의 퍼셉트론으로는 XOR 게이트를 구현할 수 없다. | 책 55p ~ 56p 참고 | . | . | . | . 이때, 직선이라는 제약을 없앤다면 주어진 입력값들을 두 구간으로 분류할 수 있을 것이다. | 퍼셉트론은 직선 하나로 나눈 영역만 표현할 수 있다는 한계가 있다. 그렇다면 방법은? | 층을 쌓아, 다층 퍼셉트론을 만든다. | 층을 하나 더 쌓아 XOR를 표현해보자 | . | . . 0627~ . 기존 게이트 조합하기 AND, NAND, OR 게이트를 조합하기 퍼셉트론의 한계 : 단층 퍼셉트론으로는 XOR 게이트를 표현할 수 없음 | 즉, 단층 퍼셉트론으로는 비선형 영역을 분리할 수 없음 | 따라서 퍼셉트론을 조합하여, 즉 층을 쌓아서 XOR 게이트를 구현하면 됨 | . | 이때 XOR 게이트는 입력 중 하나만 1일 때, 출력 1이 가능 | . | . def XOR(x1,x2) : s1 = NAND(x1,x2) s2 = OR(x1,x2) y = AND(s1,s2) return y . print(XOR(0,0)) print(XOR(0,1)) # 이때 1을 출력해야 함 print(XOR(1,0)) # # 이때 1을 출력해야 함 print(XOR(1,1)) . 0 1 1 0 . 단층 퍼셉트론으로는 표현하지 못한 것을 층을 하나 늘려 구현할 수 있게 됨 | . 정리 . 1. 퍼셉트론에서는 가중치와 편향을 매개변수로 설정 2. XOR 게이트는 단층 퍼셉트론으로는 표현할 수 없다 3. 2층 퍼셉트론을 이용하면 XOR 게이트를 표현할 수 있다 4. 단층 퍼셉트론은 직선형 영역만 표현할 수 있고, 다층 퍼셉트론은 비선형 영역도 표현할 수 있다 5. 다층 퍼셉트론은 (이론상) 컴퓨터를 표현할 수 있다 . . . . &#49888;&#44221;&#47581; . - &#54140;&#49481;&#53944;&#47200;&#50640;&#49436; &#49888;&#44221;&#47581;&#51004;&#47196; . 신경망은 퍼셉트론과 유사한 점이 많으나, 퍼셉트론과 다른 점을 중심으로 신경망의 구조를 설명해보자 | 신경망은 입력층, 은닉층, 출력층으로 구성되어 있음 이때 은닉층의 뉴런은 입력층이나 출력층과 달리 사람 눈에 보이지 않음 (아마 이게 블랙박스라고 일컬었던 것 같음) | . | rewiew 편향 : 뉴런이 얼마나 쉽게 활성화되느냐를 제어 | 가중치 : 각 신호의 영향력을 제어 | . | . | . 활성화 함수의 등장 입력 신호의 총합을 출력 신호로 변환하는 함수를 일반적으로 활성화 함수라 한다. | 입력 신호의 총합이 활성화를 일으키는지를 정하는 역할을 한다. | . | . 종전에 설명한 활성화 함수는 임계값을 경계로 출력이 바뀌는데, 이런 함수를 계단 함수라 한다. 그래서 &#39;퍼셉트론에서는 활성화 함수로 계단 함수를 이용한다&#39;고 할 수 있다. | 즉, 활성화 함수로 쓸 수 있는 여러 후보 중에서 퍼셉트론은 계단 함수를 채용한 것 그 외, 시그모이드 함수도 활성화 함수로 사용할 수 있음 | . | . | . 활성화 함수 中 시그모이드 함수 | . $$h(x) = { frac{1}{1+exp(-x)}}$$ . 활성화 함수로 이용되는 시그모이드 함수를 계단 함수와 비교하면서 자세히 살펴보자 | . def step_function(x): if x&gt;0: return 1 else : return 0 . 해당 함수는 실수만 받아들임 즉, 넘파이 배열을 인수로 넣을 순 없음 이를테면, np.array([1.3,23.3]) | 가능하게 해보자 | . | . | . def step_function(x): y = x&gt;0 return y.astype(np.int) # 원하는 자료형(e.g. np.int)을 인수로 지정해주면 된다 . step_function(np.array([23.123,-213,123,333.2,0])) . C: Users ehfus AppData Local Temp/ipykernel_8356/4075629736.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations return y.astype(np.int) # 원하는 자료형(e.g. np.int)을 인수로 지정해주면 된다 . array([1, 0, 1, 1, 0]) . . . . 0628 . 계단 함수의 그래프 | . import matplotlib.pylab as plt def step_function(x): return np.array(x&gt;0, dtype = np.int) # 배열 생성하면서 동시에 자료형까지 지정 x = np.arange(-5,5,0.1) # -5부터 5까지 0.1의 간격으로 수열 생성 y = step_function(x) plt.plot(x,y) plt.ylim(-0.1,1.1) plt.show() . C: Users ehfus AppData Local Temp/ipykernel_8356/247113324.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations return np.array(x&gt;0, dtype = np.int) # 배열 생성하면서 동시에 자료형까지 지정 . 시그모이드 함수 구현하기 | . def sigmoid(x): return 1 / ( 1 + np.exp(-x)) . x = np.array([-1,1,2]) sigmoid(x) . array([0.26894142, 0.73105858, 0.88079708]) . x = np.arange(-5,5,0.1) y = sigmoid(x) plt.plot(x,y) plt.ylim(-0.1,1.1) plt.show() . S자모양 . 시그모이드 함수와 계단 함수 비교 | . 시그모이드는 부드러운 곡선이며 입력에 딸 출력이 연속적으로 변화한다. . 한편 계단 함수는 0을 경계로 출력이 갑자기 바뀌어 버린다. . 이때 시그모이드 함수의 이 매끈함이 신경망 학습에서 아주 중요한 역할을 하게 된다. . 계단 함수가 0과 1 중 하나의 값만 돌려주는 반면 시그모이드 함수는 실수를 돌려준다. . 다시말해, 퍼셉트론에서는 뉴런 사이에 0혹은 1이 흘렀다면 신경망에서는 연속적인 실수가 흐른다.(신경망과 퍼셉트론은 유사하나 상이한 부분도 분명 있음. 다른 개념이다.) . 비유하자면, 시그모이드 함수는 물레방아처럼 흘러온 물의 양에 비례해 흐르는 물의 양을 조절한다. . 시그모이드 함수와 계단 함수의 공통점? 큰 관점에서 보면 둘은 같은 모양을 하고 있다. | 둘 다 입력이 작을 때의 출력은 0에 가깝거나 0이고, 입력이 커지면 출력이 1에 가까워지는 혹은 1이 되는 구조이다. | 즉, 계단 함수와 시그모이드 함수는 입력이 중요하면 큰 값을 출력하고 입력이 중요하지 않으면 작은 값을 출력한다. 중요도? | . | 그리고 입력이 아무리 작거나 커도 출력은 0에서 1 사이라는 것도 둘의 공통점이다. | 또한 두 함수 모두 ### 비선형 함수이다. | . | . 비선형 함수? 직선 1개로는 그릴 수 없는 함수 | 신경망에서는 활성화 함수로 비선형 함수를 사용해야 한다 즉, 선형 함수는 사용해선 안 된다. | 왜? 선형 함수를 사용하면 신경망의 층을 깊게 하는 의미가 없어지기 때문이다. | 선형 함수의 문제? 층을 아무리 깊게 해도 은닉층이 없는 네트워크(즉, 입력층과 출력층만 있는??)로도 똑같은 기능을 할 수 있다는 데 있다. | 이 부분 먼저 설명해보자 | 선형 함수인 h(x) = cx를 활성화 함수로 사용한 3층 네트워크를 떠올려보라 | 이를 식으로 나타내면 y(x) = h(h(h(x)))가 되면 계산은 ccc*x지만, 결국은 특정 상수 곱하기 엑스가 되는 것 | 즉, y(x) = h(h(h(x))) = ax로도 표현가능하다는 것. 은닉층이 없는 네트워크로도 표현이 가능해진 것이다. | . | . | . | . | . 즉! 선형 함수를 이용해서는 여러 층으로 구성하는 이점을 살릴 수 없다. . 왜? 선형 함수로 여러 층을 구성해봤자 그냥 은닉층 없는 네트워크로도 동일 기능을 수행할 수 있기 때문에 . &#46384;&#46972;&#49436; &#52789;&#51012; &#49939;&#45716; &#54812;&#53469;&#51012; &#50619;&#44592; &#50948;&#54644;&#49440; &#54876;&#49457;&#54868; &#54632;&#49688;&#47484; &#48708;&#49440;&#54805; &#54632;&#49688;&#47196; &#52292;&#53469;&#54644;&#50556; &#54620;&#45796;. . . ReLU 함수 입력이 0을 넘으면 그 입력을 그대로 출력, 그렇지 않으면 무조건 0을 출력 | . | . def relu(x): return np.maximum(0,x) . 넘파이 행렬을 써서 신경망을 구현해보자 | 해당 예에서는 편향과 활성화 함수를 생략하고 가중치만 갖는 신경망을 구현한 것이다. | . X = np.array([1,2]) # 입력값 W = np.array([[1,3,5],[2,4,6]]) # 가중치. # 해당 예에서는 편향과 활성화 함수를 생략하고 가중치만 갖는 신경망을 구현한다고 했음 # 이때, 가중치는 2x3 크기의 matrix이다 Y = np.dot(X,W) print(Y) . [ 5 11 17] . 주의 :Y = np.dot(X,W)에서 입력값과 각각 대응되는 가중치들이 적절히 곱해지도록 행렬곱이 이루어짐 이를테면 X가 1x2 크기의 행렬이고 W가 2x3 크기의 행렬인데 W에 원소들을 각각 어떻게 배치하느냐에 따라 입력값에 곱해져야 하는 가중치들이 적절히 곱해질 수도 안 곱해질 수도 있음 . 따라서 행렬곱을 수행해줄 때 입력값 각각에 할당된 가중치들이 입력값과 적절히 곱해질 수 있도록 가중치 행렬을 구성해주어야 함 . 위 예에서 볼 수 있듯 행렬의 곱으로 한꺼번에 계산해주는 기능은 신경망을 구현할 때 매우 중요함을 알 수 있다. . . 3층 신경망에서 수행되는 입력부터 출력까지의 처리(순방향 처리)를 구현해보자 | 넘파이 배열을 잘 구사하면 아주 적은 코드만으로 신경망의 순방향 처리를 완성할 수 있다. | . 85p 그림 3-17을 확인해보면, 편향을 0층 뉴런에 따로 할당하여 처리해줄 수 있다. | 해당 예에서는 편향을 1로 설정하여 두 입력값과 가중치가 곱해진 결과의 합과 편향을 더하여 다음 뉴런에 전달해주었음 | . X = np.array([1,0.5]) W1 = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]]) B1 = np.array([0.1,0.2,0.3]) print(X.shape) # 1x2 print(W1.shape) # 2x3 print(B1.shape) # 1x3 A1 = np.dot(X,W1) + B1 print(A1) # 1x3 print(A1.shape) . (2,) (2, 3) (3,) [0.3 0.7 1.1] (3,) . 0층이 아닌 1층에서의 활성화 함수를 시그모이드로 설정해보고 코드를 구현해보자 | . Z1 = sigmoid(A1) print(A1) print(Z1) . [0.3 0.7 1.1] [0.57444252 0.66818777 0.75026011] . 1층에서 2층으로 가는 과정을 구현해보자 | . W2 = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]]) B2 = np.array([0.1,0.2]) print(Z1.shape) print(W2.shape) print(B2.shape) A2 = np.dot(Z1,W2) + B2 Z2 = sigmoid(A2) . (3,) (3, 2) (2,) . 해당 과정은 1층의 출력 Z1이 2층의 입력이 된다는 점을 제외하면 0층에서 1층으로의 구현과 대동소이하다. | 이처럼 넘파이 배열을 사용하면 층 사이의 신호 전달을 쉽게 구현할 수 있다. | . 이제 2층에서 3층으로 즉, 2층에서 출력층으로의 신호 전달을 살펴보자 | 출력층의 구현도 그 동안의 구현과 일맥상통하나 활성화 함수만 지금까지의 은닉층과 다르다 | . def identity_function(x): return x # 여기서는 활성화함수로서 항등함수를 설정한 것 W3 = np.array([[0.1,0.3],[0.2,0.4]]) B3 = np.array([0.1,0.2]) A3 = np.dot(Z2,W3) + B3 Y = identity_function(A3) # 혹은 Y = A3 , 활성화 함수로 항등함수를 설정했기 때문에 . 출력층의 활성화 함수는 풀고자 하는 문제의 성질에 맞게 설정한다 . 이를테면, 회귀에는 항등함수를 설정하며 이진 분류에는 시그모이드 함수를 설정하고 다중분류에는 소프트맥스 함수를 사용하는 것이 일반적이다 . 해당 예에서는 회귀에서 항등함수를 설정하는 경우를 상정하고 출력층의 활성화함수를 설정해준 것이다. . &#44396;&#54788; &#51221;&#47532; . def init_network(): network = {} # 빈 dict 설정 network[&#39;W1&#39;] = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]]) network[&#39;b1&#39;] = np.array([0.1,0.2,0.3]) network[&#39;W2&#39;] = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]]) network[&#39;b2&#39;] = np.array([0.1,0.2]) network[&#39;W3&#39;] = np.array([[0.1,0.3],[0.2,0.4]]) network[&#39;b3&#39;] = np.array([0.1,0.2]) return network # 해당 함수를 실행시키면 3층짜리 신경망에서 필요한 가중치와 편향을 불러올 수 있음 # forward 함수를 실행시키기 위해서는 당연히 network가 설정되어 있어야 하고 network가 설정되기 위해서는 init_network함수가 불러와져야 함 def forward(network,x) : W1,W2,W3 = network[&#39;W1&#39;], network[&#39;W2&#39;], network[&#39;W3&#39;] b1,b2,b3 = network[&#39;b1&#39;], network[&#39;b2&#39;], network[&#39;b3&#39;] a1 = np.dot(x,W1) + b1 z1 = sigmoid(a1) # 입력층(0층)에서 1층으로 가며 얻은 출력값 a2 = np.dot(z1, W2) + b2 z2 = sigmoid(a2) a3 = np.dot(z2,W3) + b3 y = identity_function(a3) return y network = init_network() x = np.array([1,0.5]) # 0층에서의 입력값 y = forward(network,x) print(y) . [0.31682708 0.69627909] . 이때 함수 이름을 forward라고 명해준 이유는 신호가 순방향(입력에서 출력 방향)으로 전달됨(순전파)을 알리기 위함 . 순전파가 있다는 것은 역전파도 있다는 의미 . &#52636;&#47141;&#52789; &#49444;&#44228;&#54616;&#44592; . 신경망을 분류와 회귀 모두에 이용할 수 있다. | 다만 둘 중 어떤 문제냐에 따라 출력층에서 사용하는 활성화 함수가 달라진다. | 일반적으로 회귀에는 항등 함수를, 분류에는 소프트 맥스 함수를 사용한다. | . &#54637;&#46321; &#54632;&#49688;&#50752; &#49548;&#54532;&#53944; &#47589;&#49828; &#54632;&#49688; &#44396;&#54788;&#54616;&#44592; . 분류에서 사용하는 소프트 맥스의 식을 알아보자 . $$y_k = frac{exp(a_k)}{ Sigma exp(a_i)}$$ . 92p의 그림에서 볼 수 있듯, 소프트맥스의 출력은 모든 입력 신호로부터 화살표를 받는다. 소프트맥스 식의 분모에서 볼 수 있듯 출력층의 각 뉴런이 모든 입력 신호에서 영향을 받기 때문이다. | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/06/30/.html",
            "relUrl": "/2022/06/30/.html",
            "date": " • Jun 30, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "딥러닝의 미래",
            "content": "이미지 스타일(화풍) 변환 딥러닝을 활용해 화가처럼 그림을 그리는 것 | 콘텐츠 이미지와 스타일 이미를 조합해 새로운 그림을 그려준다. | 이 기술은 네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷해지도록 학습한다. 이렇게 하면 입력 이미지를 콘텐츠 이미지의 형태를 흉내낼 수 있다. | 또, 스타일 이미지의 화풍을 흡수하기 위해 스타일 행렬이라는 개념을 도입한다. 그 스타일 행렬의 오차를 줄이도록 학습하여 입력 이미지를 고흐의 화풍과 비슷해지게 만들 수 있는 것이다. | . | . 이미지 생성 이미지 스타일 변환은 새로운 그림을 생성하려면 이미지 두 장을 입력해야 했다. | 하지만 이 방법은 입력 이미지 없이도 새로운 이미지를 그려내는 연구이다. DCGAN 기법이 있다. | 해당 기법의 핵심은 생성자와 식별자로 불리는 2개의 신경망을 이용한다는 점이다. | 생성자가 진짜와 똑같은 이미지를 생성하고 식별자는 그것이 진짜인지(생성자가 생성한 이미지인지, 아니면 실제로 촬영된이미지인지)를 판정한다. 이런 방식으로 둘을 겨루도록 학습시켜, 생성자는 더 정교한 가짜 이미지 생성 기술을 학습하고 식별자는 더 정확하게 간파할 수 있는 감정사로 성장하는 것이다. 이렇게 둘의 능력을 수련시킨다는 개념이 GAN이다. | . | . | . 자율 주행 자율 주행은 주행 경로를 정하는 경로 계획 기술과 카메라나 레이저 등의 탐사 기술 그리고 주위 환경을 올바르게 인식하는 기술이 필요하다 그 중 주위 환경을 올바르게 인식하는 기술이 가장 중요하다. | 예를 들어 SegNet이라는 CNN기반 신경망은 주변 환경을 정확하게 인식해낸다. 입력 이미지를 분할(픽셀 수준에서 판정)하고 있다. | . | . | . Deep Q-Network(강화학습) 사람이 자전거를 배울 때 시행착오를 겪으며 배우듯, 컴퓨터도 시행착오 과정에서 스스로 학습하게 하려는 분야이다. | 가르침에 의존하는 지도 학습과는 다른 분야이다. | 에이전트라는 것이 환경에 맞게 행동을 선택하고, 그 행동에 의해서 환경이 변한다는 게 기본적인 틀이다. 환경이 변화하면 에이전트는 어떠한 보상을 얻는다. 강화학습의 목적은 더 나은 보상을 받는 쪽으로 에이전트의 행동 지침을 바로잡는 것이다. | 이때 보상은 정해진 것이 아니라 예상 보상이다. 예를 들어, 게임 캐릭터 마리오를 오른쪽으로 이동시켰을 때 얻는 보상이 항상 명확하진 않다. 상황에 따라 그것이 100원이 될 수도 혹은 장애물이 될 수도 혹은 1000원이 될 수도 있듯 어떤 상황에서 이동한 것이냐에 따라 보상은 천차만별이 될 수 있다. 이런 불명확한 상황에서는 게임 점수(동전을 먹거나 적을 쓰러뜨리는 등)나 게임 종료 등의 명확한 지표로부터 역산해서 예상 보상을 정해야 한다. | DQN Q라는 강화학습 알고리즘을 기초로 한다. Q학습에서는 최적 행동 가치 함수로 최적인 행동을 정한다. 이 함수를 딥러닝으로 비슷하게 흉내 내어 사용하는 것이 DQN이다. | . | . | . . 간단히 1회독이 종료됐다. | 2회독부터는 진도 속도를 늦추되 좀 더 정밀히 공부해보자 | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/23/dl.html",
            "relUrl": "/2022/02/23/dl.html",
            "date": " • Feb 23, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "딥러닝 좀 더 알아보기",
            "content": "정확도를 더 높일 수 있는 기술에는 무엇이 있을까 앙상블 학습, 학습률 감소, 데이터 확장 등이 정확도 향상에 공헌할 수 있다. 특히 데이터 확장은 손쉬운 방법이면서도 정확도 개선에 아주 효과적이다. | 데이터 확장 : 입력 이미지(훈련 이미지)를 알고리즘을 동원해 인위적으로 확장한다. 입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 이미지의 개수를 늘리는 것이다. 이는 데이터가 몇 개 없을 때 특히 효과적인 수단이다. 또는 이미지 일부를 잘라내는 crop이나 좌우를 뒤집는 flip(대칭성을 고려하지 않아도 되는 경우에 사용할 수 있다)등이 있을 수 있다. 일반적인 이미지에는 밝기 등의 외형 변화나 확대, 축소 등의 스케일 변화도 효과적이다. | 즉, 데이터 확장을 동원해 훈련 이미지의 개수를 늘릴 수 있다면 딥러닝의 인식 수준을 개선할 수 있다. | . | . 층을 왜 깊게 할까 층을 깊게 할 때의 이점 1) 신경망의 매개변수 수가 줄어든다는 것이다. | 2) 층을 깊게 함으로써 학습 데이터의 양을 줄여 학습을 고속으로 수행한다. 즉, 학습의 효율성을 고려하게 된다는 것이다. | 3) 학습해여 할 문제를 계층적으로 분해할 수 있다. 각 층이 학습해야 할 문제를 더 단순한 문제로 대체할 수 있다는 것이다. 예를 들어, 처음 층은 에지 학습에 전념하여 적은 학습데이터로 효율적으로 학습할 수 있다. 개가 등장하는 이미지보다 에지를 포함한 이미지는 많고, 에지의 패턴은 개라는 패턴보다 구조가 훨씬 간단하기 때문이다. | 4) 정보를 계층적으로 전달할 수 있다. 예를 들어 에지를 추출한 층의 다음 층은 에지 정보를 쓸 수 있고, 더 고도의 패턴을 효과적으로 학습하리라 기대할 수 있다. 즉, 층을 깊게 함으로써 각 층이 학습해야 할 문제를 풀기 쉬운 단순한 문제로 분해할 수 있어 효율적으로 학습하리라 기대할 수 있다. | . | . | . 세 가지 유명 신경망에 대해 알아보자 | . VGG 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN이다. | 비중 있는 층(합성곱 계층, 완전연결 계층)을 모두 16층 혹은 19층으로 심화한 게 특징이다. 층의 깊이에 따라 VGG16 또는 VGG19로 구분하기도 한다. | 3x3의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다. 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복한다. 그리고 마지막에는 완전 연결 계층을 통과시켜 결과를 출력한다. | . | . GoogLeNet 세로 방향 깊이뿐 아니라 가로 방향도 깊다는 점이 특징이다. | GoogLeNet에는 가로 방향에 폭이 있다. 이를 인셉션 구조라 한다. 인셉션 구조 : 크기가 다른 필터(와 풀링)를 여러 개 적용하여 그 결과를 결합한다. 이 인셉션 구조를 하나의 빌딩 블록으로 사용하는 것이 GoogLeNet이다. | . | . | . ResNet 지금까지보다 층을 더 깊게 할 수 있는 특별한 장치(스킵 연결)가 있다. | 층을 깊게 하는 것이 성능 향상에 중요하다. 그러나 딥러닝의 학습에서는 층이 지나치게 깊으면 학습이 잘 되지 않고, 오히려 성능이 떨어지는 경우도 많다. 이런 문제를 해결하기 위해서 ResNet에서는 스킵 연결을 도입한다. 이 구조가 층의 깊이에 비례해 성능을 향상시킬 수 있게 한 핵심이다. | 스킵 연결 : 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조를 말한다. 예를 들면, 입력 x를 연속한 두 합성곱 계층을 건너뛰어 출력에 바로 연결한다. 따라서 층이 깊어져도 학습을 효율적으로 할 수 있도록 해주는데 이는 역전파 때 스킵 연결이 신호 감쇠를 막아주기 때문이다. | 스킵 연결 : 입력 데이터를 그래도 흘리는 것으로 역전파 때도 상류의 기울기를 그대로 하류로 보낸다. 여기에서의 핵심은 상류의 기울기에 아무런 수정도 가하지 않고 그대로 흘린다는 것이다. 그래서 스킵 연결로 기울기가 작아지거나 지나치게 커질 걱정 없이 앞 층에 의미 있는 기울기가 전해지리라 기대할 수 있다. 층을 깊게 할수록 기울기가 작아지는 소실 문제를 이 스킵 연결이 줄여주는 것이다. | . | . . 딥러닝 고속화 딥러닝에서는 대부분 오랜 시간을 합성곱 계층에서 소요한다. 따라서 합성곱 계층에서 이뤄지는 연산을 어떻게 고속으로 효율적으로 하느냐가 딥러닝의 과제가 될 것이다. | . | . GPU를 활용한 고속화 GPU는 병렬 수치 연산을 고속으로 처리할 수 있다. 이 능력을 다양한 용도 활용하자는 것이 GPU 컴퓨팅의 목적이다. 이처럼 GPU로 범용 수치 연산을 수행하는 것을 GPU 컴퓨팅이라고 한다. | . | . 분산 학습 GPU로 딥러닝 연산을 꽤 가속할 수 있지만, 그래도 심층 신경망에서는 학습에 며칠 혹은 몇주가 걸리기도 한다. | 뛰어난 신경망을 만들려면 시험을 수없이 반복해야 하고, 그러려면 1회 학습에 걸리는 시간을 최대한 단축해야 한다. | 그래서 딥러닝 학습을 수평 확장 하자는 아이디어(즉, 분산 학습)가 중요해지는 것이다. | 딥러닝 계산을 더욱 고속화하고자 다수의 GPU와 기기로 계산을 분산하기도 한다. | . | . 연산 정밀도와 비트 줄이기 메모리 용량과 버스 대역폭 등이 딥러닝 고속화에 병목이 될 수 있다. | 메모리 용량 면에서는 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장해야 한다는 것을 생각해야 한다. | 버스 대역폭 면에서는 GPU 혹은 CPU의 버스를 흐르는 데이터가 많아져 한계를 넘어서면 병목이 된다. 이러한 경우를 고려하면 네트워크로 주고받는 데이터의 비트수는 최소로 만드는 것이 바람직하다. 다행히 딥러닝은 높은 수치 정밀도 즉, 수치를 몇 비트로 표현하느냐를 요구하지 않는다. 이는 신경망의 중요한 성질 중 하나로, 신경망의 견고성에 따른 특성이다. 예를 들어 신경망은 입력 이미지에 노이즈가 조금 섞여 있어도 출력 결과가 잘 달라지지 않는 강건함을 보여준다. 이런 견고성 덕분에 신경망을 흐르는 데이터를 퇴화시켜도 출력에 주는 영향은 적다. 즉, 병목 현상을 피하기 위해 비트 수를 줄여도 타격이 크지 않으니 줄여도 무방하다는 것이다. | . | . | . . 딥러닝의 활용 딥러닝은 사물 인식뿐만 아니라 이미지, 음성, 자연어 등 수많은 분야에서 활용할 수 있다. | . | . 사물 검출 이미지 속에 담긴 사물의 위치와 종류(클래스)를 알아내는 기술이다. | 사물 인식과는 다른 문제로서 좀 더 고차원적인 문제이다. | 사물 인식은 이미지 전체를 대상으로 하지만 사물 검출에서는 이미지 어딘가에 있을 사물의 위치까지 알아내야 한다. 게다가 한 이미지에 여러 사물이 존재할 수도 있다. | CNN을 이용하여 사물 검출을 수행하는 몇 가지 방식이 있는데 그중 R-CNN에 대해 알아보자 입력 이미지 | | 후보 영역 추출 | | CNN 특징 계산 | | 영역 분류 | | 여기서 2번과 3번에 주목해보자 | 먼저, 사물이 위치한 영역을 찾아낸다. 즉, 후보들을 추려낸다. 그리고 추출한 각 영역에 CNN을 적용하여 클래스를 분류한다. 여기서 이미지를 사각형으로 변형하거나 분류할 때 서포트 벡터 머신(SVM)을 사용할 수 있겠다. | 이때, 후보 영역 추출에는 컴퓨터 비전 분야에서 발전해온 다양한 기법을 사용할 수 있고, R-CNN 논문에서는 Selective-Search 기법을 사용한다. | 최근에는 이 후보 영역 추출까지 CNN으로 처리하는 Faster R-CNN 기법도 등장했다. Faster R-CNN은 모든 일을 하나의 CNN에서 처리하기 때문에 매우 빠르다. | . | . | . 분할 이미지를 픽셀 수준에서 분류하는 문제이다. | 픽셀 단위로 객체마다 채색된 지도 데이터를 사용해 학습한다. 그리고 추론할 때 입력이미지의 모든 픽셀을 분류한다. | 신경망을 이용해 분할하는 가장 단순한 방법은 모든 픽셀 각각을 추론하는 것이지만 시간이 상당히 걸릴 것이다. 이러한 낭비를 줄여주는 기법으로 FCN(Fully Convolutional Network)이 고안되었다. 이는 단 한번의 forward 처리로 모든 픽셀의 클래스를 분류해준다. 이 기법은 일반적인 CNN이 완전연결 계층을 이용하는 반면, FCN은 이 완전연결 계층을 같은 기능을 하는 합성곱 계층으로 구현한다. 즉, 합성곱 계층으로만 구성된 네트워크인 것이다. | . | . 사진 캡션(삽입된 그림이나 도표, 사진 등의 이해를 돕기 위해 쓰는 간단한 주석문) 생성 즉, 특정 사진을 주면 그 사진을 설명하는 글(사진 캡션)을 자동으로 생성하는 연구이다. | 딥러닝으로 사진 캡션을 생성하는 방법으로는 NIC(Neural Image Caption)모델이 대표적이다. 심층 CNN과 자연어를 다루는 순환 신경망(Recurrent Neural Network, RNN)으로 구성된다. RNN은 순환적 관계를 갖는 신겨망으로 자연어나 시계열 데이터 등의 연속된 데이터를 다룰 때 많이 사용한다. | 사진이나 자연어와 같은 여러 종류의 정보를 조합하고 처리하는 것을 멀티모달 처리라고 한다. | . | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/22/dl.html",
            "relUrl": "/2022/02/22/dl.html",
            "date": " • Feb 22, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "CNN 시각화하기",
            "content": "간단히 정리만 해보자 | . CNN을 구성하는 합성곱 계층은 입력으로 받은 이미지 데이터에서 무엇을 보는 걸까. | 합성곱 계층을 시각화하여 CNN이 보고 있는 것이 무엇인지 알아보자 | . MNIST 데이터셋으로 간단한 CNN 학습을 했을 때, 1번째 층의 합성곱 계층의 가중치는 그 형상이 (30,1,5,5)였다. 즉 필터 30개, 채널 1개, 5x5 크기인 것이다. 즉 채널이 1개라는 것은 이 필터를 1채널의 회색조 이미지로 시각화할 수 있다는 뜻이다. | . 255p를 참고해보면, 학습 전 필터는 무작위로 초기화되고 있어 흑백의 정도에 규칙성이 없다. 한편 학습을 마친 필터는 규칙성 있는 이미지가 되었다. 흰색에서 검은색으로 점차 변화하는 필터와 덩어리-블롭(blob)가 진 필터 등, 규칙을 띄는 필터로 바뀌었다. | 그렇다면 오른쪽 그림같이 규칙성 있는 필터는 무엇을 보고 있는 것일까. 그것은 에지(색상이 바꾸니 경계선)와 블롭(국소적으로 덩어리진 영역) 등을 보고 있다. 가령, 왼쪽 절반이 흰색이고 오른쪽 절반이 검은색인 필터는 세로 방향의 에지에 반응하는 필터이다. | . | 합성곱 계층의 필터는 에지나 블롭 등의 원시적인 정보를 추출할 수 있따. 이런 원시적인 정보가 뒷단 계층에 전달된다는 것이 앞에서 구현한 CNN에서 일어나는 일이다. | . . 층 깊이에 따른 추출 정보 변화 지금까진 1번째 층의 합성곱 계층을 대상으로 한 것이다. 1번째 층의 합성곱 계층에서는 에지나 블롭 등의 저수준 정보가 추출된다면 겹겹이 쌓인 CNN의 각 계층에서는 어떤 정보가 추출될까. 계층이 깊어지면 깊어질수록 추출되는 정보(정확히는 강하게 반응하는 뉴런)는 더 추상화된다는 것을 알 수 있다. | . | . | . 딥러닝의 흥미로운 점은 합성곱 계층을 겹겹히 쌓으면 층이 깊어지면서 더 복잡하고 추상화된 정보가 추출된다는 것이다. | 처음 층은 단순한 에지에 반응하고, 이어서 텍스처에 반응하고, 더 복잡한 사물의 일부에 반응하도록 변화한다. 즉, 층이 깊어지면서 뉴런이 반응하는 대상이 단순한 모양에서 고급 정보로 변해간다. 다시 말하면 사물의 의미를 이해하도록 변화하는 것이다. | . | . . 대표적 CNN 지금까지 제안된 CNN 네트워크 구성은 다양하다. 그 중 두가지를 알아보자 | . | . 1) LeNet 손글씨 숫자를 인식하는 네트워크로서 합성곱 계층과 풀링 계층을 반복하고 마지막으로 완전연결 계층을 거치면서 결과를 출력한다. | 현재의 CNN과 몇가지 차이가 있다. 1) 활성화함수가 LeNet은 Sigmoid인 반면, 현재는 주로 ReLU를 사용한다. | 2) 원래의 LeNet은 서브 샘플링을 하여 중간 데이터의 크기를 줄이지만 현재는 최대 풀링이 주류이다. | . | . | . 2) AlexNet 합성곱 계층과 풀링 계층을 거듭하며 마지막으로 완전연결 계층을 거쳐 결과를 출력한다. LeNet에서 큰 구조는 바뀌지 않는다. 1) 활성화 함수로 ReLU를 이용한다. | 2) LRN이라는 국소적 정규화를 실시하는 계층을 이용한다. | 3) 드롭 아웃을 사용한다. | . | . | . . Conclusion . CNN에 대해 배웠다. CNN은 이미지를 다루는 분야에서는 거의 예외없이 쓰인다. | CNN은 지금까지의 완전연결 계층 네트워크에 합성곱 계층가 풀링 계층을 새로 추가한다. | 합성곱 계층과 풀링 계층은 im2col(이미지를 행렬로 전개하는 함수)을 이용하면 간단하고 효율적으로 구현할 수 있다. | CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있다. | 대표적인 CNN에는 LeNet과 AlexNet이 있다. | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/20/dl.html",
            "relUrl": "/2022/02/20/dl.html",
            "date": " • Feb 20, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "3차원 데이터의 합성곱 연산, 풀링 계층",
            "content": "지금까지 2차원 형상을 다루는 합성곱 연산을 살펴봤다. 그러나 이미지만 해도 세로,가로,채널까지 총 3차원 데이터이다. | 채널 쪽으로 특징 맵이 여러 개 있다면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고, 그 결과를 더해서 하나의 출력을 얻는다. | 3차원 합성곱 연산에서 주의할 점은 입력 데이터의 채널 수와 필터의 채널 수가 같아야 한다는 것이다. 한편 필터 자체의 크기는 원하는 값으로 설정할 수 있다. (단, 모든 채널의 필터가 같은 크기여야 한다.) | . | . 블록으로 생각하기 3차원의 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 쉽다. 예를들어 채널수C, 높이H, 너비W인 데이터의 형상은(C,H,W)로 쓴다. 필터도 같은 순서로 쓴다. | 합성곱 연산의 출력으로 다수의 채널을 내보내려면 어떻게 해야할까 다수의 필터(가중치)를 사용하는 것이다. | 이런 방식으로 완성된 블록을 다음 계층으로 넘기겠다는 것이 CNN의 처리 흐름이다. | . | . | . 이상에서 보듯 합성곱 연산에서는 필터의 수도 고려해야 한다. 그런 이유로 필터의 가중치 데이터는 4차원 데이터이며(출력 채널 수, 입력 채널 수, 높이, 너비) 순으로 쓴다. | . 합성곱 연산에서도 완전연결 계층과 마찬가지로 편향이 쓰인다. 편향은 채널 하나에 값 하나씩으로 구성된다. 이 예에서는 편향의 현상은 (FN,1,1)이고 필터의 출력 결과의 형상은 (FN,OH,OW)이다. 이 두블록을 더하면 편향의 각 값이 필터의 출력인 (FN,OH,OW) 블록의 대응 채널의 원소 모두에 더해진다. 참고로 형상이 다른 블록의 덧셈은 넘파이의 브로드캐스트 기능으로 쉽게 구현 가능하다. | . | . | . 배치 처리 합성곱 연산도 마찬가지로 배치 처리를 지원하고자 한다. 그래서 각 계층으로 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장한다. 구체적으로는 데이터를 (데이터 수, 채널 수, 높이, 너비) 순으로 저장한다. | 여기에서 주의할 점 : 신경망에 4차원 데이터가 하나 흐를 따마다 데이터 N개에 대한 합성곱 연산이 이뤄진다는 것이다. 즉, N회 분의 처리를 한 번에 수행하는 것이다. | . | . 풀링 계층 풀링은 세로, 가로 방향의 공간을 줄이는 연산이다. | 2x2 최대 풀링은 최댓값을 구하는 연산으로 2x2는 대상 영역의 크기를 뜻한다. 즉 2x2 최대 풀링은 2x2 크기의 영역에서 가장 큰 원소 하나를 꺼낸다. 또, 스트라이드는 이 예에서는 2로 설정했으므로 2x2 윈도우가 원소 2칸 간격으로 이동한다. 참고로 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통이다. | . | . 풀링 계층의 특징 1) 풀링 계층은 합성곱 계층과 달리 학습해야 할 매개변수가 없다. 풀링은 대상 영역에서 최댓값이나 평균을 취하는 명확한 처리이므로 특별히 학습할 것이 없다. | 2) 풀링 연산은 입력 데이터의 채널 수 그대로 출력 데이터로 내보낸다. | 3) 입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 않는다. | . | . . 합성곱 풀링 계층 구현하기 CNN에서 계층 사이를 흐르는 데이터는 4차원이다. 예를 들어 데이터의 형상이 (10,1,28,28)이라면, 이는 높이28, 너비28, 채널1인 데이터가 10개라는 이야기이다. | . | . import numpy as np . x = np.random.rand(10,1,28,28) x.shape . (10, 1, 28, 28) . 여기 10개 중 첫 번째 데이터에 접근하려면 단순히 x[0], 또, 첫 번째 데이터의 첫 채널의 공간 데이터에 접근하려면 x[0][0],x[0,0]을 통해 접근할 수 있다. | 이처럼 CNN은 4차원 데이터를 다룬다. 그래서 합성곱 연산의 구현은 복잡해질 것 같지만, 다음 절에서 설명하는 im2col(image to cloumn)이라는 트릭이 문제를 단순하게 만들 수 있다. | . im2col 입력 데이터를 필터링(가중치 계산)하기 좋게 전개하는(펼치는) 함수이다. 3차원 입력 데이터에 im2col을 적용하면 2차원 행렬로 바뀐다. 정확히는 배치 안의 데이터 수까지 포함한 4차원 데이터를 2차원으로 변환한다. | im2col은 필터링하기 좋게 입력 데이터를 전개한다. 구체적으로는 입력 데이터에서 필터를 적용하는 영역을 한 줄로 늘어놓는다. | 이 전개를 필터를 적용하는 모든 영역에서 수행하는 게 im2col이다. | 필터 적용 영역이 겹치게 되면 im2col로 전개한 후의 원소 수가 원래 블록의 원소 수보다 많아진다. 그래서 im2col을 사용해 구현하면 메모리를 더 많이 소비하는 단점이 있다. 그렇지만 이 문제를 행렬 계산으로 만들면 선형 대수 라이브러리를 활용해 효율을 높일 수 있다. | . | . im2col 방식으로 출력한 결과는 2차원 행렬이다. CNN은 데이터를 4차원 배열로 저장하므로 2차원인 출력 데이터를 4차원으로 변형한다. 이상이 합성곱 계층의 구현 흐름이다. | im2col은 필터 크기, 스트라이드, 패딩을 고려하여 입력 데이터를 2차원 배열로 전개한다. 구현해보자 | . import sys, os sys.path.append(os.pardir) from common.util import im2col x1 = np.random.rand(1, 3, 7, 7) col1 = im2col(x1, 5, 5, stride = 1, pad =0) print(col1.shape) x2 = np.random.rand(10, 3, 7, 7) col2 = im2col(x2, 5, 5, stride = 1, pad =0) print(col2.shape) . (9, 75) (90, 75) . im2col을 사용하여 합성곱 계층을 구현해보자 | . class Convolution: def __init__(self, W, b, stride=1,pad=0): self.W=W self.b=b self.stride=stride self.pad=pad def forward(self, x): FN, C, FH, FW = self.W.shape N, C, H, W = x.shape out_h = int(1 + ( H + 2*self.pad - FH)/ self.stride) out_w = int(1 + ( W + 2*self.pad - FW)/ self.stride) col = im2col(x, FH, FW, self.stride, self.pad) col_W = self.W.reshape(FN, -1).T out = np.dot(col, col_W) + self.b out = im2col(x,FH,FW,self.stride, self.pad) return out . 이상이 합성곱 계층의 forward 구현이다. | 합성곱 계층의 역전파는 im2col을 역으로 처리한다. | . 풀링 계층 구현도 합성곱 계층과 마찬가지로 im2col을 사용해 입력 데이터를 전개한다. 다만, 풀링의 경우엔 채널 쪽이 독립적이라는 점이 합성곱 계층 때와 다르다. | . | . class Pooling: def __init__(self, pool_h, pool_w, stride = 1, pad=0): self.pool_h = pool_h self.pool_w = pool_w self.stirde = pool_stirde self.pad = pad def forward(self, w): N, C, H, W = x.shape out_h = int(1 + ( H + 2*self.pad - FH)/ self.stride) out_w = int(1 + ( W + 2*self.pad - FW)/ self.stride) # 전개 col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad) col = col.reshape(-1, self.pool_h *self.pool_w) # 최댓값 out = np.max(col, axis = 1) # 성형 out = out.reshape(N, out_h, out_w, C).transpose(0,3,1,2) return out . 풀링 계층 구현 1) 입력 데이터를 전개한다. | 2) 행별 최댓값을 구한다. | 3) 적절한 모양으로 성형한다. | . | . 최댓값 계산에는 넘파이의 np.max 메서드를 사용할 수 있다. np.max는 인수로 축(axis)을 지정할 수 있는데, 이 인수로 지정한 축마다 최댓값을 구할 수 있다. 가령 np.max(x, axis=1)과 같이 쓰면 입력 x의 1번째 차원(0번째가 아닌)의 축마다 최댓값을 반환해준다. .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/19/dl.html",
            "relUrl": "/2022/02/19/dl.html",
            "date": " • Feb 19, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "드롭 아웃 & 합성곱 신경망(CNN)",
            "content": "오버피팅을 억제하는 방법으로 드롭아웃이라는 기법을 사용할 수 있다. 뉴런을 임의로 삭제하면서 학습하는 방법이다. | 훈련 때 뉴런을 무작위로 골라 삭제한다. 삭제된 뉴런은 신호를 전달하지 않는다. 훈련 때는 데이터를 흘릴 때마다 삭제할 뉴런을 무작위로 선택하고, 시험 때는 모든 뉴런에 신호를 전달한다. | 단, 시험 때는 각 뉴런의 출력에 훈련 때 삭제 안 한 비율을 곱하여 출력한다. | . | . import numpy as np . class Dropout : def __init__(self, dropout_ratio=.5): self.dropout_ratio = dropout_ratio self.mask=None def forward(self, x, train_flg = True): if train_flg: self.mask = np.random.rand(*x.shape) &gt; self.dropout_ratio return x * self.mask else : return x * (1 - self.dropout_ratio) def backward(self, dout): return dout * self.mask . 여기에서의 핵심은 훈련 시에는 순전파 때마다 self.mask에 삭제할 뉴런을 False로 표시한다는 것이다. | self.mask는 x와 형상이 같은 배열을 무작위로 생성하고, 그 값이 dropout_ratio보다 큰 원소만 True로 설정한다. | 역전파때의 동작은 ReLU와 같다. | 드롭아웃의 효과를 MNIST 데이터셋으로 확인해보자 | . import os import sys sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정 import numpy as np import matplotlib.pyplot as plt from dataset.mnist import load_mnist from common.multi_layer_net_extend import MultiLayerNetExtend from common.trainer import Trainer (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True) # 오버피팅을 재현하기 위해 학습 데이터 수를 줄임 x_train = x_train[:300] t_train = t_train[:300] # 드롭아웃 사용 유무와 비울 설정 ======================== use_dropout = True # 드롭아웃을 쓰지 않을 때는 False dropout_ratio = 0.2 # ==================================================== network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio) trainer = Trainer(network, x_train, t_train, x_test, t_test, epochs=301, mini_batch_size=100, optimizer=&#39;sgd&#39;, optimizer_param={&#39;lr&#39;: 0.01}, verbose=True) trainer.train() train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list # 그래프 그리기========== markers = {&#39;train&#39;: &#39;o&#39;, &#39;test&#39;: &#39;s&#39;} x = np.arange(len(train_acc_list)) plt.plot(x, train_acc_list, marker=&#39;o&#39;, label=&#39;train&#39;, markevery=10) plt.plot(x, test_acc_list, marker=&#39;s&#39;, label=&#39;test&#39;, markevery=10) plt.xlabel(&quot;epochs&quot;) plt.ylabel(&quot;accuracy&quot;) plt.ylim(0, 1.0) plt.legend(loc=&#39;lower right&#39;) plt.show() . train loss:2.324100259095491 === epoch:1, train acc:0.06, test acc:0.0519 === train loss:2.3367240344717546 train loss:2.3198828799791507 train loss:2.334138201403393 === epoch:2, train acc:0.06333333333333334, test acc:0.0534 === train loss:2.368374415559161 train loss:2.3381363551504286 train loss:2.3330928399833835 === epoch:3, train acc:0.06333333333333334, test acc:0.0548 === train loss:2.3385353626060423 train loss:2.321698027938764 train loss:2.342470764732769 === epoch:4, train acc:0.06666666666666667, test acc:0.0566 === train loss:2.3181256091192863 train loss:2.318016527906595 train loss:2.3341585909597278 === epoch:5, train acc:0.07, test acc:0.0585 === train loss:2.3223824145629153 train loss:2.3127880613389453 train loss:2.3268800220936066 === epoch:6, train acc:0.07, test acc:0.0612 === train loss:2.3323298965987163 train loss:2.3165949954128062 train loss:2.3143363185934573 === epoch:7, train acc:0.08333333333333333, test acc:0.0633 === train loss:2.315828117487278 train loss:2.333196760768538 train loss:2.306113270261319 === epoch:8, train acc:0.08333333333333333, test acc:0.0665 === train loss:2.3230691151629 train loss:2.302295036765928 train loss:2.3050098518514877 === epoch:9, train acc:0.09, test acc:0.0681 === train loss:2.302610372179809 train loss:2.3192645732440322 train loss:2.322518870537485 === epoch:10, train acc:0.10666666666666667, test acc:0.0707 === train loss:2.307218021902985 train loss:2.3061724911770507 train loss:2.3010604532329983 === epoch:11, train acc:0.11, test acc:0.0737 === train loss:2.30023057573994 train loss:2.3051623665362864 train loss:2.2938154369504575 === epoch:12, train acc:0.11, test acc:0.0813 === train loss:2.3134678116607215 train loss:2.2945534263230702 train loss:2.3100487292414247 === epoch:13, train acc:0.12333333333333334, test acc:0.0859 === train loss:2.3037582367612863 train loss:2.308003699202601 train loss:2.2988065268228475 === epoch:14, train acc:0.12666666666666668, test acc:0.0923 === train loss:2.286301855338051 train loss:2.301356815456316 train loss:2.310309438466073 === epoch:15, train acc:0.12666666666666668, test acc:0.0969 === train loss:2.2859136734966503 train loss:2.320434074887247 train loss:2.3022566690845334 === epoch:16, train acc:0.13333333333333333, test acc:0.105 === train loss:2.303994382649848 train loss:2.2981563636787774 train loss:2.278755644740708 === epoch:17, train acc:0.13666666666666666, test acc:0.1095 === train loss:2.292802302269951 train loss:2.2967010449612086 train loss:2.297434898716603 === epoch:18, train acc:0.14, test acc:0.1122 === train loss:2.307140414078851 train loss:2.3112541114077234 train loss:2.2912007308676308 === epoch:19, train acc:0.14666666666666667, test acc:0.1173 === train loss:2.305011525489231 train loss:2.2933798585530156 train loss:2.2842759863784563 === epoch:20, train acc:0.14666666666666667, test acc:0.1212 === train loss:2.294419306615848 train loss:2.29882546005831 train loss:2.30492862773529 === epoch:21, train acc:0.15, test acc:0.1253 === train loss:2.3081045476194086 train loss:2.283894393780756 train loss:2.291670885938608 === epoch:22, train acc:0.15666666666666668, test acc:0.1295 === train loss:2.2890985760190974 train loss:2.2840575010962896 train loss:2.2822402773763595 === epoch:23, train acc:0.16, test acc:0.1336 === train loss:2.271743863077227 train loss:2.280909345191916 train loss:2.2788580115653647 === epoch:24, train acc:0.15333333333333332, test acc:0.1396 === train loss:2.2962624753864516 train loss:2.2857594410543243 train loss:2.2734956258291743 === epoch:25, train acc:0.16, test acc:0.1433 === train loss:2.281196733898885 train loss:2.2855165343491333 train loss:2.272800202200122 === epoch:26, train acc:0.17, test acc:0.146 === train loss:2.2710752373125755 train loss:2.2708058215894718 train loss:2.281390365009942 === epoch:27, train acc:0.17666666666666667, test acc:0.149 === train loss:2.276096368479296 train loss:2.2868398592049792 train loss:2.2533021288181128 === epoch:28, train acc:0.18, test acc:0.1531 === train loss:2.279790935445175 train loss:2.290175069849667 train loss:2.28755381923219 === epoch:29, train acc:0.18666666666666668, test acc:0.1584 === train loss:2.268625340428652 train loss:2.271549787381626 train loss:2.277468101452462 === epoch:30, train acc:0.20666666666666667, test acc:0.1625 === train loss:2.274422617681268 train loss:2.27950797654735 train loss:2.2595019502888984 === epoch:31, train acc:0.21, test acc:0.1682 === train loss:2.2547736778519254 train loss:2.2955682215285855 train loss:2.281911820002909 === epoch:32, train acc:0.21, test acc:0.1706 === train loss:2.2849632248118397 train loss:2.270001897878741 train loss:2.2721893742474184 === epoch:33, train acc:0.20666666666666667, test acc:0.1744 === train loss:2.2702002840967537 train loss:2.2636977488932697 train loss:2.2457445209173006 === epoch:34, train acc:0.21333333333333335, test acc:0.1782 === train loss:2.282174901289564 train loss:2.2719907929706573 train loss:2.278374323648339 === epoch:35, train acc:0.21333333333333335, test acc:0.1822 === train loss:2.2780296393134916 train loss:2.260936883419436 train loss:2.2791379144450414 === epoch:36, train acc:0.21333333333333335, test acc:0.1847 === train loss:2.2682905978520376 train loss:2.244083967617716 train loss:2.284818421389002 === epoch:37, train acc:0.22666666666666666, test acc:0.1884 === train loss:2.2703278778363924 train loss:2.27787084368482 train loss:2.264595328350379 === epoch:38, train acc:0.23, test acc:0.192 === train loss:2.2564862825603043 train loss:2.248164370992879 train loss:2.2527666356919998 === epoch:39, train acc:0.23333333333333334, test acc:0.1943 === train loss:2.2527864764123833 train loss:2.2609731773162323 train loss:2.2690263147617125 === epoch:40, train acc:0.23333333333333334, test acc:0.1952 === train loss:2.2728311806303987 train loss:2.2538989367626523 train loss:2.2480245940540566 === epoch:41, train acc:0.23333333333333334, test acc:0.1975 === train loss:2.265938876735138 train loss:2.2582592056648663 train loss:2.2479282408121732 === epoch:42, train acc:0.23333333333333334, test acc:0.1964 === train loss:2.266068436358752 train loss:2.2576908657265338 train loss:2.274389230169998 === epoch:43, train acc:0.23333333333333334, test acc:0.1976 === train loss:2.2699133277976635 train loss:2.2822305782291945 train loss:2.2583668340850913 === epoch:44, train acc:0.24, test acc:0.2027 === train loss:2.2614999803016334 train loss:2.2715128262870534 train loss:2.2588317789592836 === epoch:45, train acc:0.25333333333333335, test acc:0.2062 === train loss:2.2638318019294044 train loss:2.2537424854780173 train loss:2.2731680110310455 === epoch:46, train acc:0.25333333333333335, test acc:0.2067 === train loss:2.2671178394983924 train loss:2.2449131639062205 train loss:2.2437541809558295 === epoch:47, train acc:0.25666666666666665, test acc:0.2074 === train loss:2.263695618550946 train loss:2.244976087974502 train loss:2.2411468468562883 === epoch:48, train acc:0.25333333333333335, test acc:0.2082 === train loss:2.26033814844771 train loss:2.242678644044038 train loss:2.248558420132348 === epoch:49, train acc:0.25, test acc:0.2068 === train loss:2.2207890938560095 train loss:2.2312159532346563 train loss:2.2579461674859767 === epoch:50, train acc:0.25333333333333335, test acc:0.2077 === train loss:2.2477645504298174 train loss:2.2476478990710826 train loss:2.263757677075739 === epoch:51, train acc:0.25, test acc:0.2086 === train loss:2.2348103691313668 train loss:2.2545860567012075 train loss:2.255671015156717 === epoch:52, train acc:0.25666666666666665, test acc:0.2096 === train loss:2.2441162497387506 train loss:2.255375576433403 train loss:2.2346755166153973 === epoch:53, train acc:0.26, test acc:0.2108 === train loss:2.2570070909264732 train loss:2.2245861219591716 train loss:2.2565773725303098 === epoch:54, train acc:0.26, test acc:0.2117 === train loss:2.226096569672674 train loss:2.2218325076971666 train loss:2.227156394991192 === epoch:55, train acc:0.25666666666666665, test acc:0.2105 === train loss:2.2244379733138535 train loss:2.2325094973723605 train loss:2.241027209234398 === epoch:56, train acc:0.25666666666666665, test acc:0.2097 === train loss:2.260287003375664 train loss:2.229487178465668 train loss:2.220148957477374 === epoch:57, train acc:0.25666666666666665, test acc:0.2094 === train loss:2.239870454972404 train loss:2.235996812833804 train loss:2.229316333709944 === epoch:58, train acc:0.25666666666666665, test acc:0.2091 === train loss:2.233170338009764 train loss:2.259041256588281 train loss:2.2487296817763007 === epoch:59, train acc:0.26, test acc:0.2097 === train loss:2.228170631739541 train loss:2.2589295915082332 train loss:2.244326933571112 === epoch:60, train acc:0.2633333333333333, test acc:0.2126 === train loss:2.2364859471415284 train loss:2.2225963595525378 train loss:2.2464349094017746 === epoch:61, train acc:0.2633333333333333, test acc:0.2136 === train loss:2.2360741988667225 train loss:2.2176610983003044 train loss:2.2504923570537336 === epoch:62, train acc:0.25666666666666665, test acc:0.2161 === train loss:2.2377980569671685 train loss:2.2149168805210655 train loss:2.2266473653024543 === epoch:63, train acc:0.26, test acc:0.2161 === train loss:2.257205434155905 train loss:2.23834838368647 train loss:2.2165933792455035 === epoch:64, train acc:0.26, test acc:0.2179 === train loss:2.21724329659052 train loss:2.212005481209344 train loss:2.2086091616077375 === epoch:65, train acc:0.26, test acc:0.2154 === train loss:2.19237124426394 train loss:2.1841162031880064 train loss:2.225928661918044 === epoch:66, train acc:0.25333333333333335, test acc:0.2138 === train loss:2.2489977310895224 train loss:2.1993606346466934 train loss:2.2489438258992642 === epoch:67, train acc:0.25333333333333335, test acc:0.2148 === train loss:2.2274704687524407 train loss:2.2267277709549926 train loss:2.2124939673748223 === epoch:68, train acc:0.25666666666666665, test acc:0.2154 === train loss:2.21276779651636 train loss:2.223876646024247 train loss:2.2140444856538646 === epoch:69, train acc:0.25666666666666665, test acc:0.2163 === train loss:2.1904753882346104 train loss:2.2475553205352745 train loss:2.1829183218013553 === epoch:70, train acc:0.25666666666666665, test acc:0.2167 === train loss:2.221431769059627 train loss:2.239988305199648 train loss:2.1887003426742577 === epoch:71, train acc:0.25333333333333335, test acc:0.2168 === train loss:2.2314761993500203 train loss:2.235210919162627 train loss:2.194756686548659 === epoch:72, train acc:0.25666666666666665, test acc:0.2173 === train loss:2.2058456540427045 train loss:2.2334618712692835 train loss:2.1839681190162086 === epoch:73, train acc:0.27, test acc:0.2188 === train loss:2.2102695288167293 train loss:2.168932264118608 train loss:2.2454311199247416 === epoch:74, train acc:0.2633333333333333, test acc:0.2189 === train loss:2.2210089627153304 train loss:2.2127253844490204 train loss:2.187347815206704 === epoch:75, train acc:0.2633333333333333, test acc:0.2196 === train loss:2.209102544892577 train loss:2.1826570566323915 train loss:2.2309548372006645 === epoch:76, train acc:0.27, test acc:0.2198 === train loss:2.1992447116750014 train loss:2.180957522375729 train loss:2.218867388209114 === epoch:77, train acc:0.26666666666666666, test acc:0.2198 === train loss:2.1675144642464685 train loss:2.2068994329399634 train loss:2.2018092638357847 === epoch:78, train acc:0.2633333333333333, test acc:0.2188 === train loss:2.1847385704055253 train loss:2.180533813260938 train loss:2.1697845427004205 === epoch:79, train acc:0.27, test acc:0.2184 === train loss:2.2072852284818087 train loss:2.1970507122089566 train loss:2.1797600512638184 === epoch:80, train acc:0.2633333333333333, test acc:0.2185 === train loss:2.2161420395002245 train loss:2.2094001411863213 train loss:2.2460413384658 === epoch:81, train acc:0.2633333333333333, test acc:0.2201 === train loss:2.1806652633553365 train loss:2.198152397792485 train loss:2.1607521011605084 === epoch:82, train acc:0.2633333333333333, test acc:0.2188 === train loss:2.1807034162148136 train loss:2.2130427621985707 train loss:2.154109095438752 === epoch:83, train acc:0.26, test acc:0.2188 === train loss:2.189663737590424 train loss:2.155494630287265 train loss:2.2159501574240745 === epoch:84, train acc:0.26, test acc:0.2198 === train loss:2.162539240008073 train loss:2.195543512092732 train loss:2.1853185353311493 === epoch:85, train acc:0.2633333333333333, test acc:0.2208 === train loss:2.1600057055782638 train loss:2.1818113822289478 train loss:2.1328014536694466 === epoch:86, train acc:0.2633333333333333, test acc:0.2193 === train loss:2.1887660681677885 train loss:2.1884111205495524 train loss:2.193076194970264 === epoch:87, train acc:0.26, test acc:0.2204 === train loss:2.152790054758269 train loss:2.187410599046354 train loss:2.1901313150457593 === epoch:88, train acc:0.2633333333333333, test acc:0.2205 === train loss:2.167731209783988 train loss:2.1935874284839825 train loss:2.1537553190642615 === epoch:89, train acc:0.26, test acc:0.2211 === train loss:2.150969900292231 train loss:2.193534128106561 train loss:2.161949285578587 === epoch:90, train acc:0.2633333333333333, test acc:0.2218 === train loss:2.163776864663713 train loss:2.187102902202226 train loss:2.136568041162818 === epoch:91, train acc:0.26666666666666666, test acc:0.2227 === train loss:2.149692629425911 train loss:2.1352815933093523 train loss:2.1981598394195743 === epoch:92, train acc:0.2733333333333333, test acc:0.2232 === train loss:2.144301004755044 train loss:2.2054131763238263 train loss:2.1654375496545053 === epoch:93, train acc:0.2733333333333333, test acc:0.2233 === train loss:2.1408959125166023 train loss:2.2156218333940774 train loss:2.1763032139023584 === epoch:94, train acc:0.28, test acc:0.224 === train loss:2.147698204758112 train loss:2.183318985046108 train loss:2.118187234473891 === epoch:95, train acc:0.28, test acc:0.2251 === train loss:2.1444901122248985 train loss:2.1933666832314045 train loss:2.124085736784169 === epoch:96, train acc:0.2833333333333333, test acc:0.2252 === train loss:2.152872063824104 train loss:2.1633217497260144 train loss:2.173299458971835 === epoch:97, train acc:0.2833333333333333, test acc:0.2261 === train loss:2.1060404749821835 train loss:2.1602194770159246 train loss:2.1683339156636467 === epoch:98, train acc:0.27666666666666667, test acc:0.2262 === train loss:2.1394693562006832 train loss:2.1734312638358966 train loss:2.1380837001883064 === epoch:99, train acc:0.2833333333333333, test acc:0.227 === train loss:2.155884162173334 train loss:2.1427548765428406 train loss:2.0945199304591653 === epoch:100, train acc:0.27666666666666667, test acc:0.2262 === train loss:2.1313715872888093 train loss:2.1608023802178153 train loss:2.075899404413534 === epoch:101, train acc:0.27, test acc:0.2252 === train loss:2.1304498390585507 train loss:2.0392660263772164 train loss:2.0775353393252787 === epoch:102, train acc:0.27, test acc:0.2238 === train loss:2.063112995513289 train loss:2.140493741714319 train loss:2.1104146611017107 === epoch:103, train acc:0.2733333333333333, test acc:0.2236 === train loss:2.1176756524604308 train loss:2.177458480517272 train loss:2.0863229827353367 === epoch:104, train acc:0.2833333333333333, test acc:0.2248 === train loss:2.0859330117226564 train loss:2.122782503716861 train loss:2.0864938964362127 === epoch:105, train acc:0.27666666666666667, test acc:0.2247 === train loss:2.081051745566688 train loss:2.1361028681037437 train loss:2.22147822839819 === epoch:106, train acc:0.27666666666666667, test acc:0.2256 === train loss:2.0015204448745227 train loss:2.1104614728950937 train loss:2.113990270074682 === epoch:107, train acc:0.27666666666666667, test acc:0.2249 === train loss:2.065367547469283 train loss:2.1381304178186964 train loss:2.0455887997103117 === epoch:108, train acc:0.28, test acc:0.2251 === train loss:2.06493140690479 train loss:2.0508167423796717 train loss:2.1529074587919537 === epoch:109, train acc:0.28, test acc:0.2255 === train loss:2.1667413655310095 train loss:2.103452449869255 train loss:2.0790366549237493 === epoch:110, train acc:0.2833333333333333, test acc:0.2263 === train loss:2.1774945792404194 train loss:2.0385256422624334 train loss:2.0629139150764084 === epoch:111, train acc:0.2833333333333333, test acc:0.2266 === train loss:2.074240722121803 train loss:2.1010259158418596 train loss:2.0074007529022735 === epoch:112, train acc:0.2866666666666667, test acc:0.2265 === train loss:2.1528450740157044 train loss:2.08511780682749 train loss:2.0901948848345926 === epoch:113, train acc:0.2866666666666667, test acc:0.2278 === train loss:2.166109902076436 train loss:2.09336347639171 train loss:2.1613331299208287 === epoch:114, train acc:0.29, test acc:0.2308 === train loss:2.002040289162185 train loss:2.097397864386531 train loss:2.098147022018419 === epoch:115, train acc:0.2966666666666667, test acc:0.2318 === train loss:2.0381972726258972 train loss:2.15172476114923 train loss:2.1027479429246907 === epoch:116, train acc:0.2966666666666667, test acc:0.2334 === train loss:2.07739882818642 train loss:2.135866705591904 train loss:2.1189283073357306 === epoch:117, train acc:0.29, test acc:0.2338 === train loss:2.1116926320733493 train loss:2.099161725550368 train loss:2.0873500758779087 === epoch:118, train acc:0.29333333333333333, test acc:0.2351 === train loss:2.099495182896229 train loss:2.0126648327487664 train loss:2.0601573227547645 === epoch:119, train acc:0.29, test acc:0.2351 === train loss:2.074034520229973 train loss:2.1378415870297904 train loss:2.1141976674230287 === epoch:120, train acc:0.2966666666666667, test acc:0.2383 === train loss:2.1194542249195916 train loss:2.0985911423683614 train loss:2.122046816594318 === epoch:121, train acc:0.30666666666666664, test acc:0.2393 === train loss:2.079052667678309 train loss:2.046963236671442 train loss:2.1335675274216577 === epoch:122, train acc:0.31, test acc:0.2421 === train loss:2.127066274108861 train loss:2.100447609300942 train loss:2.098331735511033 === epoch:123, train acc:0.31, test acc:0.244 === train loss:2.0469081741676955 train loss:2.1039289102085332 train loss:1.9575786135807827 === epoch:124, train acc:0.31, test acc:0.243 === train loss:1.97676936296635 train loss:2.056448119174276 train loss:2.070794672709109 === epoch:125, train acc:0.31, test acc:0.2439 === train loss:1.9718699908195887 train loss:2.1200802686016287 train loss:2.014578938068621 === epoch:126, train acc:0.31, test acc:0.2446 === train loss:1.9547181661505006 train loss:2.0686912310767838 train loss:2.1844177786643537 === epoch:127, train acc:0.30666666666666664, test acc:0.2438 === train loss:1.9812634982241502 train loss:2.15078634646344 train loss:2.0881807215005583 === epoch:128, train acc:0.31, test acc:0.2438 === train loss:2.034935910585923 train loss:2.0164586052624873 train loss:2.112468141598271 === epoch:129, train acc:0.31, test acc:0.2449 === train loss:2.0907644950072735 train loss:1.9975399152081927 train loss:2.0736024599035736 === epoch:130, train acc:0.31, test acc:0.2464 === train loss:1.9387292142127248 train loss:2.041868755617978 train loss:2.046324630042435 === epoch:131, train acc:0.31, test acc:0.2473 === train loss:1.9727510993177229 train loss:2.043531455268269 train loss:2.0240402732367677 === epoch:132, train acc:0.31, test acc:0.2458 === train loss:2.04070453818416 train loss:2.079140562625451 train loss:2.021468476008009 === epoch:133, train acc:0.31666666666666665, test acc:0.2476 === train loss:1.935517946457607 train loss:2.051982446203123 train loss:2.100136613442308 === epoch:134, train acc:0.31333333333333335, test acc:0.2495 === train loss:1.9448120641057778 train loss:2.0112830470003633 train loss:2.057390431157715 === epoch:135, train acc:0.31333333333333335, test acc:0.2484 === train loss:2.0341794582941435 train loss:2.025210458234844 train loss:2.0281735103776906 === epoch:136, train acc:0.3233333333333333, test acc:0.2488 === train loss:1.969998278174036 train loss:2.0030721293636775 train loss:1.876649732732676 === epoch:137, train acc:0.31666666666666665, test acc:0.2479 === train loss:2.023792049309528 train loss:2.099909568899363 train loss:2.0489493873325912 === epoch:138, train acc:0.31666666666666665, test acc:0.2477 === train loss:2.045474970547569 train loss:1.9696447491452977 train loss:1.9603566304596434 === epoch:139, train acc:0.31666666666666665, test acc:0.2479 === train loss:1.9298739300918757 train loss:2.028965973441627 train loss:1.9836225923680686 === epoch:140, train acc:0.31666666666666665, test acc:0.2485 === train loss:2.0368180039384147 train loss:2.0666601418106563 train loss:2.052390861421367 === epoch:141, train acc:0.31666666666666665, test acc:0.2503 === train loss:2.039428538652129 train loss:2.1011665299140505 train loss:1.9527534298844116 === epoch:142, train acc:0.33, test acc:0.2534 === train loss:1.9917154522367349 train loss:1.989418501654413 train loss:2.0873160884058253 === epoch:143, train acc:0.33666666666666667, test acc:0.2564 === train loss:2.063290643753276 train loss:1.9756256132963648 train loss:1.9965410166665116 === epoch:144, train acc:0.3433333333333333, test acc:0.2585 === train loss:1.9643850841753834 train loss:2.0175293728607238 train loss:2.0103351770632343 === epoch:145, train acc:0.34, test acc:0.2592 === train loss:2.1078657793706843 train loss:1.8411574963386443 train loss:1.922042281137775 === epoch:146, train acc:0.34, test acc:0.261 === train loss:2.0825775896245937 train loss:2.126813271397813 train loss:1.9528955552909528 === epoch:147, train acc:0.34, test acc:0.2611 === train loss:2.03098018321778 train loss:1.9632901055441285 train loss:1.862457814085648 === epoch:148, train acc:0.34, test acc:0.2609 === train loss:1.9685806847460605 train loss:1.923425037316148 train loss:1.957268510494084 === epoch:149, train acc:0.34, test acc:0.2611 === train loss:2.043878630017103 train loss:1.9744954960327386 train loss:1.9848518415320993 === epoch:150, train acc:0.34, test acc:0.2622 === train loss:2.051841403997525 train loss:2.011274044477478 train loss:1.8818355118043169 === epoch:151, train acc:0.34, test acc:0.261 === train loss:2.0560602621623874 train loss:2.004623926602401 train loss:1.8932646503316422 === epoch:152, train acc:0.33666666666666667, test acc:0.2601 === train loss:1.9834598038826332 train loss:2.0182768513882636 train loss:1.9986896365191595 === epoch:153, train acc:0.3333333333333333, test acc:0.2632 === train loss:1.969720678927994 train loss:1.9445517208049543 train loss:1.9277266381018017 === epoch:154, train acc:0.34, test acc:0.2638 === train loss:2.0774724473669233 train loss:1.9641365271450433 train loss:1.9957655126585268 === epoch:155, train acc:0.34, test acc:0.2662 === train loss:1.9375892922085827 train loss:2.010059318934352 train loss:1.9364413587878533 === epoch:156, train acc:0.33666666666666667, test acc:0.2649 === train loss:1.9068950820392507 train loss:2.0026559727655995 train loss:2.0502203811321165 === epoch:157, train acc:0.33, test acc:0.2662 === train loss:1.8170210330517087 train loss:1.9443773176379884 train loss:1.919411704245374 === epoch:158, train acc:0.33666666666666667, test acc:0.2669 === train loss:1.920649279768768 train loss:1.9184216373899974 train loss:2.024490190710448 === epoch:159, train acc:0.34, test acc:0.2678 === train loss:1.951044152023751 train loss:2.0249130007591716 train loss:1.9660162515312378 === epoch:160, train acc:0.3466666666666667, test acc:0.2711 === train loss:1.8972348726775836 train loss:1.990833810475007 train loss:1.8555055491948909 === epoch:161, train acc:0.3433333333333333, test acc:0.2706 === train loss:2.0225194549776826 train loss:1.9440140220076108 train loss:1.9980009538684869 === epoch:162, train acc:0.3466666666666667, test acc:0.2708 === train loss:1.9254272086466748 train loss:2.0307065173792918 train loss:2.008381596962002 === epoch:163, train acc:0.3466666666666667, test acc:0.2735 === train loss:2.016539412022592 train loss:1.9956689777990155 train loss:1.984170093366145 === epoch:164, train acc:0.3466666666666667, test acc:0.2751 === train loss:1.9411797704450244 train loss:1.96764408593041 train loss:2.048926673388958 === epoch:165, train acc:0.35, test acc:0.2766 === train loss:1.9499846242655454 train loss:1.9130460257802702 train loss:1.9710619234028592 === epoch:166, train acc:0.35, test acc:0.2763 === train loss:1.9043802241945065 train loss:1.9583706004181962 train loss:1.9031245195243744 === epoch:167, train acc:0.3466666666666667, test acc:0.2758 === train loss:1.9062347210662154 train loss:1.9493844956250794 train loss:1.9071355394175773 === epoch:168, train acc:0.3466666666666667, test acc:0.2768 === train loss:2.0240281957036705 train loss:1.9561819635947373 train loss:1.8399586607735658 === epoch:169, train acc:0.35, test acc:0.2795 === train loss:1.9896012927631008 train loss:1.830988595568251 train loss:1.9382594910162485 === epoch:170, train acc:0.35, test acc:0.2793 === train loss:2.012869529899594 train loss:1.9722668865049164 train loss:1.84372392981833 === epoch:171, train acc:0.35, test acc:0.2799 === train loss:1.9659629510542826 train loss:1.8762033576907549 train loss:1.9110343407405472 === epoch:172, train acc:0.3466666666666667, test acc:0.2791 === train loss:1.9935599130037718 train loss:1.9677044010921336 train loss:1.9570530536060875 === epoch:173, train acc:0.3466666666666667, test acc:0.28 === train loss:1.9050336236965477 train loss:1.8893146808603987 train loss:1.937248951207443 === epoch:174, train acc:0.3566666666666667, test acc:0.2812 === train loss:2.0129007687434908 train loss:1.8507440880477242 train loss:1.9172139358070337 === epoch:175, train acc:0.3566666666666667, test acc:0.2821 === train loss:1.8611484880791236 train loss:1.9842011083211926 train loss:1.9702341877582854 === epoch:176, train acc:0.3566666666666667, test acc:0.2831 === train loss:1.9505687961453058 train loss:1.8790608865088543 train loss:1.9202845450752322 === epoch:177, train acc:0.36, test acc:0.2855 === train loss:1.9166693275231856 train loss:1.8575061650223998 train loss:1.8711489303742994 === epoch:178, train acc:0.36, test acc:0.2837 === train loss:1.8463088943000472 train loss:1.8510470957129552 train loss:1.8779748255987232 === epoch:179, train acc:0.37333333333333335, test acc:0.2847 === train loss:1.8907847935715134 train loss:1.868600067831465 train loss:1.970452296562895 === epoch:180, train acc:0.38, test acc:0.2861 === train loss:1.8674366822881316 train loss:1.921144585535963 train loss:1.8807798815014383 === epoch:181, train acc:0.37666666666666665, test acc:0.2867 === train loss:1.8874599954257691 train loss:1.8717509249621196 train loss:1.8045921844238015 === epoch:182, train acc:0.36, test acc:0.2877 === train loss:1.8994162210398318 train loss:1.8791350420075872 train loss:1.8480320991371042 === epoch:183, train acc:0.36, test acc:0.2879 === train loss:1.799536452818469 train loss:1.89795201733964 train loss:1.7648443495581463 === epoch:184, train acc:0.36666666666666664, test acc:0.2887 === train loss:1.835462161742262 train loss:1.8294867440417215 train loss:1.8984998467611496 === epoch:185, train acc:0.36, test acc:0.2867 === train loss:1.8943726695842509 train loss:1.8173568580152093 train loss:1.8470304534702426 === epoch:186, train acc:0.36, test acc:0.2859 === train loss:2.0573224500330896 train loss:1.8266063368945584 train loss:1.841408771074559 === epoch:187, train acc:0.36, test acc:0.2853 === train loss:1.7540531751483739 train loss:1.8568064584595232 train loss:1.8809472035617443 === epoch:188, train acc:0.36333333333333334, test acc:0.2877 === train loss:1.9003421485644183 train loss:1.8108746974278713 train loss:1.9389650756589378 === epoch:189, train acc:0.37, test acc:0.2886 === train loss:1.7805326809540967 train loss:1.8933837060774965 train loss:1.7942781465820434 === epoch:190, train acc:0.36666666666666664, test acc:0.288 === train loss:1.9647016076531691 train loss:1.825778087500078 train loss:1.9638159705018725 === epoch:191, train acc:0.37, test acc:0.2924 === train loss:1.8156817237376737 train loss:1.7638653091807088 train loss:1.8116257598243088 === epoch:192, train acc:0.37, test acc:0.2937 === train loss:1.7049855380350447 train loss:1.9221692803534238 train loss:1.9353170293217807 === epoch:193, train acc:0.37333333333333335, test acc:0.2957 === train loss:1.863317876700271 train loss:1.8838389028825713 train loss:1.7842611297470667 === epoch:194, train acc:0.37666666666666665, test acc:0.2967 === train loss:1.9797408999485304 train loss:1.7568834758081495 train loss:1.7691509836117805 === epoch:195, train acc:0.37333333333333335, test acc:0.299 === train loss:1.8256000732358004 train loss:1.816912173124073 train loss:1.8375593559073076 === epoch:196, train acc:0.38333333333333336, test acc:0.3003 === train loss:1.714850077618391 train loss:1.832786185623573 train loss:1.7963584029557291 === epoch:197, train acc:0.38, test acc:0.3004 === train loss:1.8169433828888797 train loss:1.790845683502479 train loss:1.8686575642600989 === epoch:198, train acc:0.38333333333333336, test acc:0.3016 === train loss:1.8808915858682178 train loss:1.7707733025649628 train loss:1.6997953886974657 === epoch:199, train acc:0.37666666666666665, test acc:0.3022 === train loss:1.78716741442463 train loss:1.860503622547692 train loss:1.7431574547906379 === epoch:200, train acc:0.37333333333333335, test acc:0.3018 === train loss:1.805818981800991 train loss:1.712304758575884 train loss:1.8846704156094787 === epoch:201, train acc:0.38, test acc:0.3032 === train loss:1.931746713962629 train loss:1.9230235577928536 train loss:1.9097240637508301 === epoch:202, train acc:0.38, test acc:0.3053 === train loss:1.784183568048063 train loss:1.7856396363598708 train loss:1.887761601085864 === epoch:203, train acc:0.38333333333333336, test acc:0.3069 === train loss:1.7529482498255589 train loss:1.7266563268134882 train loss:1.830276740349573 === epoch:204, train acc:0.3933333333333333, test acc:0.3082 === train loss:1.7488745909759187 train loss:1.7016843469482184 train loss:1.796807819614164 === epoch:205, train acc:0.39666666666666667, test acc:0.3097 === train loss:1.760797631408918 train loss:1.66664928355705 train loss:1.8840441966964843 === epoch:206, train acc:0.38333333333333336, test acc:0.3067 === train loss:1.7651570754348782 train loss:1.7773472656666778 train loss:1.9343544437633116 === epoch:207, train acc:0.3933333333333333, test acc:0.3074 === train loss:1.8054348882195037 train loss:1.7868764714646281 train loss:1.8198119532542705 === epoch:208, train acc:0.4, test acc:0.3113 === train loss:1.7203671129854226 train loss:1.980053568475915 train loss:1.7555365491073436 === epoch:209, train acc:0.41333333333333333, test acc:0.3133 === train loss:1.8795404255051842 train loss:1.7558985903076008 train loss:1.7365088596142109 === epoch:210, train acc:0.4166666666666667, test acc:0.3165 === train loss:1.8299119620563624 train loss:1.8166757523514045 train loss:1.8855081645007779 === epoch:211, train acc:0.41333333333333333, test acc:0.3175 === train loss:1.842641975544713 train loss:1.8022630591956763 train loss:1.838034928431486 === epoch:212, train acc:0.4166666666666667, test acc:0.319 === train loss:1.8013702436381749 train loss:1.6346987728243247 train loss:1.7000235058385857 === epoch:213, train acc:0.42, test acc:0.3217 === train loss:1.8566781438456335 train loss:1.7041221906697357 train loss:1.7625717544995407 === epoch:214, train acc:0.4166666666666667, test acc:0.3225 === train loss:1.746800230106021 train loss:1.8154755450924531 train loss:1.7999778863489149 === epoch:215, train acc:0.41, test acc:0.3229 === train loss:1.8232044704176373 train loss:1.81867070440437 train loss:1.6592537469851931 === epoch:216, train acc:0.41333333333333333, test acc:0.3253 === train loss:1.7224332593622613 train loss:1.797001090942961 train loss:1.723563256648315 === epoch:217, train acc:0.4166666666666667, test acc:0.3262 === train loss:1.9103900455828677 train loss:1.6783983670133293 train loss:1.8660601099916494 === epoch:218, train acc:0.43, test acc:0.3308 === train loss:1.7275653044742054 train loss:1.6787546585470248 train loss:1.7668240229284908 === epoch:219, train acc:0.42333333333333334, test acc:0.331 === train loss:1.7340448051992294 train loss:1.6732536457113159 train loss:1.6583273166418457 === epoch:220, train acc:0.4266666666666667, test acc:0.3328 === train loss:1.7574452942846839 train loss:1.6890455031675053 train loss:1.7561452273014115 === epoch:221, train acc:0.42, test acc:0.3306 === train loss:1.7091489149516605 train loss:1.6866254825427336 train loss:1.7631917968868753 === epoch:222, train acc:0.4266666666666667, test acc:0.3358 === train loss:1.6456125319685995 train loss:1.766322712191973 train loss:1.7357799175172948 === epoch:223, train acc:0.4266666666666667, test acc:0.3377 === train loss:1.8189521838869198 train loss:1.706825597566599 train loss:1.7142021038678188 === epoch:224, train acc:0.43666666666666665, test acc:0.3394 === train loss:1.7475017778124853 train loss:1.7613123462262328 train loss:1.7742829620636533 === epoch:225, train acc:0.43333333333333335, test acc:0.3391 === train loss:1.7792912879053078 train loss:1.54109739289766 train loss:1.789763413491916 === epoch:226, train acc:0.4266666666666667, test acc:0.3384 === train loss:1.7689114172523093 train loss:1.7038899744571572 train loss:1.6860352836209762 === epoch:227, train acc:0.43, test acc:0.3418 === train loss:1.6843603791622135 train loss:1.6828303320503832 train loss:1.6773643324580283 === epoch:228, train acc:0.43666666666666665, test acc:0.344 === train loss:1.7375537315323513 train loss:1.7115442172649833 train loss:1.6823257645203253 === epoch:229, train acc:0.44333333333333336, test acc:0.3468 === train loss:1.843718088671171 train loss:1.6469234788670655 train loss:1.6492895705839388 === epoch:230, train acc:0.45666666666666667, test acc:0.3527 === train loss:1.7979535354936311 train loss:1.639535393034727 train loss:1.7621136440933869 === epoch:231, train acc:0.46, test acc:0.3559 === train loss:1.7799639643091836 train loss:1.7802017170697684 train loss:1.7593057842668214 === epoch:232, train acc:0.4666666666666667, test acc:0.3584 === train loss:1.574712912153641 train loss:1.6998409956827003 train loss:1.5989378771112237 === epoch:233, train acc:0.47333333333333333, test acc:0.3618 === train loss:1.785811848615141 train loss:1.534281178675655 train loss:1.5198541200634095 === epoch:234, train acc:0.48333333333333334, test acc:0.3648 === train loss:1.5826778990141586 train loss:1.5849035499112525 train loss:1.662817350558833 === epoch:235, train acc:0.4766666666666667, test acc:0.3577 === train loss:1.7177112689108682 train loss:1.5539165013980303 train loss:1.5876071368935067 === epoch:236, train acc:0.4766666666666667, test acc:0.3558 === train loss:1.7396575046323906 train loss:1.565026242722249 train loss:1.6866317624746034 === epoch:237, train acc:0.4666666666666667, test acc:0.3556 === train loss:1.689891289756031 train loss:1.599954018256681 train loss:1.634418019922859 === epoch:238, train acc:0.47, test acc:0.3575 === train loss:1.7076292366605177 train loss:1.6758439224153856 train loss:1.6618571259585841 === epoch:239, train acc:0.4666666666666667, test acc:0.3607 === train loss:1.63863858191875 train loss:1.779640743257408 train loss:1.6473005473806908 === epoch:240, train acc:0.47, test acc:0.3621 === train loss:1.6414777123726347 train loss:1.5745546648368378 train loss:1.6312962380357132 === epoch:241, train acc:0.4766666666666667, test acc:0.3677 === train loss:1.566572388396348 train loss:1.5934073557487431 train loss:1.628062324786025 === epoch:242, train acc:0.48, test acc:0.3649 === train loss:1.711320766568537 train loss:1.5786321671021764 train loss:1.7497772232645865 === epoch:243, train acc:0.4766666666666667, test acc:0.3676 === train loss:1.7591329159202203 train loss:1.6084195054453954 train loss:1.5096650884245368 === epoch:244, train acc:0.48, test acc:0.3724 === train loss:1.7121261197629665 train loss:1.5985904788095016 train loss:1.5411111356793752 === epoch:245, train acc:0.48333333333333334, test acc:0.3731 === train loss:1.5982216585334155 train loss:1.638834051902801 train loss:1.5946055503395176 === epoch:246, train acc:0.4866666666666667, test acc:0.3757 === train loss:1.656636585720448 train loss:1.4612906229616553 train loss:1.5941509626244075 === epoch:247, train acc:0.4866666666666667, test acc:0.3796 === train loss:1.7164016810653757 train loss:1.5346580638881253 train loss:1.542538901818693 === epoch:248, train acc:0.49, test acc:0.3832 === train loss:1.7308203984158939 train loss:1.5922302426665516 train loss:1.6108121535789053 === epoch:249, train acc:0.49, test acc:0.3843 === train loss:1.5550386136578294 train loss:1.5563264600387745 train loss:1.614005513399188 === epoch:250, train acc:0.4866666666666667, test acc:0.3842 === train loss:1.6500828782037262 train loss:1.607933999439878 train loss:1.6568878532643685 === epoch:251, train acc:0.49333333333333335, test acc:0.3875 === train loss:1.4758006171269265 train loss:1.6532829044147137 train loss:1.5876132603249373 === epoch:252, train acc:0.49333333333333335, test acc:0.3909 === train loss:1.5790953511321293 train loss:1.5211766697296012 train loss:1.6003585039092116 === epoch:253, train acc:0.4866666666666667, test acc:0.3866 === train loss:1.5632813699473649 train loss:1.6778924478513166 train loss:1.7046327661625922 === epoch:254, train acc:0.5066666666666667, test acc:0.3985 === train loss:1.6072893775061263 train loss:1.5160192765962208 train loss:1.6472567994911358 === epoch:255, train acc:0.5066666666666667, test acc:0.401 === train loss:1.824939695036039 train loss:1.486832916459613 train loss:1.6273239580549872 === epoch:256, train acc:0.52, test acc:0.4062 === train loss:1.4874601388255393 train loss:1.467083064091311 train loss:1.5727689542098664 === epoch:257, train acc:0.53, test acc:0.4135 === train loss:1.6014578918452758 train loss:1.6171917806471432 train loss:1.6139329028629745 === epoch:258, train acc:0.5333333333333333, test acc:0.4142 === train loss:1.6156921897466183 train loss:1.5796825560037462 train loss:1.6303723682756828 === epoch:259, train acc:0.5366666666666666, test acc:0.416 === train loss:1.67597727636647 train loss:1.6359530460000717 train loss:1.5909065298419358 === epoch:260, train acc:0.5333333333333333, test acc:0.4128 === train loss:1.476790153724701 train loss:1.645917837760857 train loss:1.5046795811581344 === epoch:261, train acc:0.5366666666666666, test acc:0.4136 === train loss:1.592658864567856 train loss:1.6036165890026342 train loss:1.48338089704377 === epoch:262, train acc:0.5466666666666666, test acc:0.4151 === train loss:1.4431031663487912 train loss:1.5213506892554178 train loss:1.5697001108058286 === epoch:263, train acc:0.5566666666666666, test acc:0.4177 === train loss:1.5214170317352547 train loss:1.5180087638544617 train loss:1.5513941088676841 === epoch:264, train acc:0.55, test acc:0.4188 === train loss:1.5683995482511086 train loss:1.4676937019399676 train loss:1.4580990824226263 === epoch:265, train acc:0.5433333333333333, test acc:0.4186 === train loss:1.707480586407072 train loss:1.7280677973945473 train loss:1.5943649244397458 === epoch:266, train acc:0.5433333333333333, test acc:0.4192 === train loss:1.6544583690371593 train loss:1.583485112615594 train loss:1.530855314452777 === epoch:267, train acc:0.5533333333333333, test acc:0.421 === train loss:1.4163990687864885 train loss:1.5623199244026293 train loss:1.5682494418913913 === epoch:268, train acc:0.5666666666666667, test acc:0.4257 === train loss:1.5866676552735208 train loss:1.5222086761796292 train loss:1.552707033154662 === epoch:269, train acc:0.5666666666666667, test acc:0.4246 === train loss:1.4304363682995516 train loss:1.3942265034198058 train loss:1.509513509608932 === epoch:270, train acc:0.5733333333333334, test acc:0.4274 === train loss:1.5285919174023705 train loss:1.523626471058269 train loss:1.5459679077521553 === epoch:271, train acc:0.58, test acc:0.4319 === train loss:1.2754820882863398 train loss:1.3306849494085853 train loss:1.487829704384883 === epoch:272, train acc:0.5733333333333334, test acc:0.4298 === train loss:1.693594217374419 train loss:1.4789983761448753 train loss:1.5293101160774887 === epoch:273, train acc:0.5766666666666667, test acc:0.4322 === train loss:1.4397633088679538 train loss:1.688308959908451 train loss:1.591509956330321 === epoch:274, train acc:0.59, test acc:0.4366 === train loss:1.5196009987955374 train loss:1.6142814885675005 train loss:1.5086929363310508 === epoch:275, train acc:0.59, test acc:0.4406 === train loss:1.5089217384314362 train loss:1.607481330837734 train loss:1.4307427865183475 === epoch:276, train acc:0.5933333333333334, test acc:0.4429 === train loss:1.449484243903928 train loss:1.6394668791191593 train loss:1.5061246469661724 === epoch:277, train acc:0.59, test acc:0.4438 === train loss:1.5177055329009266 train loss:1.4645210190011435 train loss:1.5788320483727964 === epoch:278, train acc:0.5933333333333334, test acc:0.4446 === train loss:1.3248500542673856 train loss:1.425712461833036 train loss:1.5769464795472186 === epoch:279, train acc:0.59, test acc:0.4465 === train loss:1.5212173941834117 train loss:1.4893327404747831 train loss:1.4836456868756966 === epoch:280, train acc:0.5966666666666667, test acc:0.4459 === train loss:1.5759914496885892 train loss:1.3897710796790788 train loss:1.4847861713034656 === epoch:281, train acc:0.59, test acc:0.4459 === train loss:1.5329187589934907 train loss:1.3924491700739612 train loss:1.4864436046449185 === epoch:282, train acc:0.5933333333333334, test acc:0.4482 === train loss:1.4984844900409855 train loss:1.3860508188393887 train loss:1.4957577775488926 === epoch:283, train acc:0.6, test acc:0.4473 === train loss:1.5785863676120204 train loss:1.450373119556028 train loss:1.3911709595556598 === epoch:284, train acc:0.6, test acc:0.4484 === train loss:1.4162460238454186 train loss:1.5943493677742087 train loss:1.2839307441393368 === epoch:285, train acc:0.5933333333333334, test acc:0.4489 === train loss:1.5771857148568125 train loss:1.404284254426774 train loss:1.4446479155959886 === epoch:286, train acc:0.5966666666666667, test acc:0.4476 === train loss:1.3910898457538057 train loss:1.5132214887411823 train loss:1.4751150145621412 === epoch:287, train acc:0.59, test acc:0.4489 === train loss:1.4766364963477931 train loss:1.4797548246781274 train loss:1.420681103522677 === epoch:288, train acc:0.5933333333333334, test acc:0.4511 === train loss:1.428367776657395 train loss:1.359248896336314 train loss:1.372411799737209 === epoch:289, train acc:0.5933333333333334, test acc:0.4493 === train loss:1.5034113818168715 train loss:1.3577210499430956 train loss:1.2964329128208476 === epoch:290, train acc:0.5966666666666667, test acc:0.45 === train loss:1.504386786709066 train loss:1.5729882332621126 train loss:1.2274979096454768 === epoch:291, train acc:0.5933333333333334, test acc:0.4521 === train loss:1.308004413101983 train loss:1.489396218796289 train loss:1.3022177695228365 === epoch:292, train acc:0.6033333333333334, test acc:0.4559 === train loss:1.5313962977249078 train loss:1.3349677964717706 train loss:1.3605829672214755 === epoch:293, train acc:0.6033333333333334, test acc:0.458 === train loss:1.409897312064241 train loss:1.324359046307616 train loss:1.5679920469725541 === epoch:294, train acc:0.6, test acc:0.4576 === train loss:1.3823909338766933 train loss:1.4190104963643273 train loss:1.4806251658954224 === epoch:295, train acc:0.5966666666666667, test acc:0.4599 === train loss:1.4289183837655555 train loss:1.3465830333848827 train loss:1.4598031711166772 === epoch:296, train acc:0.6, test acc:0.4615 === train loss:1.4444288546243653 train loss:1.4765143250458672 train loss:1.41917198141865 === epoch:297, train acc:0.5966666666666667, test acc:0.4616 === train loss:1.379963562422937 train loss:1.4314152309404529 train loss:1.519393150293773 === epoch:298, train acc:0.6, test acc:0.463 === train loss:1.3352178599115019 train loss:1.37437421278872 train loss:1.3801700621916182 === epoch:299, train acc:0.6066666666666667, test acc:0.4664 === train loss:1.3744326244886877 train loss:1.4929308777758425 train loss:1.3930432943610944 === epoch:300, train acc:0.61, test acc:0.468 === train loss:1.3487368002494748 train loss:1.2965541557717892 train loss:1.2238049784281597 === epoch:301, train acc:0.5933333333333334, test acc:0.4681 === train loss:1.4355372170789529 train loss:1.4458507216463057 =============== Final Test Accuracy =============== test acc:0.4699 . 그림과 같이 드롭아웃을 적용하니 훈련 데이터와 시험 데이터에 대한 정확도 차이가 줄었다. | 또, 훈련 데이터에 대한 정확도가 100%에 도달하지도 않게 되었다 즉, 표현력을 높이면서도 오버 피팅을 억제할 수 있다. | 원래는 train의 정확도가 1에 육박하였으며 test와의 정확도 차이도 벌어져 있었다. | . | . 기계학습에서의 앙상블 학습은 드롭아웃과 밀접하다. 드롭아웃이 학습 때 뉴런을 무작위로 삭제하는 행위를 매번 다른 모델을 학습시키는 것으로 해석할 수 있기 때문이다. | 그리고 추론 때는 뉴런의 출력에 삭제한 비율을 곱함으로써 앙상블 학습에서 여러 모델의 평균을 내는 것과 같은 효과를 얻는 것이다. | 즉 드롭아웃은 앙상블 학습과 같은 효과를 하나의 네트워크로 구현했다고 생각할 수 있다. | . | . . 적절한 하이퍼파라미터 값 찾기 하이퍼파라미터? 각 층의 뉴런 수, 배치 크기, 매개변수 갱신 시의 학습률과 가중치 감소 등이다. | 하이퍼 파라미터의 값을 최대한 효율적으로 탐색하는 방법을 설명한다. | . | . 검증 데이터 앞으로 하이퍼파라미터를 다양한 값으로 설정하고 검증할 텐데 여기서 주의할 점은 하이퍼파라미터의 성능을 평가할 때는 시험 데이터를 사용해서 안 된다. 시험 데이터를 사용하여 하이퍼파라미터를 조정하면 하이퍼파라미터 값이 시험 데이터에 오버피팅되기 때문이다. | 즉, 하이퍼파라미터 값의 좋음을 시험 데이터로 확인하게 되므로 하이퍼파라미터의 값이 시험 데이터에만 적합하도록 조정되어 버린다. | 그렇게 되면 다른 데이터에는 적응하지 못하니 범용 성능이 떨어지는 모델이 될지도 모른다. | 따라서 하이퍼파라미터를 조정할 때는 하이퍼파라미터 전용 확인 데이터가 필요하다. 이때 검증 데이터라고 부른다. | . | . | . 훈련 데이터 : 매개변수 학습 | 검증 데이터 : 하이퍼파라미터 성능 평가 | 시험 데이터 : 신경망의 범용 성능 평가 | . 데이터 셋이 훈련 데이터와 시험 데이터로만 분리되어 있다면 검증 데이터를 직접 분리해주어야 한다. | 훈련 데이터 중 20% 정도를 검증 데이터로 먼저 분리하자 | . def shuffle_dataset(x, t): permutation = np.random.permutation(x.shape[0]) x = x[permutation,:] if x.ndim == 2 else x[permutation,:,:,:] t = t[permutation] (x_train,t_train),(x_test,t_test) = load_mnist() # 훈련 데이터를 뒤섞는다. x_train, t_train = shuffle_dataset(x_train, t_train) # 20%를 검증 데이터로 분할 validation_rate = .2 validation_num = int(x_train.shape[0] * validation_rate) x_val = x_train[:validation_num] t_val = t_train[:validation_num] x_train = x_train[validation_num:] t_train = t_train[validation_num:] . 해당 코드를 통해 훈련 데이터를 분리하기 전에 입력 데이터와 정답 레이블을 뒤섞는다. 데이터 셋 안의 데이터가 치우쳐 있을지도 모르기 때문이다. | . . 하이퍼파라미터 최적화 하이퍼파라미터를 최적화할 때의 핵심은 하이퍼파라미터의 최적값이 존재하는 범위를 조금씩 줄여간다는 것이다. | 범위를 조금씩 줄이려면, 우선 대략적인 범위를 설정하고 그 범위에서 무작위로 하이퍼파라미터 값을 골라낸 후, 그 값으로 정확도를 평가한다. 정확도를 잘 살피면서 이 작업을 여러 번 반복하며 하이퍼파라미터의 최적 값의 범위를 좁혀가는 것이다. | . | . . 정리 이번 장에서는 신경망 학습에 중요한 기술 몇 가지를 소개했다. 매개변수 갱신 방법과 가중치의 초깃값을 설정하는 방법, 또 배치 정규화와 드롭아웃 등 현대적인 신경망에서 빼놓을 수 없는 기술들이다. 매개변수 갱신 방법 : 확률적 경사 하강법(SGD), 모멘텀, AdaGrad,Adam등이 있다. | 가중치 초깃값을 정하는 방법은 올바른 학습을 하는 데 매우 중요하다. | 가충치의 초깃값으로는 Xavier 초깃값과 He 초깃값이 효과적이다. | 배치 정규화를 이용하면 학습을 빠르게 진행할 수 있으며, 초깃값의 영향을 덜 받을 수 있다. | 오버피팅을 억제하는 정규화 기술로는 가중치 감소와 드롭아웃이 있다. | 하이퍼파라미터 값 탐색은 최적 값이 존재할 법한 범위를 점차 좁히면서 하는 것이 효과적이다. | . | . | . . 합성곱 신경망(Convolutional Neural Network, CNN) 이미지 인식과 음성 인식 등 다양한 곳에서 사용되는데 특히, 이미지 인식 분야에서 딥러닝을 활용한 기법은 거의 다 CNN을 기초로 한다. | 지금까지 본 신경망과 같이 레고 블록처럼 계층을 조합하여 만들 수 있다. | 다만, 합성곱 계층과 풀링 계층이 새롭게 등장한다. | 지금까지 본 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있었다. 이를 완전연결, 전결합이라고 하며, 완전히 연결된 계층을 Affine 계층이라는 이름으로 구현했다. | 완전 연결 신경망은 Affine 계층 뒤에 활성화 함수를 갖는 ReLU 계층 혹은 Sigmoid 계층이 이어진다. 그렇다면 CNN의 구조는 어떻게 다를까 CNN에서는 새로운 합성곱 계층과 풀링 계층이 추가된다. | 합성곱 계층 - ReLU - 풀링계층 흐름으로 연결된다. 풀링계층은 생략가능하다. | 주의* 출력에 가까운 층은 지금까지의 Affine-ReLU 구성을 사용할 수 있다는 것이다. 또 마지막 출력 계층에선 Affine - Softmax 조합을 그대로 사용한다. | . | . | . CNN에서는 패딩, 스트라이드 등 CNN 고유의 용어가 등장한다. 또, 각 계층 사이에는 3차원 데이터같이 입체적인 데이터가 흐른다는 점에서 완전연결 신경망과 다르다. | . 완전 연결 계층의 문제점 완전연결 계층에서는 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할 수 있었다. | 그렇다면 문제점은 무엇인가? 데이터의 형상이 무시된다는 것이다. 만약 입력 데이터가 이미지인 경우를 예로 들면, 이미지는 통상 세로 , 가로, 채널(색상)로 구성된 3차원 데이터이다. | 그러나 완전연결 계층에 입력할 때는 3차원 데이터를 평평한 1차원 데이터로 평탄화해줘야 한다. | 완전연결 계층은 형상을 무시하고, 모든 입력 데이터를 동등한 뉴런 즉 같은 차원의 뉴런으로 취급하여 형상에 담긴 정보를 살릴 수 없다. | 한편, 합성곱 계층은 형상을 유지한다. 이미지도 3차원 데이터로 입력받으며, 마찬가지로 다음 계층에도 3차원 데이터로 전달한다. 그래서 CNN에서는 이미지처럼 형상을 가진 데이터를 제대로 이해할 가능성이 있는 것이다. | . | . | . CNN에서는 합성곱 계층의 입출력 데이터를 특징 맵(feature map)이라고도 한다. | 합성곱 계층의 입력 데이터를 입력 특징 맵, 출력 데이터를 출력 특징 맵이라고 하는 식이다. 이 책에서는 입출력 데이터와 특징 맵을 같은 의미로 사용한다. | . | . 합성곱 계층에서의 합성곱 연산을 처리하자. | 합성곱 연산은 이미지 처리에서 말하는 필터 연산에 해당한다. 필터를 커널이라 칭하기도 한다. | 합성곱 연산의 자세한 과정은 교재 231p를 참고한다. | . 완전연결 신경망에는 가중치 매개변수와 편향이 존재하는데, CNN에서는 필터의 매개변수가 그동안의 가중치에 해당한다. 그리고 CNN에도 편향이 존재한다. | 편향은 필터를 적용한 후의 데이터에 더해진다. 그리고 편향은 항상 하나만 스칼라로서 존재한다. 그 하나의 값을 필터를 적용한 모든 원소에 더하는 것이다. | . 패딩 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값(예컨대 0)으로 채우기도 한다. 이를 패딩이라한다. | 그렇게되면 출력 데이터의 형상도 달라질 것이다. 즉 패딩은 주로 출력 크기를 조정할 목적으로 사용한다. 예를 들어(4,4) 입력데이터에 (3,3) 필터를 적용하면 출력은 (2,2)가 되어 입력보다 2만큼 줄어든게 된다. 이는 합성곱 연산을 몇 번이나 되풀이하는 심층 신경망에서는 문제가 될 수 있다. | 합성곱 연산을 거칠 때마다 크기가 작아지면 어느 시점에서는 출력 크기가 1이 되어버린다. 더 이상은 합성곱 연산을 적용할 수 없다는 뜻이다. 이러한 사태를 막기 위해 패딩을 적용한다. | 이를 이용하여 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수 있다. | . | . | . 스트라이드 필터를 적용하는 위치의 간격을 스트라이드라고 한다. | 스트라이드를 2로 하면 필터를 적용하는 윈도우가 두 칸씩 이동한다. 그렇다면, 스트라이드를 키우면 출력의 크기는 작아진다. 한편, 패딩을 크게하면 출력 크기가 커졌었다. | 이러한 관계를 수식화한 234p를 참고해보자 | . | . | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/18/dl.html",
            "relUrl": "/2022/02/18/dl.html",
            "date": " • Feb 18, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "가중치 초깃값, 배치 정규화 등",
            "content": "은닉층의 활성화값(활성화 함수의 출력 데이터)의 분포를 관찰하면 중요한 정보를 얻을 수 있다. 가중치의 초깃값에 따라 은닉층 활성화값들이 어떻게 변화하는지 알아보자 | 활성화 함수로 시그모이드 함수를 사용하는 5층 신경망에 무작위로 생성한 입력 데이터를 흘리며 각 층의 활성화값 분포를 히스토그램으로 그려보자 | . | . import numpy as np import matplotlib.pyplot as plt def sigmoid(x): return 1 / (1 + np.exp(-x)) x = np.random.randn(1000, 100) # 1000개의 데이터 node_num = 100 # 각 은닉층의 노드(뉴런) 수 hidden_layer_size = 5 # 은닉층이 5개 activations = {} # 이곳에 활성화 결과를 저장 for i in range(hidden_layer_size): if i != 0: x = activations[i-1] w = np.random.randn(node_num, node_num) * 1 a = np.dot(x, w) z = sigmoid(a) activations[i] = z # 히스토그램 그리기 for i, a in activations.items(): plt.subplot(1, len(activations), i+1) plt.title(str(i+1) + &quot;-layer&quot;) if i != 0: plt.yticks([], []) # plt.xlim(0.1, 1) # plt.ylim(0, 7000) plt.hist(a.flatten(), 30, range=(0,1)) plt.show() . C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy _distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs: C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll warnings.warn(&#34;loaded more than 1 DLL from .libs:&#34; . 각 층의 활성화값들이 0과 1에 치우쳐 분포되어 있다. | 여기에서 사용한 시그모이드 함수는 그 출력이 0에 가까워지자 또는 1에 가까워지자 그 미분은 0에 다가간다. 그래서 데이터가 0과 1에 치우쳐 분포하게 되면 역전파의 기울기 값이 점점 작아지다가 사라진다. | 이것이 기울기 소실이다. | 이번에는 가중치의 표준편차를 0.01로 바꿔 같은 실험을 반복해보자 | . import numpy as np import matplotlib.pyplot as plt def sigmoid(x): return 1 / (1 + np.exp(-x)) x = np.random.randn(1000, 100) # 1000개의 데이터 node_num = 100 # 각 은닉층의 노드(뉴런) 수 hidden_layer_size = 5 # 은닉층이 5개 activations = {} # 이곳에 활성화 결과를 저장 for i in range(hidden_layer_size): if i != 0: x = activations[i-1] w = np.random.randn(node_num, node_num) * 0.01 a = np.dot(x, w) z = sigmoid(a) activations[i] = z # 히스토그램 그리기 for i, a in activations.items(): plt.subplot(1, len(activations), i+1) plt.title(str(i+1) + &quot;-layer&quot;) if i != 0: plt.yticks([], []) # plt.xlim(0.1, 1) # plt.ylim(0, 7000) plt.hist(a.flatten(), 30, range=(0,1)) plt.show() . 이번에는 0.5 부근에 집중되어 있다. 앞의 그래프처럼 0과 1에 치우치진 않았으니 기울기 소실 문제는 일어나지 않지만 활성화값들이 치우쳤다는 것은 표현력 관점에서는 큰 문제가 있는 것이다. | 즉, 다수의 뉴런이 거의 같은 값을 출력하고 있으니 뉴런을 여러 개 둔 의미가 없어진다는 뜻이다. | 예를 들어, 뉴런 100개가 거의 같은 값을 출력한다면 뉴런 1개짜리와 별반 다를 게 없는 것이다. | 그래서 활성화값들이 치우치면 표현력을 제한한다는 관점에서 문제가 된다. | 각 층의 활성화값은 적당히 고루 분포되어야 한다. 층과 층 사이에 적당하게 다양한 데이터가 흐르게 해야 신경망 학습이 효율적으로 이루어지기 때문이다. 치우친 데이터가 흐르면 기울기 소실이나 표현력 제한 문제에 빠져 학습이 잘 이루어지지 않을 수 있다. | . 권장되는 Xavier 초깃값을 써보자 이 초깃값을 사용하면 앞 층에 노드가 많을수록 대상 노드의 초깃값으로 설정하는 가중치가 좁게 퍼진다. | . | . import numpy as np import matplotlib.pyplot as plt def sigmoid(x): return 1 / (1 + np.exp(-x)) x = np.random.randn(1000, 100) # 1000개의 데이터 node_num = 100 # 각 은닉층의 노드(뉴런) 수 hidden_layer_size = 5 # 은닉층이 5개 activations = {} # 이곳에 활성화 결과를 저장 for i in range(hidden_layer_size): if i != 0: x = activations[i-1] w = np.random.randn(node_num, node_num) / np.sqrt(node_num) a = np.dot(x, w) z = sigmoid(a) activations[i] = z # 히스토그램 그리기 for i, a in activations.items(): plt.subplot(1, len(activations), i+1) plt.title(str(i+1) + &quot;-layer&quot;) if i != 0: plt.yticks([], []) # plt.xlim(0.1, 1) # plt.ylim(0, 7000) plt.hist(a.flatten(), 30, range=(0,1)) plt.show() . 층이 깊어지면서 형태가 다소 일그러지지만, 앞에서 본 방식보다는 확연히 넓게 분포되는 것을 알 수 있다. | 각 층에 흐르는 데이터는 적당히 퍼져 있으므로 시그모이드 함수의 표현력도 제한받지 않고, 학습이 효율적으로 이뤄질 것으로 기대할 수 있다. | . Xavier 초깃값을 활성화 함수가 선형인 것을 전제로 이끈 결과이다. 시그모이드 함수와 tanh 함수는 좌우 대칭이라 중앙 부근이 선형인 함수로 볼 수 있다. 그래서 Xavier 초깃값이 적당하다. | 반면 ReLU를 이용할 때는 ReLU에 특화된 초깃값을 이용하라고 권장한다. | 해당 초깃값을 He 초깃값이라 한다. | . import numpy as np import matplotlib.pyplot as plt def relu(x): return np.maximum(0,x) x = np.random.randn(1000, 100) # 1000개의 데이터 node_num = 100 # 각 은닉층의 노드(뉴런) 수 hidden_layer_size = 5 # 은닉층이 5개 activations = {} # 이곳에 활성화 결과를 저장 for i in range(hidden_layer_size): if i != 0: x = activations[i-1] w = np.random.randn(node_num, node_num) * np.sqrt(2) / np.sqrt(node_num) a = np.dot(x, w) z = relu(a) activations[i] = z # 히스토그램 그리기 for i, a in activations.items(): plt.subplot(1, len(activations), i+1) plt.title(str(i+1) + &quot;-layer&quot;) if i != 0: plt.yticks([], []) # plt.xlim(0.1, 1) # plt.ylim(0, 7000) plt.hist(a.flatten(), 30, range=(0,1)) plt.show() . He 초깃값은 모든 층에서 균일하게 분포되어 있다. | 층이 깊어져도 분포가 균일하게 유지되기에 역전파 때도 적절한 값이 나올 것으로 기대할 수 있다. | 따라서 활성화 함수로 ReLU를 사용할 때는 He 초깃값을, sigmoid마 tanh 등의 S자 모양 곡선일 때는 Xavier 초깃값을 쓴다. | . . MNIST 데이터셋으로 본 가중치 초깃값 비교 실제 데이터를 가지고 가중치의 초깃값을 주는 방법이 신경망 학습에 얼마나 영향을 주는지 알아보자 | . | . import os import sys sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정 import numpy as np import matplotlib.pyplot as plt from dataset.mnist import load_mnist from common.util import smooth_curve from common.multi_layer_net import MultiLayerNet from common.optimizer import SGD # 0. MNIST 데이터 읽기========== (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True) train_size = x_train.shape[0] batch_size = 128 max_iterations = 2000 # 1. 실험용 설정========== weight_init_types = {&#39;std=0.01&#39;: 0.01, &#39;Xavier&#39;: &#39;sigmoid&#39;, &#39;He&#39;: &#39;relu&#39;} optimizer = SGD(lr=0.01) networks = {} train_loss = {} for key, weight_type in weight_init_types.items(): networks[key] = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100], output_size=10, weight_init_std=weight_type) train_loss[key] = [] # 2. 훈련 시작========== for i in range(max_iterations): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] for key in weight_init_types.keys(): grads = networks[key].gradient(x_batch, t_batch) optimizer.update(networks[key].params, grads) loss = networks[key].loss(x_batch, t_batch) train_loss[key].append(loss) if i % 100 == 0: print(&quot;===========&quot; + &quot;iteration:&quot; + str(i) + &quot;===========&quot;) for key in weight_init_types.keys(): loss = networks[key].loss(x_batch, t_batch) print(key + &quot;:&quot; + str(loss)) # 3. 그래프 그리기========== markers = {&#39;std=0.01&#39;: &#39;o&#39;, &#39;Xavier&#39;: &#39;s&#39;, &#39;He&#39;: &#39;D&#39;} x = np.arange(max_iterations) for key in weight_init_types.keys(): plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key) plt.xlabel(&quot;iterations&quot;) plt.ylabel(&quot;loss&quot;) plt.ylim(0, 2.5) plt.legend() plt.show() . ===========iteration:0=========== std=0.01:2.302429797639348 Xavier:2.3026148669107496 He:2.277857804579289 ===========iteration:100=========== std=0.01:2.303292853997276 Xavier:2.234326172265587 He:1.5005924485044848 ===========iteration:200=========== std=0.01:2.301417343514494 Xavier:2.087924436660839 He:0.7067580473137639 ===========iteration:300=========== std=0.01:2.3013438187421946 Xavier:1.770500143384992 He:0.5602112129657093 ===========iteration:400=========== std=0.01:2.3014368742428744 Xavier:1.3176740433596514 He:0.3681439703994114 ===========iteration:500=========== std=0.01:2.3044005756657437 Xavier:0.9902237159385396 He:0.30892714112828057 ===========iteration:600=========== std=0.01:2.3030591310458215 Xavier:0.7526462154317728 He:0.40218584589549555 ===========iteration:700=========== std=0.01:2.3041291713479843 Xavier:0.586208347563391 He:0.3337892925219035 ===========iteration:800=========== std=0.01:2.303364952400675 Xavier:0.63464499915734 He:0.41187381352936203 ===========iteration:900=========== std=0.01:2.2975302040733254 Xavier:0.30952570462933804 He:0.16631918507970234 ===========iteration:1000=========== std=0.01:2.296942843621004 Xavier:0.3161938527906491 He:0.18967482624871215 ===========iteration:1100=========== std=0.01:2.2994930233988304 Xavier:0.3459259879231751 He:0.26021137128760713 ===========iteration:1200=========== std=0.01:2.2992459071770277 Xavier:0.34298167086324327 He:0.2288704138513741 ===========iteration:1300=========== std=0.01:2.304113865320631 Xavier:0.35294921013770564 He:0.18997185815254125 ===========iteration:1400=========== std=0.01:2.298613076761841 Xavier:0.4594074014741365 He:0.27355975550609296 ===========iteration:1500=========== std=0.01:2.2987149901527157 Xavier:0.35297086572944764 He:0.2800627974265304 ===========iteration:1600=========== std=0.01:2.302619261878843 Xavier:0.29813585576266644 He:0.19331724426040525 ===========iteration:1700=========== std=0.01:2.309549447205139 Xavier:0.3326361965668827 He:0.2399589526449093 ===========iteration:1800=========== std=0.01:2.301983183071444 Xavier:0.26631561315403807 He:0.1804474045819951 ===========iteration:1900=========== std=0.01:2.2996949081037243 Xavier:0.38827001458299426 He:0.24350341698182332 . std = 0.01일 때는 학습이 전혀 이루어지지 않고 있다. 순전파 때 너무 작은 값(0 근처로 밀집한 데이터)이 흐르기 때문이다. 그로 인해 역전파 때의 기울기도 작아져 가중치가 거의 갱신되지 않는 것이다. | . | He 초깃값이나 Xavier의 경우 학습이 순조롭게 이뤄지고 있음을 알 수 있다. 다만 학습 진도는 He 초깃값 쪽이 더 빠르다. | . | . . 배치 정규화 각 층이 활성화를 적당히 퍼뜨리도록 강제해보자 1) 학습을 빨리 진행할 수 있다. | 2) 초깃값에 크게 의존하지 않는다. | 3) 오버피팅을 억제한다. | . | 데이터 분포를 정규화하는 배치 정규화 계층을 신경망에 삽입한다. | . | . 미니배치 B라는 m개의 입력 데이터의 집합에 대해 평군과 분산을 구한다. | 그리고 입력 데이터를 평균이 0 분산이 1이 되게 정규화한다. | 미니배치 입력 데이터를 평균 0, 분산 1인 데이터로 변환해주는 처리를 활성화 함수의 앞 혹은 뒤에 삽입함으로써 데이터 분포가 덜 치우치게 할 수 있다. | 또, 배치 정규화 계층마다 이 정규화된 데이터 대한 고유한 확대와 이동 변환을 수행한다. (수식은 교재 212p를 참고한다. ) | . 해당 배치 정규화의 알고리즘이 신경망에서 순전파 때 적용된다. | . MNIST 데이터 셋을 사용하여 배치 정규화 계층을 사용할 때와 사용하지 않을 때의 학습 진도가 어떻게 달라지는지 살펴보자 | . import sys, os sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정 import numpy as np import matplotlib.pyplot as plt from dataset.mnist import load_mnist from common.multi_layer_net_extend import MultiLayerNetExtend from common.optimizer import SGD, Adam (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True) # 학습 데이터를 줄임 x_train = x_train[:1000] t_train = t_train[:1000] max_epochs = 20 train_size = x_train.shape[0] batch_size = 100 learning_rate = 0.01 def __train(weight_init_std): bn_network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10, weight_init_std=weight_init_std, use_batchnorm=True) network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10, weight_init_std=weight_init_std) optimizer = SGD(lr=learning_rate) train_acc_list = [] bn_train_acc_list = [] iter_per_epoch = max(train_size / batch_size, 1) epoch_cnt = 0 for i in range(1000000000): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] for _network in (bn_network, network): grads = _network.gradient(x_batch, t_batch) optimizer.update(_network.params, grads) if i % iter_per_epoch == 0: train_acc = network.accuracy(x_train, t_train) bn_train_acc = bn_network.accuracy(x_train, t_train) train_acc_list.append(train_acc) bn_train_acc_list.append(bn_train_acc) print(&quot;epoch:&quot; + str(epoch_cnt) + &quot; | &quot; + str(train_acc) + &quot; - &quot; + str(bn_train_acc)) epoch_cnt += 1 if epoch_cnt &gt;= max_epochs: break return train_acc_list, bn_train_acc_list # 그래프 그리기========== weight_scale_list = np.logspace(0, -4, num=16) x = np.arange(max_epochs) for i, w in enumerate(weight_scale_list): print( &quot;============== &quot; + str(i+1) + &quot;/16&quot; + &quot; ==============&quot;) train_acc_list, bn_train_acc_list = __train(w) plt.subplot(4,4,i+1) plt.title(&quot;W:&quot; + str(w)) if i == 15: plt.plot(x, bn_train_acc_list, label=&#39;Batch Normalization&#39;, markevery=2) plt.plot(x, train_acc_list, linestyle = &quot;--&quot;, label=&#39;Normal(without BatchNorm)&#39;, markevery=2) else: plt.plot(x, bn_train_acc_list, markevery=2) plt.plot(x, train_acc_list, linestyle=&quot;--&quot;, markevery=2) plt.ylim(0, 1.0) if i % 4: plt.yticks([]) else: plt.ylabel(&quot;accuracy&quot;) if i &lt; 12: plt.xticks([]) else: plt.xlabel(&quot;epochs&quot;) plt.legend(loc=&#39;lower right&#39;) plt.show() . ============== 1/16 ============== epoch:0 | 0.099 - 0.112 epoch:1 | 0.097 - 0.129 . C: Users ehfus Downloads DeepLearning deep-learning-from-scratch-master ch06 .. common multi_layer_net_extend.py:104: RuntimeWarning: overflow encountered in square weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2) C: Users ehfus Downloads DeepLearning deep-learning-from-scratch-master ch06 .. common multi_layer_net_extend.py:104: RuntimeWarning: invalid value encountered in double_scalars weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2) C: Users ehfus Downloads DeepLearning deep-learning-from-scratch-master ch06 .. common functions.py:34: RuntimeWarning: invalid value encountered in subtract x = x - np.max(x, axis=0) . epoch:2 | 0.097 - 0.166 epoch:3 | 0.097 - 0.178 epoch:4 | 0.097 - 0.181 epoch:5 | 0.097 - 0.195 epoch:6 | 0.097 - 0.218 epoch:7 | 0.097 - 0.238 epoch:8 | 0.097 - 0.245 epoch:9 | 0.097 - 0.251 epoch:10 | 0.097 - 0.285 epoch:11 | 0.097 - 0.3 epoch:12 | 0.097 - 0.316 epoch:13 | 0.097 - 0.331 epoch:14 | 0.097 - 0.339 epoch:15 | 0.097 - 0.351 epoch:16 | 0.097 - 0.366 epoch:17 | 0.097 - 0.382 epoch:18 | 0.097 - 0.393 . No handles with labels found to put in legend. . epoch:19 | 0.097 - 0.401 ============== 2/16 ============== epoch:0 | 0.097 - 0.092 epoch:1 | 0.097 - 0.102 . C: Users ehfus Downloads DeepLearning deep-learning-from-scratch-master ch06 .. common multi_layer_net_extend.py:104: RuntimeWarning: overflow encountered in square weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2) C: Users ehfus Downloads DeepLearning deep-learning-from-scratch-master ch06 .. common multi_layer_net_extend.py:104: RuntimeWarning: invalid value encountered in double_scalars weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2) . epoch:2 | 0.097 - 0.125 epoch:3 | 0.097 - 0.16 epoch:4 | 0.097 - 0.197 epoch:5 | 0.097 - 0.222 epoch:6 | 0.097 - 0.236 epoch:7 | 0.097 - 0.267 epoch:8 | 0.097 - 0.284 epoch:9 | 0.097 - 0.316 epoch:10 | 0.097 - 0.343 epoch:11 | 0.097 - 0.357 epoch:12 | 0.097 - 0.372 epoch:13 | 0.097 - 0.387 epoch:14 | 0.097 - 0.401 epoch:15 | 0.097 - 0.423 epoch:16 | 0.097 - 0.442 epoch:17 | 0.097 - 0.46 . No handles with labels found to put in legend. . epoch:18 | 0.097 - 0.465 epoch:19 | 0.097 - 0.479 ============== 3/16 ============== epoch:0 | 0.098 - 0.092 epoch:1 | 0.361 - 0.13 epoch:2 | 0.488 - 0.165 epoch:3 | 0.605 - 0.183 epoch:4 | 0.674 - 0.207 epoch:5 | 0.717 - 0.254 epoch:6 | 0.78 - 0.297 epoch:7 | 0.813 - 0.324 epoch:8 | 0.831 - 0.371 epoch:9 | 0.867 - 0.4 epoch:10 | 0.905 - 0.439 epoch:11 | 0.903 - 0.466 epoch:12 | 0.919 - 0.498 epoch:13 | 0.935 - 0.529 epoch:14 | 0.941 - 0.551 epoch:15 | 0.949 - 0.566 epoch:16 | 0.958 - 0.585 epoch:17 | 0.967 - 0.613 epoch:18 | 0.967 - 0.626 epoch:19 | 0.971 - 0.643 . No handles with labels found to put in legend. . ============== 4/16 ============== epoch:0 | 0.099 - 0.099 epoch:1 | 0.207 - 0.093 epoch:2 | 0.367 - 0.183 epoch:3 | 0.484 - 0.242 epoch:4 | 0.569 - 0.285 epoch:5 | 0.623 - 0.336 epoch:6 | 0.661 - 0.389 epoch:7 | 0.689 - 0.44 epoch:8 | 0.726 - 0.493 epoch:9 | 0.743 - 0.538 epoch:10 | 0.763 - 0.569 epoch:11 | 0.771 - 0.613 epoch:12 | 0.782 - 0.638 epoch:13 | 0.797 - 0.672 epoch:14 | 0.818 - 0.689 epoch:15 | 0.839 - 0.711 epoch:16 | 0.841 - 0.73 epoch:17 | 0.857 - 0.746 epoch:18 | 0.869 - 0.766 epoch:19 | 0.866 - 0.781 . No handles with labels found to put in legend. . ============== 5/16 ============== epoch:0 | 0.091 - 0.101 epoch:1 | 0.101 - 0.167 epoch:2 | 0.111 - 0.277 epoch:3 | 0.121 - 0.395 epoch:4 | 0.122 - 0.532 epoch:5 | 0.136 - 0.597 epoch:6 | 0.155 - 0.642 epoch:7 | 0.177 - 0.688 epoch:8 | 0.185 - 0.726 epoch:9 | 0.195 - 0.746 epoch:10 | 0.219 - 0.772 epoch:11 | 0.231 - 0.789 epoch:12 | 0.242 - 0.8 epoch:13 | 0.232 - 0.813 epoch:14 | 0.248 - 0.822 epoch:15 | 0.24 - 0.837 epoch:16 | 0.254 - 0.844 epoch:17 | 0.253 - 0.851 epoch:18 | 0.265 - 0.863 epoch:19 | 0.263 - 0.873 . No handles with labels found to put in legend. . ============== 6/16 ============== epoch:0 | 0.114 - 0.123 epoch:1 | 0.117 - 0.169 epoch:2 | 0.117 - 0.356 epoch:3 | 0.117 - 0.52 epoch:4 | 0.117 - 0.633 epoch:5 | 0.16 - 0.692 epoch:6 | 0.14 - 0.74 epoch:7 | 0.117 - 0.771 epoch:8 | 0.117 - 0.785 epoch:9 | 0.117 - 0.816 epoch:10 | 0.117 - 0.829 epoch:11 | 0.117 - 0.843 epoch:12 | 0.117 - 0.854 epoch:13 | 0.117 - 0.873 epoch:14 | 0.117 - 0.885 epoch:15 | 0.117 - 0.9 epoch:16 | 0.117 - 0.911 epoch:17 | 0.137 - 0.921 . No handles with labels found to put in legend. . epoch:18 | 0.204 - 0.927 epoch:19 | 0.144 - 0.932 ============== 7/16 ============== epoch:0 | 0.117 - 0.094 epoch:1 | 0.117 - 0.31 epoch:2 | 0.117 - 0.617 epoch:3 | 0.117 - 0.744 epoch:4 | 0.117 - 0.802 epoch:5 | 0.116 - 0.843 epoch:6 | 0.117 - 0.862 epoch:7 | 0.117 - 0.893 epoch:8 | 0.117 - 0.912 epoch:9 | 0.117 - 0.926 epoch:10 | 0.117 - 0.942 epoch:11 | 0.117 - 0.952 epoch:12 | 0.117 - 0.957 epoch:13 | 0.117 - 0.962 epoch:14 | 0.117 - 0.968 epoch:15 | 0.117 - 0.975 epoch:16 | 0.117 - 0.981 epoch:17 | 0.117 - 0.986 epoch:18 | 0.117 - 0.988 . No handles with labels found to put in legend. . epoch:19 | 0.117 - 0.989 ============== 8/16 ============== epoch:0 | 0.092 - 0.094 epoch:1 | 0.099 - 0.441 epoch:2 | 0.105 - 0.622 epoch:3 | 0.117 - 0.737 epoch:4 | 0.117 - 0.788 epoch:5 | 0.117 - 0.838 epoch:6 | 0.117 - 0.869 epoch:7 | 0.117 - 0.899 epoch:8 | 0.116 - 0.937 epoch:9 | 0.116 - 0.961 epoch:10 | 0.117 - 0.971 epoch:11 | 0.117 - 0.982 epoch:12 | 0.117 - 0.988 epoch:13 | 0.117 - 0.991 epoch:14 | 0.117 - 0.994 epoch:15 | 0.117 - 0.996 epoch:16 | 0.117 - 0.998 epoch:17 | 0.117 - 0.998 epoch:18 | 0.117 - 0.999 . No handles with labels found to put in legend. . epoch:19 | 0.117 - 1.0 ============== 9/16 ============== epoch:0 | 0.093 - 0.104 epoch:1 | 0.117 - 0.563 epoch:2 | 0.117 - 0.701 epoch:3 | 0.117 - 0.788 epoch:4 | 0.117 - 0.891 epoch:5 | 0.116 - 0.931 epoch:6 | 0.117 - 0.955 epoch:7 | 0.117 - 0.974 epoch:8 | 0.117 - 0.988 epoch:9 | 0.117 - 0.991 epoch:10 | 0.117 - 0.993 epoch:11 | 0.117 - 0.993 epoch:12 | 0.117 - 0.995 epoch:13 | 0.117 - 0.998 epoch:14 | 0.117 - 0.999 epoch:15 | 0.117 - 0.999 epoch:16 | 0.117 - 1.0 epoch:17 | 0.117 - 1.0 epoch:18 | 0.117 - 1.0 . No handles with labels found to put in legend. . epoch:19 | 0.117 - 1.0 ============== 10/16 ============== epoch:0 | 0.116 - 0.097 epoch:1 | 0.117 - 0.406 epoch:2 | 0.117 - 0.622 epoch:3 | 0.117 - 0.691 epoch:4 | 0.117 - 0.845 epoch:5 | 0.117 - 0.904 epoch:6 | 0.116 - 0.96 epoch:7 | 0.117 - 0.964 epoch:8 | 0.116 - 0.977 epoch:9 | 0.117 - 0.984 epoch:10 | 0.117 - 0.976 epoch:11 | 0.117 - 0.995 epoch:12 | 0.117 - 0.995 epoch:13 | 0.117 - 0.996 epoch:14 | 0.117 - 0.997 epoch:15 | 0.117 - 0.998 epoch:16 | 0.117 - 0.999 epoch:17 | 0.117 - 0.999 . No handles with labels found to put in legend. . epoch:18 | 0.117 - 0.999 epoch:19 | 0.117 - 0.999 ============== 11/16 ============== epoch:0 | 0.116 - 0.099 epoch:1 | 0.117 - 0.465 epoch:2 | 0.117 - 0.626 epoch:3 | 0.117 - 0.733 epoch:4 | 0.117 - 0.736 epoch:5 | 0.117 - 0.772 epoch:6 | 0.117 - 0.758 epoch:7 | 0.117 - 0.785 epoch:8 | 0.117 - 0.801 epoch:9 | 0.117 - 0.796 epoch:10 | 0.117 - 0.798 epoch:11 | 0.117 - 0.801 epoch:12 | 0.117 - 0.811 epoch:13 | 0.117 - 0.806 epoch:14 | 0.117 - 0.898 epoch:15 | 0.117 - 0.896 epoch:16 | 0.117 - 0.902 epoch:17 | 0.117 - 0.901 epoch:18 | 0.117 - 0.898 . No handles with labels found to put in legend. . epoch:19 | 0.117 - 0.974 ============== 12/16 ============== epoch:0 | 0.117 - 0.17 epoch:1 | 0.105 - 0.424 epoch:2 | 0.116 - 0.375 epoch:3 | 0.117 - 0.701 epoch:4 | 0.117 - 0.765 epoch:5 | 0.117 - 0.829 epoch:6 | 0.117 - 0.84 epoch:7 | 0.117 - 0.853 epoch:8 | 0.117 - 0.82 epoch:9 | 0.117 - 0.863 epoch:10 | 0.117 - 0.883 epoch:11 | 0.117 - 0.876 epoch:12 | 0.117 - 0.88 epoch:13 | 0.117 - 0.864 epoch:14 | 0.117 - 0.877 epoch:15 | 0.117 - 0.811 epoch:16 | 0.117 - 0.843 epoch:17 | 0.117 - 0.873 epoch:18 | 0.117 - 0.886 epoch:19 | 0.117 - 0.834 . No handles with labels found to put in legend. . ============== 13/16 ============== epoch:0 | 0.097 - 0.252 epoch:1 | 0.097 - 0.455 epoch:2 | 0.117 - 0.415 epoch:3 | 0.117 - 0.588 epoch:4 | 0.117 - 0.593 epoch:5 | 0.117 - 0.603 epoch:6 | 0.117 - 0.606 epoch:7 | 0.117 - 0.603 epoch:8 | 0.116 - 0.624 epoch:9 | 0.116 - 0.657 epoch:10 | 0.116 - 0.636 epoch:11 | 0.116 - 0.647 epoch:12 | 0.116 - 0.638 epoch:13 | 0.116 - 0.631 epoch:14 | 0.116 - 0.68 epoch:15 | 0.116 - 0.701 epoch:16 | 0.116 - 0.72 epoch:17 | 0.116 - 0.743 epoch:18 | 0.116 - 0.762 . No handles with labels found to put in legend. . epoch:19 | 0.116 - 0.802 ============== 14/16 ============== epoch:0 | 0.097 - 0.1 epoch:1 | 0.117 - 0.337 epoch:2 | 0.117 - 0.445 epoch:3 | 0.117 - 0.46 epoch:4 | 0.117 - 0.498 epoch:5 | 0.117 - 0.504 epoch:6 | 0.117 - 0.52 epoch:7 | 0.117 - 0.511 epoch:8 | 0.117 - 0.518 epoch:9 | 0.117 - 0.521 epoch:10 | 0.117 - 0.558 epoch:11 | 0.117 - 0.602 epoch:12 | 0.117 - 0.598 epoch:13 | 0.117 - 0.568 epoch:14 | 0.117 - 0.594 epoch:15 | 0.117 - 0.592 epoch:16 | 0.117 - 0.593 epoch:17 | 0.117 - 0.616 epoch:18 | 0.117 - 0.612 epoch:19 | 0.117 - 0.623 . No handles with labels found to put in legend. . ============== 15/16 ============== epoch:0 | 0.117 - 0.147 epoch:1 | 0.105 - 0.346 epoch:2 | 0.105 - 0.389 epoch:3 | 0.105 - 0.419 epoch:4 | 0.105 - 0.412 epoch:5 | 0.116 - 0.431 epoch:6 | 0.116 - 0.438 epoch:7 | 0.116 - 0.48 epoch:8 | 0.116 - 0.469 epoch:9 | 0.116 - 0.589 epoch:10 | 0.116 - 0.593 epoch:11 | 0.116 - 0.658 epoch:12 | 0.116 - 0.604 epoch:13 | 0.116 - 0.658 epoch:14 | 0.116 - 0.664 epoch:15 | 0.116 - 0.566 epoch:16 | 0.116 - 0.685 epoch:17 | 0.116 - 0.705 . No handles with labels found to put in legend. . epoch:18 | 0.116 - 0.633 epoch:19 | 0.116 - 0.712 ============== 16/16 ============== epoch:0 | 0.117 - 0.171 epoch:1 | 0.117 - 0.218 epoch:2 | 0.117 - 0.313 epoch:3 | 0.117 - 0.309 epoch:4 | 0.117 - 0.305 epoch:5 | 0.117 - 0.336 epoch:6 | 0.117 - 0.409 epoch:7 | 0.117 - 0.423 epoch:8 | 0.117 - 0.415 epoch:9 | 0.117 - 0.419 epoch:10 | 0.117 - 0.422 epoch:11 | 0.117 - 0.42 epoch:12 | 0.117 - 0.421 epoch:13 | 0.117 - 0.419 epoch:14 | 0.117 - 0.407 epoch:15 | 0.117 - 0.431 epoch:16 | 0.117 - 0.438 epoch:17 | 0.117 - 0.446 epoch:18 | 0.117 - 0.437 epoch:19 | 0.117 - 0.367 . 거의 모든 경우에서 배치 정규화를 사용할 때의 학습 진도가 빠른 것을 볼 수 있다. | 배치 정규화를 이용하지 않는 경우엔 초깃값이 잘 분포되어 있지 않으면 학습이 전혀 진행되지 않는 모습도 확인할 수 있다. | . . 기계학습에서는 오버피팅이 문제가 되는 경우가 많다. 오버피팅이란 신경망이 훈련 데이터에만 지나치게 적응되어 그 외의 데이터에는 제대로 대응하지 못하는 상태를 말한다. 범용 성능을 갖지 못하는 것이다. | 오버피팅의 경우 1) : 매개변수가 많고 표현력이 높은 모델 | 오버피팅의 경우 2) : 훈련 데이터가 적을 때 | . | . . 오버피팅 억제 가중치 감소 : 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 페널티를 부과하여 오버피팅을 억제하는 방법이다. 원래 오버피팅은 가중치 매개변수의 값이 커서 발생하는 경우가 많기 때문이다. | . | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/17/dl.html",
            "relUrl": "/2022/02/17/dl.html",
            "date": " • Feb 17, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "학습 관련 기술들",
            "content": "매개변수 갱신 신경망 학습의 목적은 손실 함수의 값을 가능한 한 낮추는 매개변수를 찾는 것이었다. 즉 매개변수의 최적값을 찾는 문제이며, 이러한 문제를 푸는 것을 최적화라 한다. 우리는 지금까지 최적의 매개변수 값을 찾는 단서로 매개변수의 기울기(미분)를 이용했다. 매개변수의 기울기를 구해, 기울어진 방향으로 매개변수 값을 갱신하는 일을 몇 번이고 반복해서 점점 최적의 값에 다가갔다. 이것이 확률적 경사 하강법(SGD)이란 방법이다. 가장 크게 기울어진 방향으로 가자는 것이 SGD의 전략이다. | SGD를 복습해보자 | . | . class SGD : def __init__(self,lr=0.01): self.lr=lr # 학습률은 인스턴스 변수로 유지한다. def update(self, params, grads): # params, grads는 딕셔너리 변수이다. for key in params.keys(): params[key] -= self.lr * grads[key] . SGD의 단점 : 문제에 따라서는 비효율적일 수 있다. 다음 함수의 최솟값을 구하는 문제를 생각해보자 | $f(x,y) = frac{1}{20} x^2 + y^2$ | 다음 함수의 기울기를 그려보면 | | y축 방향은 크고 x축 방향은 작다는 것이 특징이다. 말하자면 y축 방향은 가파른 반면 x축 방향은 완만한 것이다. | 또 주의할 점은 해당 식이 최솟값이 되는 장소는 (0,0)이지만, 기울기 대부분은 (0,0)을 가리키지 않고 있다. | 해당 함수에 SGD를 적용해보자 | 탐색을 시작하는 장소(초깃값)는 (x,y)=(-7,2)로 한다. 그러면 SGD는 심하게 요동치며 최소점을 향해 찾아가는 상당히 비효율적인 움직임을 보여준다. | 즉 SGD의 단점은 비등방성 함수(방향에 따라 성질, 즉 여기에서는 기울기가 달라지는 함수)에서는 탐색 경로가 비효율적이라는 것이다. | 이럴때는 SGD와 같이 무작정 기울어진 방향으로 진행하는 단순한 방식보다 더 영리한 묘안을 강구해야 한다. | 또한 SGD가 지그재그로 탐색하는 근본 원인은 기울어진 방향이 본래의 최솟값과 다른 방향을 가리켜서라는 점도 생각해볼 필요가 있다. | 이제 이러한 단점을 개선해보자 | . . 모멘텀 : 운동량을 뜻한다. | $v = alpha v - eta frac{ partial L}{ partial W}$ | 기울기 방향으로 힘을 받아 물체가 가속된다는 물리 법칙을 나타낸다. | $ alpha v$항은 물체가 아무런 힘을 받지 않을 때 서서히 하강시키는 역할을 한다. 여기서 $ alpha$는 0.9등의 값으로 설정한다. 물리에서의 지면 마찰이나 공기 저항에 해당한다. | $W = W + v$ | 여기서 v라는 새로운 변수는 물리에서 말하는 속도에 해당한다. | . class Momentum: def __init__(self, lr=0.01, momentum=0.9): self.lr = lr self.momentum = momentum self.v = None def update(self, params, grads): if self.v is None: self.v = {} for key, val in params.items(): self.v[key] = np.zeros_like(val) for key in params.keys(): self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] params[key] += self.v[key] . 그림에서 보듯 모멘텀의 갱신 경로는 공이 그릇 바닥을 구르듯 움직인다. | SGD와 비교하면 지그재그 정도가 덜한 것을 알 수 있다. | 이는 x축의 힘은 아주 작지만 방향은 변하지 않아서 한 방향으로 일정하게 가속하기 때문이다. | 반면 y축의 힘은 크지만 위아래로 번갈아 받아서 상충하여 y축 방향의 속도는 안정적이지 않다. | 전체적으로 SGD보다 x축 방향으로 빠르게 다가가 지그재그 움직임이 줄어든다. | . . AdaGrad 학습률을 정하는 효과적 기술로 학습률 감소가 있다. 이는 학습을 진행하면서 학습률을 점차 줄여가는 방법이다. 처음에는 크게 학습하다가 조금씩 작게 학습한다는 것으로 실제 신경망 학습에 자주 쓰인다. | 학습률을 서서히 낮추는 가장 간단한 방법은 매개변수 전체의 학습률 값을 일괄적으로 낮추는 것이다. 이를 더욱 발전시킨 것이 AdaGrad이다. AdaGrad는 각각의 매개변수에 맞춤형 값을 만들어준다. AdaGrad는 개별 매개변수에 적응적으로 학습률을 조정하면서 학습을 진행한다. | 자세한 수식은 197p를 참고하자, 학습률 감소가 매개변수의 원소마다 다르게 적용된다. | 과거의 기울기를 제곱하여 계속 더해간다. 그래서 학습을 진행할수록 갱신 강도가 약해진다. 실제로 무한히 계속 학습한다면 어느 순간 갱신량이 0이 되어 전혀 갱신되지 않게 된다. 이 문제를 개선한 기법으로 RMSProp이 있다. | . | . class AdaGrad: def __init__(self, lr=0.01): self.lr = lr self.h = None def update(self, params, grads): if self.h is None: self.h = {} for key, val in params.items(): self.h[key] = np.zeros_like(val) for key in params.keys(): self.h[key] += grads[key] * grads[key] params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7) . AdaGrad를 사용해서 최적화 문제를 풀어보면 결과는 전과는 상이하게 최솟값을 향해 효율적으로 움직이는 것을 알 수 있다. | y축의 방향은 기울기가 커서 처음에는 크게 움직이지만, 그 큰 움직임에 비례해 갱신 정도도 큰 폭으로 작아지도록 조정된다. 그래서 y축 방향으로 갱신 강도가 빠르게 약해지고, 지그재그 움직임이 줄어든다. | . . Adam 모멘텀은 공이 그릇 바닥을 구르는 듯한 움직임을 보였다. AdaGrad는 매개변수의 원소마다 적응적으로 갱신 정도를 조정했다. | 그렇다면 이 두 기법을 응용하면 어떻게 될까. 이것이 바로 Adam이다. | Adam 갱신 과정도 (Momentum)그릇 바닥을 구르듯 움직인다. 모멘텀과 비슷한 패턴인데, 모멘텀때보다 공의 좌우 흔들림이 적다. 이는 (Adagrad) 학습의 갱신 강도를 적응적으로 조정해서 얻는 혜택이다. | . | . 지금까지 SGD, 모멘텀, Adagrad, Adam 매개변수의 갱신 방법 4가지에 대해 알아봤다. | 갱신 경로만 보면 요동치는 정도가 가장 적은 AdaGrad가 가장 나은 것 같은데 사실 이 결과는 풀어야 할 문제가 무엇이냐에 따라 달라지므로 주의해야 한다. | . . MNIST 데이터셋으로 본 갱신 방법 비교 손글씨 숫자 인식을 대상으로 지금까지 설명한 네 기법을 비교해보자 | . | . import os import sys sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정 import matplotlib.pyplot as plt from dataset.mnist import load_mnist from common.util import smooth_curve from common.multi_layer_net import MultiLayerNet from common.optimizer import * # 0. MNIST 데이터 읽기========== (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True) train_size = x_train.shape[0] batch_size = 128 max_iterations = 2000 # 1. 실험용 설정========== optimizers = {} optimizers[&#39;SGD&#39;] = SGD() optimizers[&#39;Momentum&#39;] = Momentum() optimizers[&#39;AdaGrad&#39;] = AdaGrad() optimizers[&#39;Adam&#39;] = Adam() #optimizers[&#39;RMSprop&#39;] = RMSprop() networks = {} train_loss = {} for key in optimizers.keys(): networks[key] = MultiLayerNet( input_size=784, hidden_size_list=[100, 100, 100, 100], output_size=10) train_loss[key] = [] # 2. 훈련 시작========== for i in range(max_iterations): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] for key in optimizers.keys(): grads = networks[key].gradient(x_batch, t_batch) optimizers[key].update(networks[key].params, grads) loss = networks[key].loss(x_batch, t_batch) train_loss[key].append(loss) if i % 100 == 0: print( &quot;===========&quot; + &quot;iteration:&quot; + str(i) + &quot;===========&quot;) for key in optimizers.keys(): loss = networks[key].loss(x_batch, t_batch) print(key + &quot;:&quot; + str(loss)) # 3. 그래프 그리기========== markers = {&quot;SGD&quot;: &quot;o&quot;, &quot;Momentum&quot;: &quot;x&quot;, &quot;AdaGrad&quot;: &quot;s&quot;, &quot;Adam&quot;: &quot;D&quot;} x = np.arange(max_iterations) for key in optimizers.keys(): plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key) plt.xlabel(&quot;iterations&quot;) plt.ylabel(&quot;loss&quot;) plt.ylim(0, 1) plt.legend() plt.show() . C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy _distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs: C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll warnings.warn(&#34;loaded more than 1 DLL from .libs:&#34; . ===========iteration:0=========== SGD:2.4245769818085576 Momentum:2.346583857109649 AdaGrad:2.1283048286868858 Adam:2.2080398770776695 ===========iteration:100=========== SGD:1.5691069268871414 Momentum:0.29373629355944125 AdaGrad:0.13642667512271506 Adam:0.21445109796790202 ===========iteration:200=========== SGD:0.8166887158281744 Momentum:0.21159000564075253 AdaGrad:0.08534754183867585 Adam:0.14871188875325708 ===========iteration:300=========== SGD:0.5927395240643325 Momentum:0.20364796646558878 AdaGrad:0.09084197008327988 Adam:0.13585210467729422 ===========iteration:400=========== SGD:0.45543570314422704 Momentum:0.21066776035884405 AdaGrad:0.10310908134025634 Adam:0.1846534875661896 ===========iteration:500=========== SGD:0.4027826266352906 Momentum:0.221139535021391 AdaGrad:0.08556882267214833 Adam:0.21073625455382072 ===========iteration:600=========== SGD:0.33404005434414336 Momentum:0.09804773058593517 AdaGrad:0.056309395962392664 Adam:0.08948393377128226 ===========iteration:700=========== SGD:0.34693488522351895 Momentum:0.07545772179885256 AdaGrad:0.043922483552253214 Adam:0.07964291275332695 ===========iteration:800=========== SGD:0.33573942138910273 Momentum:0.23839737607949812 AdaGrad:0.10292067394041546 Adam:0.1935787287396677 ===========iteration:900=========== SGD:0.20438899943713784 Momentum:0.0523520726209493 AdaGrad:0.03101552525304059 Adam:0.051509911698420105 ===========iteration:1000=========== SGD:0.1922428945493172 Momentum:0.07907356221358142 AdaGrad:0.05871374836697205 Adam:0.07451081744780795 ===========iteration:1100=========== SGD:0.2658194643136783 Momentum:0.08210573686090676 AdaGrad:0.02537673880760616 Adam:0.024366772338120537 ===========iteration:1200=========== SGD:0.1462742320820858 Momentum:0.029192949210851783 AdaGrad:0.013672443982969618 Adam:0.03675634293185297 ===========iteration:1300=========== SGD:0.2528114695501593 Momentum:0.06433625244291916 AdaGrad:0.01876255590535962 Adam:0.033767862377853355 ===========iteration:1400=========== SGD:0.3783286559947407 Momentum:0.0744831102590841 AdaGrad:0.05366499026128387 Adam:0.04769333537464324 ===========iteration:1500=========== SGD:0.19357250699181133 Momentum:0.03237601523485906 AdaGrad:0.0191261105894449 Adam:0.028462431288655072 ===========iteration:1600=========== SGD:0.19182541384300544 Momentum:0.03857226153669857 AdaGrad:0.014562516415530913 Adam:0.027793526442153157 ===========iteration:1700=========== SGD:0.22812540265627623 Momentum:0.11054587069579386 AdaGrad:0.04519680624854676 Adam:0.0837270248673069 ===========iteration:1800=========== SGD:0.1863568618844701 Momentum:0.03897395551247439 AdaGrad:0.028702095570500324 Adam:0.024345535136644385 ===========iteration:1900=========== SGD:0.27381809376928257 Momentum:0.1274323413676476 AdaGrad:0.08634600734703075 Adam:0.09503495193875286 . 결과를 보면 SGD의 학습 진도가 가장 느리다. | 일반적으로 SGD보다 다른 세 기법이 빠르게 학습하고 때로는 최종 정확도도 높게 나타난다. | . . 가중치의 초깃값 신경망 학습에서 특히 중요한 것이 가중치의 초깃값이다. 이번 절에서는 권장 초깃값에 대해 알아보자 | . | . 초깃값을 0으로 하면? 이제부터 오버피팅을 억제해 범용 성능을 높이는 테크닉인 가중치 감소 기법을 소개한다. | 가중치 감소 = 가중치 매개변수의 값이 작아지도록 학습하는 방법이다. 가중치 값을 작게 하여 오버피팅이 일어나지 않게 하는 것이다. | 가중치를 작게 만들고 싶으면 초깃값을 최대한 작은 값에서 시작하는 것이 정공법일텐데 그러면 0으로 시작하면 안 되나? 그러면 안 되는 이유는 정확히는 가중치를 균일한 값으로 설정해서는 안 된다. 그 이유는 바로 오차역전파법에서 모든 가중치의 값이 똑같이 갱신되기 때문이다. 예를 들어 2층 신경망에서 첫 번째와 두 번째 층의 가중치가 0이라고 가정하자. 그럼 순전파때는 입력층의 가중치가 0이기 때문에 두 번째 층의 뉴런에 모두 같은 값이 전달된다. 두 번째 층의 모든 뉴런에 같은 값이 입력된다는 것은 역전파 때 두 번째 층의 가중치가 모두 똑같이 갱신된다는 말이다. 그래서 가중치들은 같은 초깃값에서 시작하고 갱신을 거쳐도 여전히 같은 값을 유지하는 것이다. 이는 가중치를 여러 개 갖는 의미를 퇴색시킨다. 이 가중치가 고르게 되어버리는 상황을 막으려면 정확히는 가중치의 대칭적인 구조를 무너뜨리려면 초깃값을 무작위로 설정해야 한다. 0처럼 균일하게 설정하면 안 된다는 것이다. | . | . | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/16/dl.html",
            "relUrl": "/2022/02/16/dl.html",
            "date": " • Feb 16, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "연쇄 법칙과 역전파",
            "content": "역전파 : 국소적인 미분을 순방향과는 방대인 오른쪽에서 왼쪽으로 전달한다. 또한, 이런 국소적 미분을 전달하는 원리는 연쇄 법칙에 따른 것이다. 연쇄 법칙 : 합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다. 이것이 연쇄 법칙의 원리이다. | $ frac{ partial z}{ partial x} = frac{ partial z}{ partial t} frac{ partial t}{ partial x}$ | . | 역전파의 계산 절차는 신호 E에 노드의 국소적 미분을 곱한 후 다음 노드로 전달하는 것이다. 여기에서 말하는 국소적 미분은 순전파 때의 y=f(x) 계산의 미분을 구한다는 것이며, 이는 x에대한 y의 미분을 구한다는 뜻이다. | . 덧셈 노드의 역전파 역전파 때는 상류에서 전해진 미분에 1을 곱하여 하류로 흘린다. 즉, 덧셈 노드의 역전파는 1을 곱하기만 할 뿐이므로 입력된 값을 그대로 다음 노드로 보내게 된다. | . | 곱셈 노드의 역전파 상류의 값에 순전파 때의 입력 신호들을 서로 바꾼 값을 곱해서 하류로 보낸다. 서로 바꾼 값이란 순전파 때 x였다면 역전파에서는 y, 순전파 때 y였다면 역전파에서는 x로 바꾼다는 의미이다. | . | . 덧셈의 역전파에서는 상류의 값을 그대로 흘려보내서 순방향 입력 신호의 값을 필요하지 않았지만, 곱셈의 역전파는 순방향 입력 신호의 값이 필요하다. 그래서 곱셈 노드를 구현할 때는 순전파의 입력 신호를 변수에 저장해둔다. . 앞서 들었던 사과 쇼핑의 예를 들어보자 이 문제에서는 사과의 가격, 사과의 개수, 소비세라는 세 변수 각각이 최종 금액에 어떻게 영향을 주느냐를 풀고자 한다. 이는 사과 가격에 대한 지불 금액의 미분, 사과 개수에 대한 지불 금액의 미분, 소비세에 대한 지불 금액의 미분을 구하는 것에 해당한다. | 앞서 곱셈 노드의 역전파에서는 입력 신호를 서로 바꿔서 하류로 흘린다고 했다. 결과를 보면 사과 과격의 미분은 2.2, 사과 개수의 미분은 110, 소비세의 미분은 200이다. 이는 소비세와 사과 과격이 같은 양만큼 오르면 최종 금액에는 소비세가 200의 크기로 사과 과격이 2.2 크기로 영향을 준다고 해석할 수 있다. 단, 단위는 조심하여야 한다. | . | . . 지금까지 보아온 사과 쇼핑의 예를 파이썬으로 구현해보자 | . 먼저, 곱셈 계층부터 구현해보자 | . class MulLayer: # 곱셈 노드 def __init__(self): # 생성자 함수로써 인스턴스 변수인 x와 y를 초기화한다. self.x = None self.y = None def forward(self, x, y): # 순전파 self.x = x self.y = y out = x * y return out def backward(self, dout): # 역전파 dx = dout * self.y # x와 y를 바꾼다. dy = dout * self.x return dx, dy . 순전파에서는 x와 y를 인수로 받고 두 값을 곱해서 반환한다. 반면 역전파에서는 상류에서 넘어온 미분(dout)에 순전파 때의 값을 서로 바꿔 곱한 후 하류로 흘려보낸다. | 해당 클래스를 이용하여 사과 쇼핑 예시에서의 순전파를 구현해보자 | . apple = 100 apple_num = 2 tax = 1.1 # 계층들 mul_apple_layer = MulLayer() mul_tax_layer = MulLayer() # forward apple_price = mul_apple_layer.forward(apple, apple_num) price = mul_tax_layer.forward(apple_price, tax) print(int(price)) . 220 . 각 변수에 대한 미분은 backward()에서 구할 수 있다. | . dprice = 1 dapple_price, dtax = mul_tax_layer.backward(dprice) dapple, dapple_num = mul_apple_layer.backward(dapple_price) print(&quot;dApple:&quot;, dapple) print(&quot;dApple_num:&quot;, int(dapple_num)) print(&quot;dTax:&quot;, dtax) . dApple: 2.2 dApple_num: 110 dTax: 200 . backward() 호출 순서는 forward()때와는 반대이다. 또 backward()가 받는 인수는 순전파의 출력에 대한 미분이다. 가령 mul_apple_layer()라는 곱셈 계층은 순전파 때는 apple_price를 반환하지만 역전파 때는 apple_price의 미분 값인 dapple_price를 인수로 받는다. | . . 덧셈 계층을 구현해보자 | . class AddLayer: def __init__(self): pass # 덧셈 계층에서는 초기화가 필요없으니 pass처리 한다. def forward(self,x,y): out = x+y return out def backward(self, dout): dx = dout * 1 dy = dout * 1 return dx,dy . 전체적인 계산 그래프를 파이썬으로 구현해보자 | . apple = 100 apple_num = 2 orange = 150 orange_num = 3 tax = 1.1 # layer mul_apple_layer = MulLayer() mul_orange_layer = MulLayer() add_apple_orange_layer = AddLayer() mul_tax_layer = MulLayer() # forward apple_price = mul_apple_layer.forward(apple, apple_num) # (1) orange_price = mul_orange_layer.forward(orange, orange_num) # (2) all_price = add_apple_orange_layer.forward(apple_price, orange_price) # (3) price = mul_tax_layer.forward(all_price, tax) # (4) # backward dprice = 1 dall_price, dtax = mul_tax_layer.backward(dprice) # (4) dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) # (3) dorange, dorange_num = mul_orange_layer.backward(dorange_price) # (2) dapple, dapple_num = mul_apple_layer.backward(dapple_price) # (1) print(&quot;price:&quot;, int(price)) print(&quot;dApple:&quot;, dapple) print(&quot;dApple_num:&quot;, int(dapple_num)) print(&quot;dOrange:&quot;, dorange) print(&quot;dOrange_num:&quot;, int(dorange_num)) print(&quot;dTax:&quot;, dtax) . price: 715 dApple: 2.2 dApple_num: 110 dOrange: 3.3000000000000003 dOrange_num: 165 dTax: 650 . . 활성화 함수 계층을 구현해보자, 계산 그래프를 신경망에 적용해보자 ReUL 계층, 165p 참고. | . | . class Relu: def __init__(self): self.mask = None # 해당 클래스는 mask라는 인스턴스 변수를 갖는다. bool형 넘파이 배열로 사용될 것이다. def forward(self, x): self.mask = (x&lt;=0) out = x.copy() out[self.mask] = 0 return out def backward(self,dout): dout[self.mask] = 0 dx = sout return dx . import numpy as np x = np.array([[1,-0.5],[-2,3]]) print(x) print(&#39; n&#39;) mask = x&lt;=0 print(mask) . [[ 1. -0.5] [-2. 3. ]] [[False True] [ True False]] . 이제 sigmoid 함수를 구현해보자 +와 x노드 말고도 exp와 /노드도 필요하다. | 자세한 과정은 167p부터 169p를 참고하자 | . | . class Sigmoid: def __init__(self): self.out = None def forward(self, x): out = 1 / ( 1 + np.exp(-x)) self.out = out def backward(self, dout): dx = dout * (1 - self.out) * self.out return dx . 해당 구현에서는 순전파의 출력을 인스턴스 변수 out에 보관했다가, 역전파 계산 때 그 값을 사용하는 것이다. | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/12/dl.html",
            "relUrl": "/2022/02/12/dl.html",
            "date": " • Feb 12, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "클래스로 신경망 구현, 오차역 전파법",
            "content": "학습 알고리즘 구현하기 신경망 학습의 순서를 확인해보자 전제 : 신경망에는 적응 가능한 가중치와 편향이 이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 학습이라고 한다. 신경망 학습은 다음과 같이 4단계로 수행된다. | 1) 미니배치 : 훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수 값을 줄이는 것이 목표이다. | 2) 기울기 산출 : 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실함수의 값을 가장 작게 하는 방향을 제시한다. | 3) 매개변수 갱신 : 가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다. | 4) 반복 : 1~3단계를 반복한다. | . | 이것이 신경망 학습이 이루어지는 순서이다. 이는 경사 하강법으로 매개변수를 갱신하는 방법이며, 이때 데이터를 미니배치로 무작위로 선정하기 때문에 확률적 경사 하강법이라고 부른다. (이하 SGD) 확률적으로 무작위로 골라낸 데이터에 대해 수행하는 경사 하강법이라 의미이다. | . | 실제로 손글씨 숫자를 학습하는 신경망을 구현해보자 | 여기에서는 2층 신경망(은닉층이 1개인 네트워크)을 대상으로 MNIST 데이터셋을 사용하여 학습을 수행한다. | 처음에는 2층 신경망을 하나의 클래스로 구현하는 것부처 시작한다. | 이 클래스의 이름은 TwoLayerNet이다. | . import sys, os sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정 from common.functions import * from common.gradient import numerical_gradient class TwoLayerNet: def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01): # 가중치 초기화 self.params = {} self.params[&#39;W1&#39;] = weight_init_std * np.random.randn(input_size, hidden_size) self.params[&#39;b1&#39;] = np.zeros(hidden_size) self.params[&#39;W2&#39;] = weight_init_std * np.random.randn(hidden_size, output_size) self.params[&#39;b2&#39;] = np.zeros(output_size) def predict(self, x): W1, W2 = self.params[&#39;W1&#39;], self.params[&#39;W2&#39;] b1, b2 = self.params[&#39;b1&#39;], self.params[&#39;b2&#39;] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, W2) + b2 y = softmax(a2) return y # x : 입력 데이터, t : 정답 레이블 def loss(self, x, t): y = self.predict(x) return cross_entropy_error(y, t) def accuracy(self, x, t): y = self.predict(x) y = np.argmax(y, axis=1) t = np.argmax(t, axis=1) accuracy = np.sum(y == t) / float(x.shape[0]) return accuracy # x : 입력 데이터, t : 정답 레이블 def numerical_gradient(self, x, t): loss_W = lambda W: self.loss(x, t) grads = {} grads[&#39;W1&#39;] = numerical_gradient(loss_W, self.params[&#39;W1&#39;]) grads[&#39;b1&#39;] = numerical_gradient(loss_W, self.params[&#39;b1&#39;]) grads[&#39;W2&#39;] = numerical_gradient(loss_W, self.params[&#39;W2&#39;]) grads[&#39;b2&#39;] = numerical_gradient(loss_W, self.params[&#39;b2&#39;]) return grads . 앞에서 다룬 신경망의 순전파 처리 구현과 공통되는 부분이 많고, 새로운 내용은 딱히 없다. | 우선 이 클래스가 사용하는 변수와 메서드를 정리해보자 중요해보이는 것 일부만 작성하였으며 그 외의 것은 139p를 참고하자 params : 신경망의 매개변수를 보관하는 딕셔너리 변수(인스턴스 변수) | grads : 기울기 보관하는 딕셔너리 변수 (numerical_gradient() 메서드의 반환 값) | . | TwoLayerNet 클래스는 딕셔너리인 params와 grads를 인스턴스 변수로 갖는다. | 자세한 내용은 해당 교재를 참고하자. | 예를 하나 살펴보자 | . | . net = TwoLayerNet(input_size = 784, hidden_size= 100, output_size= 10) print(net.params[&#39;W1&#39;].shape) print(net.params[&#39;b1&#39;].shape) print(net.params[&#39;W2&#39;].shape) print(net.params[&#39;b2&#39;].shape) . (784, 100) (100,) (100, 10) (10,) . 이와 같이 params 변수에는 이 신경망에 필요한 매개변수가 모두 저장된다. 그리고 params 변수에 저장된 가중치 매개변수가 예측 처리(순방향 처리)에서 사용된다. 참고로 예측 처리는 다음과 같이 실행할 수 있다. | . x = np.random.rand(100,784) # 더미 입력 데이터 100장 분량 y = net.predict(x) . grads 변수에는 params 변수에 대응하는 각 매개변수의 기울기가 저장된다. 예를 들어 다음과 같이 numericla_gradient() 메서드를 사용해 기울기를 계산하면 grads 변수에 기울기 정보가 저장된다. | . x = np.random.rand(100,784) # 더미 입력 데이터 (100장 분량) t = np.random.rand(100,10) # 더미 정답 레이블 (100장 분량) grads = net.numerical_gradient(x,t) print(grads[&#39;W1&#39;].shape) print(grads[&#39;b1&#39;].shape) print(grads[&#39;W2&#39;].shape) print(grads[&#39;b2&#39;].shape) . (784, 100) (100,) (100, 10) (10,) . 이어서 TwoLayerNet 메서드를 살펴보자 우선 init : 메서드는 클래스를 초기화한다. (이 초기화 메서드는 TwoLayerNet을 생성할 때 불리는 메서드이다.) | 추가 : 신경망 학습은 시간이 오래 걸리니, 시간을 절약하려면 같은 결과를 훨씬 빠르게 얻을 수 있는 오차역전파법으로 각 매개변수의 손실 함수에 대한 기울기를 계산할 수 있다. 이는 다음장에서 학습할 것이다. | . | . 미니배치 학습 구현하기 신경망 학습 구현에는 앞에서 설명한 미니배치 학습을 활용한다. 미니배치 학습이란 훈련 데이터 중 일부를 무작위로 꺼내고, 그 미니배치에 대해서 경사법으로 매개변수를 갱신한다. | . | . import numpy as np import matplotlib.pyplot as plt from dataset.mnist import load_mnist from two_layer_net import TwoLayerNet # 데이터 읽기 (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True) network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) # 하이퍼파라미터 iters_num = 10000 # 반복 횟수를 적절히 설정한다. train_size = x_train.shape[0] batch_size = 100 # 미니배치 크기 learning_rate = 0.1 train_loss_list = [] for i in range(iters_num): # 미니배치 획득 batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] # 기울기 계산 #grad = network.numerical_gradient(x_batch, t_batch) grad = network.gradient(x_batch, t_batch) # 매개변수 갱신 for key in (&#39;W1&#39;, &#39;b1&#39;, &#39;W2&#39;, &#39;b2&#39;): network.params[key] -= learning_rate * grad[key] # 학습 경과 기록 loss = network.loss(x_batch, t_batch) train_loss_list.append(loss) . 여기서는 미니배치 크기를 100으로 했다. 즉, 매번 60000개의 훈련 데이터에서 임의로 100개의 데이터(이미지 데이터와 정답 레이블 데이터)를 추려낸다. 그리고 그 100개의 미니배치를 대상으로 확률적 경사 하강법을 수행해 매개변수를 갱신한다. 경사법에 의한 갱신 횟수(반복 횟수)를 10000번으로 설정하고 갱신할 때마다 훈련 데이터에 대한 손실함수를 계산하고 그 값을 배열에 추가한다. | 학습 횟수가 늘어가면서 손실 함수의 값이 줄어들고 이는 학습이 잘 이루어지고 있다는 뜻으로 신경망의 가중치 매개변수가 서서히 데이터에 적응하고 있음을 의미한다. 신경망이 학습하고 있는 것이다. 다시 말해 데이터를 반복해서 학습함으로써 최적 가중치 매개변수로 서서히 다가가고 있는 것이다. | . 하지만 정확히는 훈련 데이터의 미니배치에 대한 손실 함수의 값이다. 훈련 데이터의 손실 함수 값이 작아지는 것은 잘 학습하고 있다는 방증이지만 이 결과만으로는 다른 데이터셋에서도 비슷한 실력을 발휘할지는 확실하지 않다. | 신경망 학습에서는 훈련 데이터 외의 데이터를 올바르게 인식하는지를 확인해여 한다. 다른 말로 오버피팅을 일으키지 않는지 확인해야 한다. 오비피팅 되었다는 것은 예를 들어 훈련 데이터 포함된 이미지만 제대로 구분하고 그렇지 않은 이미지는 식별할 수 없다는 뜻이다. | 범용적인 능력의 평가를 위해, 훈련 데이터에 포함되지 않은 데이터를 사용해 평가해봐야 한다. 이를 위해 다음 구현에서는 학습 도중 정기적으로 훈련 데이터와 시험 데이터를 대상으로 정확도를 기록한다. 여기에서는 1에폭별로 훈련 데이터와 시험 데이터에 대한 정확도를 기록한다. 에폭은 하나의 단위이다. 1에폭은 학습에서 훈련 데이터를 모두 소진했을 때의 횟수에 해당한다. 예컨대 훈련 데이터 10000개를 100개의 미니배치로 학습할 경우, 확률적 경사 하강법을 100회 반복하면 모든 훈련 데이터를 소진한게 된다. 이 경우 100회가 1에폭이 된다. | . | . | . from dataset.mnist import load_mnist from two_layer_net import TwoLayerNet # 데이터 읽기 (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True) network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) # 하이퍼파라미터 iters_num = 10000 # 반복 횟수를 적절히 설정한다. train_size = x_train.shape[0] batch_size = 100 # 미니배치 크기 learning_rate = 0.1 train_loss_list = [] train_acc_list = [] test_acc_list = [] # 1에폭당 반복 수 iter_per_epoch = max(train_size / batch_size, 1) for i in range(iters_num): # 미니배치 획득 batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] # 기울기 계산 #grad = network.numerical_gradient(x_batch, t_batch) grad = network.gradient(x_batch, t_batch) # 매개변수 갱신 for key in (&#39;W1&#39;, &#39;b1&#39;, &#39;W2&#39;, &#39;b2&#39;): network.params[key] -= learning_rate * grad[key] # 학습 경과 기록 loss = network.loss(x_batch, t_batch) train_loss_list.append(loss) # 1에폭당 정확도 계산 if i % iter_per_epoch == 0: train_acc = network.accuracy(x_train, t_train) test_acc = network.accuracy(x_test, t_test) train_acc_list.append(train_acc) test_acc_list.append(test_acc) print(&quot;train acc, test acc | &quot; + str(train_acc) + &quot;, &quot; + str(test_acc)) . train acc, test acc | 0.09915, 0.1009 train acc, test acc | 0.7825666666666666, 0.7853 train acc, test acc | 0.8771333333333333, 0.8807 train acc, test acc | 0.8981166666666667, 0.9014 train acc, test acc | 0.9082833333333333, 0.9104 train acc, test acc | 0.9147, 0.9171 train acc, test acc | 0.9193, 0.9215 train acc, test acc | 0.92455, 0.9265 train acc, test acc | 0.9277166666666666, 0.9291 train acc, test acc | 0.9313833333333333, 0.9322 train acc, test acc | 0.93445, 0.9348 train acc, test acc | 0.9368333333333333, 0.9367 train acc, test acc | 0.939, 0.9385 train acc, test acc | 0.9403666666666667, 0.9408 train acc, test acc | 0.9431666666666667, 0.942 train acc, test acc | 0.9448, 0.9435 train acc, test acc | 0.94635, 0.9451 . 이 예에서는 1에폭마다 모든 훈련 데이터와 시험 데이터에 대한 정확도를 계산하고 그 결과를 기록한다. | 정확도를 1에폭마다 계산하는 이유는 for문 앞에서 매번 계산하기에는 시간이 오래 걸리고 또 그렇게까지 자주 기록할 필요도 없기 때문이다. | 앞의 코드로 얻은 결과를 그래프로 그려보자 | . markers = {&#39;train&#39;: &#39;o&#39;, &#39;test&#39;: &#39;s&#39;} x = np.arange(len(train_acc_list)) plt.plot(x, train_acc_list, label=&#39;train acc&#39;) plt.plot(x, test_acc_list, label=&#39;test acc&#39;, linestyle=&#39;--&#39;) plt.xlabel(&quot;epochs&quot;) plt.ylabel(&quot;accuracy&quot;) plt.ylim(0, 1.0) plt.legend(loc=&#39;lower right&#39;) plt.show() . 훈련 데이터에 대한 정확도를 실선으로 시험 데이터 에대한 정확도를 점선으로 그렸다. 보다시피 에폭이 진행될수록, 즉 학습이 진행될수록 훈련데이터와 시험데이터를 사용하고 평가한 정확도가 모두 좋아지고 있다. 또 두 정확도에는 차이가 없음을 알 수 있다. 다시 말해 이번 학습에서는 오버피팅이 일어나지 않았음을 알 수 있다. | . 만약 오버피팅이 일어난다면? 훈련이란 훈련 데이터에 대한 정확도를 높이는 방향으로 학습이 이루어지니 그 정확도는 에폭을 반복할 수록 높아진다. 반면 훈련 데이터에 지나치게 적응하면, 즉 오버피팅되면 훈련 데이터와는 다른 데이터를 보면 잘못된 판단을 하기 시작한다. 어느 순간부터 시험 데이터에 대한 정확도가 점차 떨어지기 시작한다는 뜻이다. 이 순간이 오버피팅이 시작되는 순간이다. 여기서 중요한 insight! $ to$ 이 순간을 포착해 학습을 중단하면 오버피팅을 효과적으로 예방할 수 있을 것이다. 이 기법을 조기 종료라 하며, 가중치 감소, 드롭 아웃과 함께 대표적인 오버피팅 예방법이다. | . | . 결론 기계학습에서 사용하는 데이터 셋은 훈련 데이터와 시험 데이터로 나눠 사용한다. | 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가한다. | 신경망 학습은 손실 함수를 지표로, 손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신한다. | 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복한다. | 아주 작은 값을 주었을 때의 차분으로 미분하는 것을 수치 미분이라고 한다. | 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있다. | 수치 미분을 이요한 계산에는 시간이 걸리지만, 그 구현은 간단하다. 한편, 다음 장에서 구현하는 다소 복잡한 오차역 전파법은 기울기를 고속으로 구할 수 있다. | . | . . 오차역 전파법 가중치 매개변수의 기울기 정확히는 가중치 매개변수에 대한 손실 함수의 기울기를 효율적으로 계산하는 오차역 전파법을 배워보자 | 오차역 전파법 이해하기 오차역 전파법을 수식으로도 이해할 수 있겠지만, 이번 장에서는 계산 그래프를 사용해서 시작적으로 이해해보자 | . | . | . 계산 그래프 계산 과정을 그래프로 나타낸 것이다. | 복수의 노드와 에지로 표현된다. 노드 사이의 직선을 에지라고 한다. | 간단한 문제부터 해결해보자 | . | . 문제 1) 현빈 군은 슈퍼에서 1개에 100원인 사과를 2개 샀다. 이때 지불 금액을 구하세요. 단, 소비세가 10% 부과된다. 계산 그래프는 계산 과정을 노드와 화살표(에지)로 표현한다. | 원안에 연산 내용을 적고 계산 결과를 화살표 위에 적어 각 노드의 계산 결과가 왼쪽에서 오른쪽으로 전해지게 한다. | 여기서는 원 대신 괄호로 대체한다. | (사과) $ to$ 100 $ to$ (x2) $ to$ 200 $ to$ (x1.1) $ to$ 220 | 처음에 사과의 100원이 x2 노드로 흐르고 200원이 되어 다음 노드(x1.1)로 전달된다. 이제 200원이 x1.1 노드를 거쳐 220원이 된다. | 따라서 이 계산 그래프에 따르면 최종 답은 220원이 된다. | 여기에서는 x2와 x1.1을 각각 하나의 연산으로 취급해 원 안에 표기했지만, 곱셈이 x만을 연산으로 생각할 수도 있다. 이렇게하면 다음과 같이 2와 1.1은 각각 사과의 개수와 소비세 변수가 되어 원밖에 표기하게 된다. | 사과 $ to$ 100 $ to$ (x) $ to$ 200 $ to$ (x) $ to$ 220 $ to$ | 이제 첫 번째 노드에 2가 대입되고 다음 노드에 1.1이 대입된다. | . | . 지금까지 살펴본 계산 그래프를 이용한 문제풀이는 다음 흐름으로 진행된다. 1) 계산 그래프를 구성한다. | 2) 그래프에서 계산을 왼쪽에서 오른쪽으로 진행한다. | 여기서 2번째 &#39;계산을 왼쪽에서 오른쪽으로 진행&#39;하는 단계를 순전파라고 한다. | 순전파의 반대 &#39;역전파&#39;도 존재할 것이다. 역전파는 이후에 미분을 계산할 때 중요한 역할을 한다. | . | . 계산 그래프의 특징 : 국소적(자신과 직접 관계된 작은 범위)계산을 전파함으로써 최종 결과를 얻는다. 국소적 계산은 결국 전체에서 어떤 일이 벌어지든 상관없이 자신과 관계된 정보만으로 결과를 출력할 수 있다는 점이다. | 국소적 계산? 가령 슈퍼마켓에서 사과 2개를 포함한 여러 식품을 구입하는 경우를 생각해보자. 여러 식품을 구입하여 총 금액이 3000원이 되었다 여기에서 ㅎ개심은 각 노드에서의 계산은 국소적 계산이라는 점이다. 가령 사과와 그 외의 물품 값을 더하는 계산 3000+200에서 3000이라는 숫자가 어떻게 계산되었느냐와는 상관없이 단지 두 숫자(3000과 200)를 더하면 된다는 뜻이다. 각 노드는 자신과 관련한 계산외에는 아무것도 신경 쓸 게 없다는 것이다. | 이처럼 계산 그래프는 국소적 계산에 집중한다. 전체 계산이 제아무리 복잡하더라도 각 단계에서 하는 일은 해당 노드의 국소적 계산이다. 국소적 계산은 단순하지만, 그 결과를 전달함으로써 전체를 구성하는 복잡한 계산을 해낼 수 있다. | 또한 계산 그래프는 중간 계산 결과를 모두 보관할 수 있다. | 또한 역절파를 통해 미분을 효율적으로 계산할 수 있다. 위에서 설명한 문제1)을 살펴보자 | 가령 사과 가격이 오르면 최종 금액에 어떤 영향을 끼치는지를 알고 싶다고 해보자. | 이는 사과 과격에 대한 지불 금액의 미분을 구하는 문제에 해당된다. 기호로 나타낸다면 x는 사과 값을, L을 지불 금액이라고 했을때 $ frac{ partial L}{ partial x}$을 구하는 것이다. | 위 미분 값은 사과 값이 아주 조금 올랐을 때 지불 금액이 얼마나 증가하느냐를 표시한 것이다. | 즉, 사과 과격에 대한 지불 금액의 미분 같은 값은 계산 그래프에서 역전파를 하면 구할 수 있다. | 역전파가 어떻게 이루어지느냐는 뒤에서 추가 설명하겠다. | . | . | . | . 이처럼 계산 그래프의 이점은 순전파와 역전파를 활용해서 각 변수의 미분을 효율적으로 구할 수 있다는 것이다. | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/10/dl.html",
            "relUrl": "/2022/02/10/dl.html",
            "date": " • Feb 10, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "수치 미분",
            "content": "경사법에서는 기울기 값을 기준으로 나아갈 방향을 정한다. | 함수를 미분하는 계산을 구현해보자 | . def numerical_diff(f,x): h = 1e-50 # 매우 작은 수, 소수점 아래 0이 50개 return (f(x+h) - f(x))/h . 위 함수에서 개선해야 할 점 1) 1e-50은 반올림 오차 문제를 일으킨다. 작은 값이 생략되어 최종 계산 결과에 오차가 생기게 하는 것이다. 예를 들면 | . | . import numpy as np np.float32(1e-50) . 0.0 . 미세한 값 h를 10-4 정도로 이용해보자. 10-4 정도의 값을 사용하면 좋은 결과를 얻는다고 알려져 있다. | 두 번째 개선 : 함수 f의 차분(임의의 두 점에서의 함수 값들의 차이)과 관련한 것이다. 위 함수에서는 x+h와 x사이의 함수f의 차분을 계산하고 있지만, 애당초 이 계산에는 오차가 있다는 사실에 주의해야 한다. | 진정한 미분은 x 위치의 함수의 기울기(이를 접선이라고 함)에 해당하지만, 이번 구현에서의 미분은 (x+h)와 x사이의 기울기에 해당한다 | 그래서 진정한 미분(진정한 접선)과 이번 구현의 값은 엄밀히는 일치하지 않는다. 이 차이는 h를 무한히 0으로 좁히는 것이 불가능해 생기는 한계이다. | . | . 수치 미분에는 오차가 포함된다. 이 오차를 줄이기 위해 (x+h)와 (x-h)일 때의 함수f의 차분을 계산하는 방법을 쓰기도 한다. | 해당 차분은 x를 중심으로 그 전후의 차분을 계산한다는 의미에서 중심 차분 혹은 중앙 차분이라고 한다. (x와 x+h의 차분은 전방 차분이라고 한다.) | . | 두 개선점을 적용해 수치 미분을 구현해보자 | . def numerical_diff(f,x): h = 1e-4 #0.0001 # 개선 1 return (f(x+h) - f(x-h)) / (2*h) # 2h = x+h-(x-h) =2h # 개선 2 . . 앞 절의 수치 미분을 사용하여 간단한 함수를 미분해보자 | . def function_1(x): return 0.01*x**2 + 0.1*x . import matplotlib.pyplot as plt x = np.arange(0.0,20.0,0.1) y = function_1(x) plt.xlabel(&#39;x&#39;) plt.ylabel(&#39;f(x)&#39;) plt.plot(x,y) plt.show() . 이제 x는 5일 때와 10일 때의 함수의 미분을 계산해보자 | . print(numerical_diff(function_1,5)) print(numerical_diff(function_1,10)) # 함수의 기울기에 해당한다. . 0.1999999999990898 0.2999999999986347 . . def tangent_line(f, x): d = numerical_diff(f, x) print(d) y = f(x) - d*x return lambda t: d*t + y fig, (ax1,ax2)= plt.subplots(1,2) x = np.arange(0.0, 20.0, 0.1) y = function_1(x) tf = tangent_line(function_1, 5) y2 = tf(x) ax1.plot(x, y) ax1.plot(x, y2) ax1.set_xlabel(&#39;x&#39;) ax1.set_ylabel(&#39;f(x)&#39;) tf = tangent_line(function_1, 10) y2 = tf(x) ax2.plot(x, y) ax2.plot(x, y2) ax2.set_xlabel(&#39;x&#39;) ax2.set_ylabel(&#39;f(x)&#39;) plt.show() . 0.1999999999990898 0.2999999999986347 . . 편미분 | . def function_2(x): return x[0]**2+x[1]**2 # 또는 return np.sum(x**2) . 앞의 예와 달리 변수가 2개이다 미분해보자 변수가 2개다 | 어느 변수에 대한 미분이냐가 중요하다 | 이와 같이 변수가 여럿인 함수에 대한 미분을 편미분이라고 한다. | $ frac{ partial f}{ partial x_0}$ | $ frac{ partial f}{ partial x_1}$ | . | . | . x_0 = 3, x_1 = 4 일 때, x_0에 대한 편미분을 구해보자 | . def function_tmp1(x0): return x0*x0 + 4**2 numerical_diff(function_tmp1,3) . 6.00000000000378 . def function_tmp2(x1): return 3**2 + x1*x1 numerical_diff(function_tmp2,4) . 7.999999999999119 . 변수가 하나인 함수를 정의하고, 그 함수를 미분하는 형태로 구현하여 풀었다. 예를 들어 문제 1에서는 x1=4로 고정된 새로운 함수를 정의하고 변수가 x0 하나뿐인 함수에 대해 이전에 정의해두었던 수치 미분 함수를 적용하였따. | 이처럼 편미분은 변수가 하나인 미분과 마찬가지로 특정 장소의 기울기를 구한다. | 단, 여러 변수 중 목표 변수 하나에 초점을 맞추고 다른 변수는 값을 고정한다. | 앞의 예에서는 목표 변수를 제외한 나머지를 특정 값에 고정하기 위해서 새로운 함수를 정의했다. | 그리고 그 새로이 정의한 함수에 대해 그동안 사용한 수치 미분 함수를 적용하여 편미분을 구한 것이다. | . | . . 기울기 위에선 x0와 x1에 대한 편미분 각각을 구했다. 이번엔 편미분을 묶어서 | ($ frac{ partial f}{ partial x_0}$, $ frac{ partial f}{ partial x_1}$) | 을 계산해본다고 해보자. 이때 ($ frac{ partial f}{ partial x_0}$, $ frac{ partial f}{ partial x_1}$)처럼 모든 변수의 편미분을 벡터로 정리한 것을 기울기라고 한다. | 구현해보자 | . | . def numerical_gradient(f,x): h = 1e-4 grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성 for idx in range(x.size): tmp_val = x[idx] # f(x+h) 계산 x[idx] = tmp_val + h fxh1 = f(x) # f(x-h) 계산 x[idx] = tmp_val - h fxh2 = f(x) grad[idx] = (fxh1 - fxh2) / (2*h) x[idx] = tmp_val # 값 복원 return grad . 좀 복잡해보이지만 동작 방식은 변수가 하나일 때의 수치 미분과 거의 동일하다 | . numerical_gradient(function_2,np.array([3.0,4.0])) . array([6., 8.]) . numerical_gradient(function_2,np.array([0.0,2.0])) . array([0., 4.]) . numerical_gradient(function_2,np.array([3.0,0.0])) . array([6., 0.]) . 아직은 잘 모르겠지만 numerical_gradient함수에 인수로 넘파이 배열 입력해줄 때, 소수형태가 아닌 int형태로 입력해주면 값이 현저히 달라짐 | 그런데 이 기울기가 의미하는 건 뭘까, 그림으로 그려서 이해해보자 기울기의 결과에 마이너스를 붙인 벡터를 그린것이다. | . | . 기울기 그림을 살펴보면 방향을 가진 벡터로 그려진다. | 기욹는 함수의 가장 낮은 장소(최솟값)를 가리키는 것 같다. | 또 가장 낮은 곳(최솟값)에서 멀어질수록 화살표의 크기가 커짐을 알 수 있다. | 위 그림에서 기울기는 가장 낮은 장소를 가리킨다. 실제는 반드시 그렇다고는 할 수 없다. | 사실 기울기는 각 지점에서 낮아지는 방향을 가리킨다. #### 더 정확히 말하자면 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향이다 | (※ 매우중요) | . | . . 경사법(경사 하강법) 기계학습 문제 대부분은 학습 단계에서 최적의 매개변수를 찾아낸다. 신경망 역시 최적의 매개변수(가중치와 편향)를 학습 시에 찾아야 한다. 여기에서 최적이란 손실 함수가 최솟값이 될 때의 매개변수 값이다. 이런 상황에서 기울기를 잘 이용해 함수의 최소값(또는 가능한 한 작은 값)을 찾으려는 것이 경사법이다. | 여기에서 주의할 점은 각 지점에서 함수의 값을 낮추는 방안을 제시하는 지표가 기울기라는 것이다. 그렇지만 기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지, 즉 그쪽이 정말로 나아갈 방향인지는 보장할 수 없다. 실제로 복잡한 함수에서는 기울기가 가리키는 방향에 최솟값이 없는 경우가 대부분이다. | . | 기울어진 방향이 꼭 최솟값을 가리키는 것은 아니나, 그 방향으로 가야 함수의 값을 줄일 수 있다. | 그래서 최솟값이 되는 장소를 찾는 문제, 아니면 가능한 한 작은 값이 되는 장소를 찾는 문제에서는 기울기 정보를 단서로 나아갈 방향을 정해야 한다. | . | . 경사법 : 현 위치에서 기울어진 방향으로 일정 거리만큼 이동한다. 그런 다음 이동한 곳에서도 마찬가지로 기울기를 구하고, 또 그 기울어진 방향으로 나아가기를 반복한다. 이렇게 해서 함수의 값을 줄이는 것이 경사법이다. 경사법은 기계학습을 최적화하는 데 흔히 쓰는 방법이다. 특히 신경망에서는 경사법을 많이 사용한다. | . 경사법을 수식으로 나타내보자 $x_0 = x_0 - eta frac{ partial f}{ partial x_0}$ | $x_1 = x_1 - eta frac{ partial f}{ partial x_1}$ | . | $ eta$는 갱신하는 양이다. 신경망 학습에서는 학습률이라고 한다. 한 번의 학습으로 얼마만큼 학습해야 할지, 즉 매개변수 값을 얼마나 갱신하느냐를 정하는 것이 학습률이다. | 위 식은 1회에 해당하는 갱신이고, 이 단계를 반복한다. | 위 단계를 반복하며 서서히 함수의 값을 줄이는 것이다. | 또한 학습률은 0.01 혹은 0.001 등 미리 특정한 값으로 정해두어야 하는데, 일반적으로 이 값이 너무 크거나 작으면 좋은 장소를 찾아갈 수 없다. 신경망 학습에서는 보통 이 학습률 값을 변경하면서 올바르게 학습하고 있는지를 확인하면서 진행한다. | . . 경사 하강법을 구현해보자 | . def gradient_descent(f,init_x,lr=0.01,step_num=100): x = init_x for i in range(step_num): grad = numerical_gradient(f,x) x-= lr*grad return x . f = 최적화하려는 함수 | init_x = 초깃값 | lr = 학습률 | step_num = 경사법에 따른 반복횟수 | . def function_2(x): return x[0]**2 +x[1]**2 init_x = np.array([-3.0,4.0]) gradient_descent(function_2,init_x=init_x,lr =0.1, step_num=100) . array([-6.11110793e-10, 8.14814391e-10]) . 초깃값을 (-3.0,4.0)으로 설정한 후 경사법을 사용해 최솟값 탐색을 시작한다. | 최종 결과는 거의 (0,0)에 가깝다. 실제로 진정한 최솟값을 (0,0)이므로 경사법으로 거의 정확한 결과를 얻은 것이다. | . . 학습률을 달리하여 해보자 | . init_x = np.array([-3.0,4.0]) gradient_descent(function_2,init_x=init_x,lr=10.0,step_num=100) . array([-2.58983747e+13, -1.29524862e+12]) . 너무 크게 했더니 큰 값으로 발산해버렸다 | . init_x = np.array([-3.0,4.0]) gradient_descent(function_2,init_x=init_x,lr=1e-10,step_num=100) . array([-2.99999994, 3.99999992]) . 너무 작게 했더니 거의 갱신하지 않고 끝났다 | . $ to$ 따라서 학습률을 적절히 설정하는 일은 중요하다 . 학습률과 같은 매개 변수를 하이퍼 파라미터라고 한다. 이는 가중치와 편향같은 신경망의 매개변수와는 성질이 다른 매개변수이다. 신경망의 가중치 매개변수는 훈련 데이터와 학습 알고리즘에 의해서 자동으로 획득되는 매개변수인 반면, 학습률 같은 하이퍼 파라미터는 사람이 직접 설정해야 하는 매개변수인 것이다. 일반적으로는 이 하이퍼파라미터들은 여러 후보 값 중에서 시험을 통해 가장 잘 학습하는 값을 찾는 과정을 거쳐야 한다. | . . 신경망에서의 기울기 여기서 말하는 기울기는 가중치 매개변수에 대한 손실 함수의 기울기이다. | . | . import sys, os sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정 import numpy as np from common.functions import softmax, cross_entropy_error from common.gradient import numerical_gradient class simpleNet: def __init__(self): self.W = np.random.randn(2,3) # 정규분포로 초기화 def predict(self, x): return np.dot(x, self.W) def loss(self, x, t): z = self.predict(x) y = softmax(z) loss = cross_entropy_error(y, t) return loss . simpleNet 클래스는 형상이 2x3인 가중치 매개변수 하나를 인스턴스 변수로 갖는다. | 메서드는 2개인데, 하나는 예측을 수행하는 predict이고 다른 하나는 손실 함수의 값을 구하는 loss이다. 여기서 x는 입력데이터, t는 정답 레이블이다. | . net = simpleNet() # 가중치 매개변수 print(net.W) x = np.array([0.6, 0.9]) p = net.predict(x) print(p) # 최댓값의 인덱스 print(np.argmax(p)) # 정답 레이블 t = np.array([0, 0, 1]) net.loss(x,t) . [[ 0.48129772 0.4062162 -0.31963495] [ 0.11586695 1.06101565 -0.79045592]] [ 0.39305889 1.19864381 -0.90319129] 1 . 2.5523095142122116 . 이어서 기울기를 구해보자 | . def f(W): return net.loss(x,t) dW = numerical_gradient(f, net.W) print(dW) . [[ 0.17086397 0.38239445 -0.55325842] [ 0.25629596 0.57359168 -0.82988764]] . 람다를 사용해 아래와 같이 구현할 수 있겠다 | . f = lambda w: net.loss(x, t) dW = numerical_gradient(f, net.W) print(dW) . [[ 0.17086397 0.38239445 -0.55325842] [ 0.25629596 0.57359168 -0.82988764]] . 신경망의 기울기를 구한 다음에는 경사법에 따라 가중치 매개변수를 갱신하기만 하면 된다. 다름 절에서는 2층 신경망을 대상으로 학습 과정 전체를 구현해보자 | 135p참고하기 | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/09/dl-Copy1.html",
            "relUrl": "/2022/02/09/dl-Copy1.html",
            "date": " • Feb 9, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "교차 엔트로피 오차",
            "content": "데이터에서 학습한다 : 가중치 매개변수의 값을 데이터를 보고 자동으로 결정한다. | 이번 장에서는 신경망 학습(데이터로부터 매개변수의 값을 정하는 방법)에 대해 알아보고 파이썬으로 MNIST 데이터셋의 손글씨 숫자를 학습하는 코드를 구현해보자 | . . 데이터 주도 학습 신경망과 딥러닝은 기존 기계학습에서 사용하던 방법보다 사람의 개입을 더욱 배제할 수 있게 해주는 중요한 특성을 지녔다. 구체적 예 &gt; 가령 이미지에서 &#39;5&#39;라는 숫자를 인식하는 프로그램을 구현한다고 해보자. 주어진 데이터를 잘 활용해서 해결해야 한다. 이런 방법의 하나로서 이미지에서 특징을 추출하고 그 특징의 패턴을 기계학습 기술로 학습하는 방법이 있다. 여기서 말하는 특징은 입력 데이터(입력 이미지)에서 본질적인 데이터(중요 데이터)를 정확하게 추출할 수 있도록 설계된 변환기를 가리킨다. 이미지의 특징은 보통 벡터로 기술한다. 이미지 데이터를 벡터로 변환하고, 변환된 벡터를 가지고 지도 학습 방식의 대표 분류 기법인 SVM,KNN등으로 학습할 수 있다. | 다만, 이미지를 벡터로 변환할 때 사용하는 특징은 여전히 사람이 설계한다. | 즉, 특징과 기계학습을 활용한 접근에도 문제에 따라서는 사람이 적절한 특징을 생각해내야 하는 것이다. | 반면 신경망 방식은 사람이 개입하지 않는 블록 하나로 이루어진다. | 신경망은 이미지를 있는 그대로 학습한다. 신경망은 이미지에 포함된 중요한 특징까지도 기계가 스스로 학습한다. 따라서 종단간 기계학습이라고 딥러닝을 부르기도 한다. | . | . | . 신경망도 하나의 지표를 기준으로 최적의 매개변수 값을 탐색한다. 신경망 학습에서 사용하는 지표는 손실 함수라고도 한다. 이 손실 함수는 임의의 함수를 사용할 수도 있지만 일반적으로는 오차제곱합과 교차 엔트로피 오차를 사용한다. | 오차 제곱합은 각 원소의 출력(추정 값)과 정답 레이블(참 값)의 차를 제곱한 후, 그 총합을 구한다. 파이썬으로 구현해보자 | . import numpy as np def sum_squares_error(y,t): return 0.5 * np.sum((y-t)**2) . 여기서 인수 y와 t는 넘파이 배열이다. | . t = [0,0,1,0,0,0,0,0,0,0] y = [0.1,0.05,0.6,0,0.05,0.1,0,0.1,0,0] sum_squares_error(np.array(y), np.array(t)) . 0.09750000000000003 . sum(y) # 해당 예는 정답도 2이고 예측도 2일 확률이 0.6으로 가장 높다고 했음 . 1.0 . y = [0.1,0.05,0.1,0,0.05,0.1,0,0.6,0,0] sum_squares_error(np.array(y),np.array(t)) . 0.5975 . sum(y) # 해당 예는 정답은 똑갑이 2이지만 예측은 6일 확률이 0.6으로 가장 높다고 했음 . 1.0 . 즉, 첫 번째 예의 손실 함수 쪽 출력이 작으며 정답 레이블과의 오차도 작은 것을 알 수 있다. | 오차제곱합 기준으로는 첫 번째 추정 결과가 (오차가 더 작으니) 정답에 더 가까울 것으로 판단할 수 있다. | . . 교차 엔트로피 오차 실질적으로 정답일 때의 추정의 자연로그를 계산하는 식이 된다. | 즉, 교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 정하게 된다. | 정답에 해당하는 출력이 커질수록 0에 다가가다가, 그 출력이 1일 때, 0이 된다. | 반대로 정답일 때의 출력이 작아질수록 오차는 커진다. | . | . import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&#39;ignore&#39;) x=np.arange(0,1,0.01) plt.plot(x,np.log(x)) plt.title(&#39;y=log(x)&#39;) . Text(0.5, 1.0, &#39;y=log(x)&#39;) . def cross_entropy_error(y,t): delta = 1e-7 # np.log 함수에 0을 입력하면 마이너스 무한대를 뜻하는 -inf가 되어 더 이상 계산할 수 없기에 아주 작은 값인 delta를 더해줌. return -np.sum( t*np.log(y+delta)) . t = [0,0,1,0,0,0,0,0,0,0] y = [0.1,0.05,0.6,0,0.05,0.1,0,0.1,0,0] cross_entropy_error(np.array(y),np.array(t)) . 0.510825457099338 . y = [0.1,0.05,0.1,0,0.05,0.6,0,0.1,0,0] cross_entropy_error(np.array(y),np.array(t)) . 2.302584092994546 . 첫 번째 예는 정답일 때의 출력이 0.6인 경우로 이때의 교차 엔트로피 오차는 약 0.51이다. | 다음은 정답일 때의 출력이 0.1인 경우로 이 때의 교차 엔트로피 오차는 무려 2.3이다. | 즉, 결과(오차 값)가 더 작은 첫 번째 추정이 정답일 가능성이 높다고 판단한 것으로, 앞서 오차제곱합의 판단과 일치한다. | . . 지금까지는 데이터 하나에 대한 손실 함수만 생각했으니, 이제 훈련 데이터 모두에 대한 손실함수의 합을 구하는 방법에 대해 생각해보자 | 빅데이터 수준의 수백만, 수천만개의 수준에서는 데이터 일부를 추려 전체의 근사치로 이용할 수 있다. 이 일부를 미니배치라고 한다. 가령 60000장의 훈련 데이터 중에서 100장을 무작위로 뽑아 그 100장 만을 사용하여 학습하는 것이다. 이러한 학습을 미니배치 학습이라고 한다. | 미니배치 학습을 구현하는 코드를 작성해보자 | . | . import sys, os sys.path.append(os.pardir) from dataset.mnist import load_mnist (x_train,t_train),(x_test, t_test) = load_mnist(normalize=True, one_hot_label=True) print(x_train.shape) print(t_train.shape) . (60000, 784) (60000, 10) . 이 훈련 데이터에서 무작위로 10장만 빼내려면 어떻게 하면 될까. | . train_size = x_train.shape[0] batch_size = 10 batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] . np.random.choice(60000,10) . 의미 : 0이상 60000 미만의 수 중에서 무작위로 10개 골라낸다 | . 이제 무작위로 선택한 이 인덱스를 사용해 미니배치를 뽑아내기만 하면 된다. 손실함수도 이 미니배치로 계산한다. | . . 미니배치 같은 배치 데이터를 지원하는 교차 엔트로피 오차는 어떻게 구현할까 | 아래 셀은 데이터가 하나인 경우와 데이터가 배치로 묶여 입력된 경우 모두를 처리할 수 있도록 구현한 것이다. | . def cross_entropy_error(y,t): # y는 신경망의 출력, t는 정답레이블 if y.dim == 1: t = t.reshape(1, t.size) y = y.reshape(1, y.size) batch_size = y.shape[0] return -np.sum( t * np.log(y + 1e-7)) / batch_size . y(신경망의 출력)가 1차원이라면, 즉 데이터 하나당 교차 엔트로피 오차를 구하는 경우는 reshape함수로 데이터의 형상을 바꿔준다. | 정답 레이블이 원-핫 인코딩이 아니라 &#39;2&#39;나 &#39;7&#39;등의 숫자 레이블로 주어졌을 때의 교차 엔트로피 오차는 다음과 같이 구현할 수 있다. | . def cross_entropy_error(y,t): # y는 신경망의 출력, t는 정답레이블 if y.dim == 1: t = t.reshape(1, t.size) y = y.reshape(1, y.size) batch_size = y.shape[0] return -np.sum( np.log(y[np.arange(batach_size),t] + 1e-7)) / batch_size . 이 구현에서는 원-핫 인코딩일 때 t가 0인 원소는 교차 엔트로피 오차도 0이므로, 그 계산은 무시해도 좋다는 것이 핵심이다. | 다시 말하면 정답에 해당하는 신경망의 출력만으로 교차 엔트로피 오차를 계산할 수 있다. | . .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/08/dl.html",
            "relUrl": "/2022/02/08/dl.html",
            "date": " • Feb 8, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "소프트맥스, MNIST Data Set",
            "content": "소프트맥스 함수 분류에서 사용한다. | 소프트맥스의 출력은 모든 입력 신호로부터 화살표를 받는다. | 소프트맥스의 함수의 분모에서 볼 수 있듯, 촐력층의 각 뉴런이 모든 입력 신호에서 영향을 받기 때문이다. | 이상의 소프트맥스 함수를 구현해보자 | . | . import numpy as np a = np.array([0.3,2.9,4]) exp_a = np.exp(a) print(exp_a) sum_exp_a = np.sum(exp_a) print(sum_exp_a) y = exp_a / sum_exp_a print(y) . [ 1.34985881 18.17414537 54.59815003] 74.1221542101633 [0.01821127 0.24519181 0.73659691] . C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy _distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs: C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll warnings.warn(&#34;loaded more than 1 DLL from .libs:&#34; . 위 논리 흐름을 파이썬 함수로 정의하자 | . def softmax(a): exp_a = np.exp(a) sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y . 소프트맥스 함수 구현시 주의할 점 위에서 정의한 softmax() 함수의 코드는 컴퓨터로 계산할 때 결함이 있다. 바로 오버플로 문제이다. 소프트맥스 함수는 지수 함수를 사용하는데, 지수함수란 것이 쉽게 아주 큰 값을 내지만 컴퓨터는 다룰 수 있는 범위가 한정되어 있어 수치가 커짐에 따라 결과 수치가 불안정해질 수 있다. | 해결책 : 오버플로를 막기 위해 입력 신호 중 최댓값을 이용하여 지수 함수에서 빼준다. | 구현해보자 | . | . | . import warnings warnings.filterwarnings(&#39;ignore&#39;) a = np.array([1010,1000,990]) print(np.exp(a) / np.sum(np.exp(a))) c = np.max(a) np.exp(a-c) / np.sum(np.exp(a-c)) . [nan nan nan] . array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09]) . 위에서 볼 수 있듯, 아무런 조치 없이 그냥 계산하면 nan이 반환된다. | 하지만 입력 신호 중 최댓값을 빼주면 올바르게 계싼할 수 있다. | 이를 바탕으로 소프트맥스 함수를 다시 구현해보자 | . def softmax(a): c = np.max(a) exp_a = np.exp(a - c) # 이게 오버플로 대책이다. sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y . 소프트맥스 함수의 특징 | . a = np.array([0.3,2.9,4]) y = softmax(a) print(y) print(np.sum(y)) . [0.01821127 0.24519181 0.73659691] 1.0 . 즉, 소프트맥스 함수의 출력은 0에서 1사이의 실수이다. (그럴 수 밖에 없는 것이 소프트맥스 함수를 살펴보면 1을 넘을 수 없다) | 출력의 총합은 1이며 소프트맥스 함수의 중요한 성질이 된다. 이 성질 덕분에 소프트맥스 함수의 출력을 확률로 정의할 수 있다. | 즉, 소프트맥스 함수를 이용함으로써 문제를 확률적(통계적)으로 대응할 수 있게 되는것이다. | . | . . 출력층의 뉴런 수 정하기 출력층의 뉴런 수는 풀려는 문제에 맞게 적절히 정해야 한다. | 분류에서는 분류하고 싶은 클래스 수로 설정하는 것이 일반적이다. 예를 들어 입력 이미지를 숫자 0부터 9 중 하나로 분류하는 문제라면 출력층의 뉴런을 10개로 설정한다. | . | . | . 손글씨 숫자 인식 이번 절에서는 이미 학습된 매개변수(가중치, 편향(임계값))를 사용하여 학습 과정은 생략하고 추론 과정만 구현한다. | 이 추론 과정을 신경망의 순전파(forward propagation)라고도 한다. 머신러닝과 마찬가지로 신경망도 두 단계를 거쳐 문제를 해결한다. 먼저 훈련 데이터 즉, 학습 데이터를 사용해 가중치 매개변수를 학습하고 추론 단계에서는 앞서 학습한 매개변수를 사용하여 입력 데이터를 분류한다. | . | . | . MNIST data set 손글씨 숫자 이미지 집합 | MNIST의 이미지 데이터는 28 $ times$ 28 크기의 회색조 이미지이며 각 픽셀은 0에서 255까지의 값을 취한다. 각 이미지에는 또한 7,2,1과 같이 그 이미지가 실제 의미하는 숫자가 레이블로 붙어 있다. | . | . import sys,os sys.path.append(os.pardir) # 부모 디렉토리의 파일을 가져올 수 있도록 설정 from dataset.mnist import load_mnist (x_train, t_train),(x_test, t_test) = load_mnist(flatten = True, normalize = False) # 각 데이터 형상 출력해보자 print(x_train.shape) print(t_train.shape) print(x_test.shape) print(t_test.shape) . (60000, 784) (60000,) (10000, 784) (10000,) . 첫 번째 인수인 normalize는 입력 이미지의 픽셀값을 0~1 사이의 값으로 정규화할지를 정한다. | flatten은 입력 이미지를 평탄하게, 즉 1차원 배열로 만들지를 정한다. False로 설정하면 입력 이미지를 1 x 28 x 28의 3차원 배열로, True로 설정하면 784개의 원소로 이루어진 1차원 배열로 저장한다. | . | . . 참고) 파이썬에는 pickle이라는 편리한 기능이 있다. 이는 프로그램 실행 중에 특정 객체를 파일로 저장하는 기능이다. 저장해준 pickle 파일을 로드하면 실행 당시의 객체를 즉시 복원할 수 있다. MNIST 데이터셋을 읽는 load_mnist() 함수에서도 (2 번째 이후의 읽기 시에) pickle을 이용한다. pickle 덕분에 MNIST 데이터를 순식간에 준비할 수 있는 것이다. | . | . . MNIST 이미지를 화면으로 불러보도록 하자. | . import sys, os sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정 import numpy as np from dataset.mnist import load_mnist from PIL import Image def img_show(img): pil_img = Image.fromarray(np.uint8(img)) pil_img.show() (x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False) img = x_train[0] label = t_train[0] print(label) # 5 print(img.shape) # (784,) img = img.reshape(28, 28) # 형상을 원래 이미지의 크기로 변형 print(img.shape) # (28, 28) img_show(img) . 5 (784,) (28, 28) . 주의 flatten=True로 설정해 읽어 들인 이미지는 1차원 넘파이 배열로 저장돼 있다. 그래서 이미지를 표시할 땐 원래 형상인 28 x 28 크기로 다시 변형해야 한다. reshape() 메서드에 원하는 형상을 인수로 지정하면 넘파이 배열의 형상을 바꿀 수 있다. | 또한 넘파이로 저장된 이미지 데이터를 PIL용 데이터 객체로 변환해야 하며, 이 변환은 Image.fromarray()가 수행한다. | . | . . 신경망의 추론 처리 드디어 이 MNIST 데이터셋을 가지고 추론을 수행하는 신경망을 구현해보자 | 이 신경망은 입력층 뉴런을 784(28x28)개, 출력층 뉴련을 10개로 구성한다. | 한편, 은닉층은 총 두 개로, 첫 번째 은닉층에는 50개의 뉴런을 두 번째 은닉층에는 100개의 뉴런을 배치한다. 여기서 50과 100은 임의로 정한 값이다. | . | . import sys, os sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 import numpy as np import pickle from dataset.mnist import load_mnist from common.functions import sigmoid, softmax def get_data(): (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False) return x_test, t_test def init_network(): with open(&quot;sample_weight.pkl&quot;, &#39;rb&#39;) as f: network = pickle.load(f) return network def predict(network, x): w1, w2, w3 = network[&#39;W1&#39;], network[&#39;W2&#39;], network[&#39;W3&#39;] b1, b2, b3 = network[&#39;b1&#39;], network[&#39;b2&#39;], network[&#39;b3&#39;] a1 = np.dot(x, w1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, w2) + b2 z2 = sigmoid(a2) a3 = np.dot(z2, w3) + b3 y = softmax(a3) return y . init_network()에서는 pickle 파일인 sample_weight.pkl에 저장된 학습된 가중치 매개변수를 읽는다. 이 파일에는 가중치와 편향 매개변수가 딕셔너리 변수로 저장되어 있다. | 이제 이 세 함수를 이용해 신경망에 의한 추론을 수행해보고, 정확도(분류가 얼마나 올바른가)도 평가해보자 | . x, t = get_data() network = init_network() batch_size = 100 # 배치 크기 accuracy_cnt = 0 for i in range(0, len(x), batch_size): x_batch = x[i:i+batch_size] y_batch = predict(network, x_batch) p = np.argmax(y_batch, axis=1) accuracy_cnt += np.sum(p == t[i:i+batch_size]) print(&quot;Accuracy:&quot; + str(float(accuracy_cnt) / len(x))) . Accuracy:0.9352 . 또한 이 예에서는 load_mnist 함수의 인수인 normalize를 True로 설정했다. 이처럼 데이터를 특정 범위로 변환하는 처리를 정규화라 하고, 신경망의 입력 데이터에 특정 변환을 가하는 것을 전처리라 한다. 여기에서는 입력 이미지 데이터에 대한 전처리 작업으로 정규화를 수행한 셈이다. | . . 배치처리 입력 데이터와 가중치 매개변수의 형상에 주의하여 조금 전 구현을 다시 살펴보자 | 우선 앞서 구현한 신경망 각 층의 가중치 형상을 출력해보자 | . | . x,_ = get_data() network = init_network() W1,W2,W3 = network[&#39;W1&#39;], network[&#39;W2&#39;], network[&#39;W3&#39;] print(x.shape) print(x[0].shape) print(W1.shape) #1 print(W2.shape) #2 print(W3.shape) #3 . (10000, 784) (784,) (784, 50) (50, 100) (100, 10) . 이 결과에서 다차원 배열의 대응하는 차원의 수가 일치함을 확인할 수 있다. (교재 102p를 참고해보자) | . | 이는 이미지 데이터 1장만 입력했을 때의 데이터 처리 흐름이다. 그렇다면 이미지 여러 장을 한 번에 입력하는 경우를 생각해보자 가령 이미지 100개를 묶어 predict() 함수에 한 번에 넘기는 경우가 있다고 해보자. | x의 형상을 100x784fh qkRNjtj 100장 분량의 데이터를 하나의 입력 데이터로 표현하면 될 것이다. | 이때 입력 데이터의 형상은 100x784, 출력 데이터의 형상은 100x10이 된다. | 이는 100장 분량의 입력 데이터의 결과가 한 번에 출력됨을 나타낸다. | 가령 x[0]과 y[0]에는 0번째 이미지와 그 추론 결과가 저장되는 식이다. | 이처럼 하나로 묶은 입력 데이터를 배치(batch)라고 한다. 즉, 묶음을 의미하며 이미지가 지폐처럼 다발로 묶여 있다고 생각하면 된다. | . | . | . 배치 처리를 구현해보자 | . x, t = get_data() network = init_network() batch_size = 100 # 배치 크기 accuracy_cnt = 0 for i in range(0, len(x), batch_size): x_batch = x[i:i+batch_size] y_batch = predict(network, x_batch) p = np.argmax(y_batch, axis=1) # 100x10이라는 다차원에서 0번째 차원말고 1번째 차원에 접근하겠다. #?????????????? accuracy_cnt += np.sum(p == t[i:i+batch_size]) print(&quot;Accuracy:&quot; + str(float(accuracy_cnt) / len(x))) . Accuracy:0.9352 . . x = np.array([[3,2,1],[4,5,6]]) y = np.argmax(x,axis=1) print(y) . [0 2] . . 마지막으로 배치 단위로 분류한 결과를 실제 답과 비교한다. 이를 위해 ==연사자를 사용한다. | . y = np.array([1,2,1,0]) t = np.array([1,2,0,0]) print(y==t) np.sum(y==t) . [ True True False True] . 3 . 이런 식으로 구현하면 된다. | . . Conclusion . 이번 장에서는 신경망의 순전파를 살펴봤다. 이번 장에서 설명한 신경망은 각 층의 뉴런들이 다음 층의 뉴런으로 신호를 전달한다는 점에서 앞 장의 퍼셉트론과 같다. 하지만 다름 뉴런으로 갈 때, 신호를 변화시키는 활성화 함수에 큰 차이가 있었다. 신경망에서는 매끄럽게 변화하는 시그모이드 함수를, 퍼셉트론에서는 갑자기 변화하는 계단 함수를 활성화 함수로 사용했다. 이 차이가 신경망 학습에 중요하다. 다음 장에서 더욱 알아보도록 하자. .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/07/dl.html",
            "relUrl": "/2022/02/07/dl.html",
            "date": " • Feb 7, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "신경망",
            "content": "신경망을 통해 가중치 매개변수의 적절한 값을 데이터로부터 자동으로 학습하는 능력이 이제부터 살펴볼 신경망의 중요한 성질이다. | 신경망의 개요를 알아보고, 신경망이 입력 데이터가 무엇인지 식별하는 처리 과정을 자세히 알아보자. | . 퍼셉트론에서 신경망으로 . 입력층, 은닉층, 출력층으로 구성된다. | 이 중 은닉층의 뉴런은 사람 눈에는 보이지 않는다. | 뉴런이 연결되는 방식은 앞 장의 퍼셉트론과 달라진 것이 없다. | 차이점에 대해 알아보자 | . 활성화 함수 . 입력 신호의 총합을 출력 신호로 변환하는 함수를 일컫는다. | 활성화라는 이름이 말해주듯 활성화 함수는 입력 신호의 총합이 활성화를 일으키는지를 정하는 역할을 한다. | 임계값을 경계로 출력이 바뀌는데 이런 함수를 계단 함수라고 한다. | 그래서 퍼셉트론에서는 활성화 함수로 계단 함수를 이용한다라고 할 수 있다. | 즉 활성화 함수로 쓸 수 있는 여러 후보 중에서 퍼셉트론은 계단 함수를 채용하고 있다. | 그렇다면 계단 함수 이외의 함수를 사용하면 어떻게 될까. 사실 활성화 함수를 계단 함수에서 다른 함수로 변경하는 것이 신경망의 세계로 나아가는 열쇠이다. | 신경망에서 이용하는 활성화 함수를 알아보자 | . 신경망에서 자주 이용하는 활성화 함수인 시그모이드 함수를 알아보자 $ frac{1}{1+exp(-x)}$ | . | . 신경망에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하고, 그 변환된 신호를 다음 뉴런에 전달한다. | 앞 장에서본 퍼셉트론과 앞으로 볼 신경망의 주된 차이는 이 활성화 함수이다. | 계단 함수를 구현해보자 | . import numpy as np def step_function(x): if x&gt;0: return 1 else : return 0 . 인수 x는 실수만 받아들인다. 즉 step_function(3.0) 같은 것은 가능하지만 step_function(np.array([1,2]))는 안 된다. | 가능하도록 해보자 | . def step_function(x): y = x &gt; 0 return y.astype(np.int) . 아래 셀을 통해 위 함수를 이해해보자 | . x = np.array([-1,1,2]) y = x&gt;0 y . array([False, True, True]) . 이렇게 넘파이 배열에 부등호 연산을 수행하면 배열의 원소 각각에 부등호 연산을 수행한 bool 배열이 새로 생성되고 y라는 변수에 저장된다. | 그런데 우리가 원하는 계단 함수는 0이나 1의 int형을 출력하는 함수이기 때문에 아래 셀을 통해 변환하여 반환해주자 | . import warnings warnings.filterwarnings(&quot;ignore&quot;) y = y.astype(np.int) y . array([0, 1, 1]) . 이제 앞에서 정의한 계단 함수를 그래프로 그려보자 | . import matplotlib.pyplot as plt def step_function(x): return np.array(x&gt;0 , dtype=np.int) x = np.arange(-5,5,0.1) y = step_function(x) plt.plot(x,y) plt.ylim(-0.1,1.1) plt.show() . 시그모이드 함수를 구현해보자 | . def sigmoid(x): return 1/(1 + np.exp(-x)) x = np.array([-1,1,2]) sigmoid(x) . array([0.26894142, 0.73105858, 0.88079708]) . 시그모이드 함수를 그래프로 그려보자 | . x = np.arange(-5, 5, 0.1) y = sigmoid(x) plt.plot(x,y) plt.ylim(-0.1,1.1) plt.title(&#39;Sigmoid Function&#39;) plt.show() . 잡담 : 시그모이드란 &#39;S&#39;자 모양이라는 뜻이다. 계단 함수처럼 그 모양을 따 이름을 지은 것이다. &#39;S자 모양 함수&#39;라고도 부를 수 있다. | . . fig, (ax1,ax2) = plt.subplots(1,2) x = np.arange(-5,5,0.1) y = step_function(x) ax1.plot(x,y) ax1.set_title(&#39;Step Function&#39;) x = np.arange(-5, 5, 0.1) y = sigmoid(x) ax2.plot(x,y) ax2.set_title(&#39;Sigmoid Function&#39;) plt.show() . 비교 시그모이드 함수는 부드러운 곡선이며 입력에 따라 출력이 연속적으로 변한다. 한편 계단 함수는 0을 경계로 출력이 갑자기 바뀌어버린다. 시그모이드 함수의 이 매끈함이 신경망 학습에서 아주 중요한 역할을 한다. | 다시 말해 퍼셉트론에서는 뉴런 사이에 0 혹은 1이 흘렀다면 신경망에서는 연속적인 실수가 흐른다. | 공통점 : 둘 다 입력이 작을 때의 출력은 0에 가깝고 혹은 0이고 입력이 커지면 출력이 1에 가까워지는 혹은 1이 되는 구조이다. | 즉, 계단 함수와 시그모이드 함수는 입력이 중요하면 큰 값을 출력하고 입력이 중요하지 않으면 작은 값을 출력한다. | 그리고 입력이 아무리 작거나 커도 출력은 0에서 1 사이라는 것도 둘의 공통점이다. | 또한 둘다 비선형 함수이다. | . | . 신경망에서는 활성화 함수로 비선형 함수를 사용해야 한다. 선형 함수를 이용하면 신경망의 층을 깊게 하는 의미가 없어지기 때문이다. | . . 시그모이드 함수는 신경망 분야에서 오래전부터 이용해왔으나 최근에는 ReUL(Rectified Linear Unit) 렐루 함수를 주로 이용한다. | 렐루 함수는 입력이 0을 넘으면 그 입력을 그대로 출력하고 0 이하이면 0을 출력하는 함수이다. | . def relu(x): return np.maximum(0,x) x = np.arange(-6 ,6 ,0.1) y = relu(x) plt.plot(x,y) plt.ylim(-1,7) plt.show() . ReLU 함수도 활성화 함수로 이용할 수 있다. | . . 넘파이의 다차원 배열에 대해 간략히 알아보자 | . b = np.array([[1,2],[3,4],[5,6]]) b . array([[1, 2], [3, 4], [5, 6]]) . print(np.ndim(b)) print(np.shape(b)) . 2 (3, 2) . $3 times 2$ 배열이다. | 처음 차원에는 원소가 3개 다음 차원에는 원소가 2개 들어있다는 의미이다. | 이때 처음 차원은 0번째 차원, 다음 차원은 1번째 차원에 대응한다. 2차원 배열은 행렬이라고 부르고 가로방향을 행, 세로방향을 열이라고 부른다. | . | . np.dot() . 은 입력이 1차원 배열이면 벡터를, 2차원 배열이면 행렬 곱을 계산한다. . 주의할 것은 np.dot(A,B)와 np.dot(B,A)는 다른 값이 될 수 있다.(우연의 일치가 발생할 순 있다.) . 행렬의 곱은 *과는 다르다 | . . a = np.array([2,3]) # 입력 값 b = np.array([[1,2,3],[4,5,6]]) # 가중치 # 편향과 활성화 함수를 생략하고 가중치만 갖는 간단한 신경망이다. np.dot(a,b) . array([14, 19, 24]) . . def identity_function(x): return x def init_network(): network = {} # dict 형태로 이용할 것 network[&#39;W1&#39;] = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]]) network[&#39;b1&#39;] = np.array([0.1,0.2,0.3]) network[&#39;W2&#39;] = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]]) network[&#39;b2&#39;] = np.array([0.1,0.2]) network[&#39;W3&#39;] = np.array([[0.1,0.3],[0.2,0.4]]) network[&#39;b3&#39;] = np.array([0.1,0.2]) return network def forward(network, x): W1,W2,W3 = network[&#39;W1&#39;],network[&#39;W2&#39;],network[&#39;W3&#39;] b1,b2,b3 = network[&#39;b1&#39;],network[&#39;b2&#39;],network[&#39;b3&#39;] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) # 1층 a2 = np.dot(z1, W2) + b2 z2 = sigmoid(a2) # 2층 a3 = np.dot(z2,W3) + b3 y = identity_function(a3) # 3층 return y network = init_network() x = np.array([1,0.5]) y = forward(network, x) print(y) . [0.31682708 0.69627909] . network . {&#39;W1&#39;: array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]]), &#39;b1&#39;: array([0.1, 0.2, 0.3]), &#39;W2&#39;: array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]]), &#39;b2&#39;: array([0.1, 0.2]), &#39;W3&#39;: array([[0.1, 0.3], [0.2, 0.4]]), &#39;b3&#39;: array([0.1, 0.2])} .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/05/dl.html",
            "relUrl": "/2022/02/05/dl.html",
            "date": " • Feb 5, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "퍼셉트론",
            "content": "퍼셉트론을 구현해보자 AND 게이트 구현 | . | . def AND(x1, x2): w1,w2,theta = 0.5,0.5,0.7 tmp = x1*w1+x2*w2 if tmp&lt;=theta: return 0 elif tmp&gt;theta: return 1 print(AND(0,0)) print(AND(1,0)) print(AND(0,1)) print(AND(1,1)) . 0 0 0 1 . 물론 앞에서 구현한 AND 게이트는 직관적이고 알기 쉽지만, 앞으로를 생각해서 다른 방식으로 수정해보자. 편향이라는 개념을 도입하여, 퍼셉트론은 입력신호에 가중치를 곱한 값과 편향을 더하여, 그 값이 0을 넘으면 1을 출력하고 그렇지 않으면 0을 출력한다. | . | . import numpy as np x = np.array([0,1]) # 입력 w = np.array([0.5,0.5]) # 가중치 b = -0.7 # 편향 print(w*x) print(np.sum(w*x)) print(np.sum(w*x)+b) . [0. 0.5] 0.5 -0.19999999999999996 . . 가중치와 편향을 도입한 AND 게이트는 다음과 같이 구현할 수 있다. | . def AND(x1,x2): x = np.array([x1,x2]) w = np.array([0.5,0.5]) b = -0.7 tmp = np.sum(x*w) + b if tmp&lt;=0 : return 0 elif tmp &gt;0 : return 1 . w1,w2는 각 입력 신호가 결과에 주는 영향력을 조절하는 매개변수이고, 편향을 뉴런이 얼마나 쉽게 활성화(결과로 1을 출력)하느냐를 조정하는 매개변수이다. | . def NAND(x1,x2): x = np.array([x1,x2]) w = np.array([-0.5,-0.5]) b = 0.7 tmp = np.sum(x*w) + b if tmp&lt;=0 : return 0 elif tmp &gt;0 : return 1 def OR(x1,x2): x = np.array([x1,x2]) w = np.array([0.5,0.5]) b = -0.2 tmp = np.sum(x*w) + b if tmp&lt;=0 : return 0 elif tmp &gt;0 : return 1 . AND, NAND, OR 모두 같은 구조의 퍼셉트론이고 차이는 가중치 매개변수의 값뿐이다. 실제로 파이썬으로 작성한 NAND와 OR 게이트의 코드에서도 AND와 다른 곳은 가중치와 편향 값을 설정하는 부분뿐이다. | . . XOR 게이트 배타적 논리합이라는 논리회로이다. 한쪽이 1일때만 1을 출력. OR게이트와 달리 둘 다 1일때는 출력하지 않는다. | 지금까지 본 퍼셉트론의 구조로는 이 XOR 게이트를 구현할 수 없다. | . | . import matplotlib.pyplot as plt plt.scatter([0,0,1,1],[0,1,0,1]) plt.xlim(0,2) plt.ylim(0,2) . (0.0, 2.0) . (0,0)(1,1),(1,0)(0,1)이 두 묶음을 각각 나눌 수 있는 직선은 있을 수 없다. | 하지만 직선이라는 제약을 없앤다면 가능하다 | 퍼셉트론은 직선 하나로 나눈 영역만 표현할 수 있다는 한계가 있다. 곡선은 표현할 수 없다. | 퍼셉트론으로는 XOR 게이트를 표현할 수 없지만 층을 쌓아 다층 퍼셉트론을 통해 구현할 수 있다. | . . AND, OR NAND 게이트를 조합하여 XOR게이트를 만들 수 있다. | 단층 퍼셉트론으로는 XOR 게이트를 표현할 수 없다. 단층 퍼셉트론으로는 비선형 영역을 분리할 수 없다. | 퍼셉트론을 조합하여 즉, 층을 쌓아서 XOR 게이트를 구현하는 것이다. | . def XOR(x1,x2): s1 = NAND(x1,x2) s2 = OR(x1,x2) y = AND(s1,s2) return y . print(XOR(0,0)) print(XOR(0,1)) print(XOR(1,0)) print(XOR(1,1)) . 0 1 1 0 . 이처럼 퍼셉트론은 층을 쌓아 더 다양한 것을 표현할 수 있다. | . . Conclusion . 퍼셉트론은 입출력을 갖춘 알고리즘이다. 입력을 주면 정해진 규칙에 따른 값을 출력한다. | 퍼셉트론에서는 가중치와 편향을 매개변수로 설정한다. | 퍼셉트론으로 AND,OR 게이트 등의 논리 회로를 표현할 수 있다. | XOR 게이트는 단층 퍼셉트론으로는 표현할 수 없다. | 2층 퍼셉트론을 이용하면 XOR 게이트를 표현할 수 있다. | 단층 퍼셉트론은 직선형 영역만 표현할 수 있고, 다층 퍼셉트론은 비선형 영역도 표현할 수 있다. | 다층 퍼셉트론은 (이론상) 컴퓨터도 표현할 수 있다. | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/02/04/dl.html",
            "relUrl": "/2022/02/04/dl.html",
            "date": " • Feb 4, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "2022/01/29/SAT",
            "content": "Softmax Classfication Logistic Regression의 연장선에 있다고 볼 수 있다. | . | . import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim # 재현성을 위하여 torch.manual_seed(1) . &lt;torch._C.Generator at 0x208d7a60b70&gt; . Discrete Probability Distribution 이산적인 확률 분포를 말한다. 확률 분포에는 연속적인 확률 분포와 이산적인 확률 분포가 있다. | 가령 우리가 주사위를 던져서 주사위가 6개중 하나의 숫자가 나오게 되는데 이러한 경우 혹은 가위바위보 이런 경우를 이산적인 확률 분포라고 한다. | 주사위의 PMF(Probability Mass Function) 확률질량함수는 아래와 같다. Uniform Distribution | | . | 가위 바위 보도 동일하게 정의할 수 있을 것이다. Uniform Distribution | | . | 일반적으로 알고 있는 확률분포함수pdf에서는 | | 위와 같이 생길 수 있는데 면적이 확률을 의미한다. 어떤 지점 자체는 확률을 의미하지 않는다. 알 수도 없다. | discrete에서는 지점의 확률을 구할 수 있다. | 그래서 이러한 이산적인 확률 분포를 바탕으로 머신러닝을 수행한다고 생각해보자 | 가위바위보 상황에서 이전이 상대방이 낸 것을 바탕으로 해서 다음에 상대방이 낼 것을 예측할 수 있을 것이다. 완전히 랜덤은 아닐 것이고 사람마다 일정한 어떤 패턴이 있을 것이다. 즉 확률 분포함수가 있다는 것이다. 예전에 철수가 가위를 냈을 떄 다음에 주먹을 낼 확률은 얼마? 이런 것이다. 이렇게 정의할 수 있을 것이다. | P(주먹 | 가위) = ? 혹은 P(가위 | 가위) 혹은 P(보 | 가위), 이 세가지를 알 수 있다면 상대방이 가위를 냈을 떄 다음에 무엇을 낼 지 예측할 수 잇을 것이다. | 분명히 이런 패턴의 확률 분포가 있을 것이고 이 확률 분포를 근사해야한다. | . | softmax라는 함수가 있는데 말 그대로 max값을 뽑아주는데 soft하게 뽑아준다. | softmax | | 기존에 max를 뽑는다면.. 아래를 살펴보자 | . | . z = torch.FloatTensor([1,2,3]) . 위와 같이 주어졌을 떄, argmax 값은 max=(0,0,1)이 됐을 것이다. | 그런데 softmax는 가볍게 뽑아준다. 부드럽게 뽑아준다. 즉, 위 처럼 (0,0,1) 대신에 합쳐서 1이 되는,, 비율에 따라서 나타내 줄 수 있겠다. | 확률 값으로 볼 수도 있겠다. 아래를 살펴보자 | . hypothesis = F.softmax(z, dim=0) print(hypothesis) . tensor([0.0900, 0.2447, 0.6652]) . 각각의 이 세 값들은 위 사진 수식에 따라서 활용이 될 것이다. | 예를 들어 첫 번쨰 값인 0.09같은 경우에는 | | 이와 같이 구해졌을 것이다. | . hypothesis.sum() . tensor(1.) . softmax값은 1이 된다. | 우리는 이를 이용해 철수가 가위를 냈을 때 다음에 어떤 것을 낼지 확률 분포를 근사할 수 있겠다, | . . Cross Entropy 이러한 두개의 확률 분포가 주어졌을 때 두 확률 분포가 얼마나 비슷한지를 나타내는 수치라고 볼 수 있다 | 수식을 살펴보자 | | 좀 더 직관적으로 나타내보자 | | 예를 들어서 맨 왼쪽에 있는 분포가 P 가운데가 Q_1 맨 오른쪽에 있는 분포가 Q_2라고 했을 때, P에서 샘플링한다는 (사진상에서 E밑에있는 P가 P에서 샘플링한다는 것을 의미함) 것은 P에 해당되는 density대로 샘플링이 되겠다. | 예를 들어 사진상에서 빨간동그라미에서 점이 뽑혔다면, 그 위에서 Q_1과 Q_2에 해당될 것이다. | 즉, 우리는 이 log를 취하고 -를 붙여줬기 때문에, Q_1의 값이 Q_2의 값보다 훨씬 크게 될 것이다. | | 따라서 만약에 철수가 가위를 냈을 때 다음에 무엇을 낼지에 대한 확률 분포함수가 있을 것인데 그것을 P라고 했을 떄, 우리는 이 cross entropy를 구해서 cross entropy 이것을 최소화하도록 하면 Q_2에서 Q_1으로 그리고 P로 다가갈 수 있을 것이다. | 그래서 우리가 가지고 있는 모델의 확률 분포함수는 점점 P에 근사하게 될 것이다. | 따라서 cross entropy를 최소화하는 것이 중요하다. | . | . corss entropy loss 손실함수를 계산해보자 cross entropy는 아래와 같이 수식으로 계산할 수 있겠다. | | . | . z = torch.rand(3 ,5 ,requires_grad = True) hypothesis = F.softmax(z,dim=1) # 두 번째 행에 대해서 softmax를 수행하라. print(hypothesis) . tensor([[0.2441, 0.1429, 0.2298, 0.2344, 0.1487], [0.1665, 0.2504, 0.2309, 0.1707, 0.1815], [0.2733, 0.1576, 0.2292, 0.2147, 0.1252]], grad_fn=&lt;SoftmaxBackward0&gt;) . 이것이 사실은 예측값 즉 yhat이 될 것이다. | 정답이 뭔지 알아보자(지금은 따로 정답이 없기 때문에 랜덤으로 정답을 생성해보자) | . y = torch.randint(5, (3,)).long() print(y) . tensor([1, 0, 0]) . 우리는 각각의 샘플에 대해서 정답 인덱스를 구했다고 볼 수 있다. | 첫 번째 행에서 1인덱스 두 번째 행에서 0인덱스 세 번째 행에서 0인덱스를 의미한다. | . one hot vector로 나타내보자 | . y_one_hot = torch.zeros_like(hypothesis) y_one_hot.scatter_(1, y.unsqueeze(1),1) # tensor([1,0,0]) . tensor([[0., 1., 0., 0., 0.], [1., 0., 0., 0., 0.], [1., 0., 0., 0., 0.]]) . cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean() print(cost) . tensor(1.6784, grad_fn=&lt;MeanBackward0&gt;) . sim(dim=1)은 3 x 1이 남을 것이다. | . . Cross-entropy Loss with torch.nn.functional | . torch.log(F.softmax(z, dim=1)) # low lovel . 을 생략하고 아래와 같이 이용할 수 있겠다 . | . F.log_softmax(z, dim=1) . tensor([[-1.4101, -1.9457, -1.4703, -1.4507, -1.9056], [-1.7925, -1.3848, -1.4657, -1.7679, -1.7066], [-1.2971, -1.8475, -1.4731, -1.5385, -2.0782]], grad_fn=&lt;LogSoftmaxBackward0&gt;) . 한 번 더 간편하게 이용할 수 있다. | NLL (Negative Log Likelihood) | . F.nll_loss(F.log_softmax(z,dim=1),y) . tensor(1.6784, grad_fn=&lt;NllLossBackward0&gt;) . 위 값과 동일함을 알 수 있다. | 더 단순하게 수행할 수 잇다. | . F.cross_entropy(z,y) . tensor(1.6784, grad_fn=&lt;NllLossBackward0&gt;) . 값이 동일함을 알 수 있다. | 필요에 따라서 원하는 값을 사용하면 된다. | . . Training with Low-level Cross Entripy Loss | 손실함수를 통해서 직접 최적화, 학습을 해보자 | . x_train = [[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]] y_train = [2,2,2,1,1,1,0,0] x_train = torch.FloatTensor(x_train) y_train = torch.FloatTensor(y_train) . 이와 같이 학스부data가 주어져있다고 해보자. | x_train이 m x 4 라고 해보고 그렇다면 y_train도 m개가 있을 것이다. 즉 4차원의 벡터를 받아서 어떤 클래스인지 예측하도록 하고싶다. | 여기서 y_train은 one-hot벡터로 나타냈을 때, 1이 있는 위치에서의 인덱스 값일 것이다. | 코드를 작성해보자 | . # 모델 초기화 W = torch.zeros((4,3), requires_grad = True) b = torch. zeros(1, requires_grad = True) # optimizer 설정 optimizer = optim.SGD([W,b], lr=0.1) nb_epochs = 1000 for epoch in range(nb_epochs +1): # cost 계산(1) hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) y_one_hot = torch.zeros_like(hypothesis) y_one_hot.scatter_(1, y_train.unsqueeze(1),1) cost = (y_one_hot * -torch.log(F.softmax(hypothesis, dim=1))).sum(dim=1) # cost로 H(x) 개선 optimizer.zero_grad() cost.backward() optimizer.step() # 100번 마다 로그 출력 if epoch7 % 100 == 0 : print(&#39;Epoch {:4d}/{} Cost : {:.6f}&#39;.format(epoch, nb_epochs, cost.item())) . 좀 더 쉽게 구현을 해보자 | Training with F.cross_entropy | . # 모델 초기화 W = torch.zeros((4,3), requires_grad = True) b = torch. zeros(1, requires_grad = True) # optimizer 설정 optimizer = optim.SGD([W,b], lr=0.1) nb_epochs = 1000 for epoch in range(nb_epochs +1): # cost 계산(2) z = x_train.matmul(W)+b cost = F.cross_entropy(z, y_train) # scatter를 사용할 필요가 없어짐 # cost로 H(x) 개선 optimizer.zero_grad() cost.backward() optimizer.step() # 100번 마다 로그 출력 if epoch7 % 100 == 0 : print(&#39;Epoch {:4d}/{} Cost : {:.6f}&#39;.format(epoch, nb_epochs, cost.item())) . 좀 더 실전에 가깝게 쉽게 구현해보자 | High level Implementation with nn.Module | . class SoftmaxClassifierModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(4,3) def forward(self, x) : return self.linear(x) model = SoftmaxClassifierModel() . # optimizer 설정 optimizer = optim.SGD(model.parameters(), lr=0.1) nb_epochs = 1000 for epoch in range(nb_epochs +1): # H(x) 계산 prediction = model(x_train) # cost 계산 cost = F.cross_entropy(prediction, y_train) # cost로 H(x) 개선 optimizer.zero_grad() cost.backward() optimizer.step() # 100번 마다 로그 출력 if epoch7 % 100 == 0 : print(&#39;Epoch {:4d}/{} Cost : {:.6f}&#39;.format(epoch, nb_epochs, cost.item())) .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/01/29/intro.html",
            "relUrl": "/2022/01/29/intro.html",
            "date": " • Jan 29, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "2022/01/28/FRI",
            "content": "회귀 분석 회귀 분석은 데이터의 특성에 따라 선형 회귀와 비선형 회귀로 나눌 수 있다. | 데이터 분포에 따라 선형적 특성을 보이면 선형 회귀를 사용하고 데이터가 비선형적 특성을 보이면 비선형 회귀를 사용한다. | 이러한 방법을 사용하는 회귀분석의 목적은 컴퓨터가 보유한 데이터로부터 데이터의 특성을 스스로 학습하고 앞으로 데이터를 추정 및 예측하는 것이다. Linear Regression vs Logistic Regression | 두 가지 모두 회귀 분석의 종류이다. 즉, output의 형태만 다를 뿐이다. | 먼저 선형,비선형 회귀는 연속형 data를 input으로 하여 연속형 output을 추정하는 알고리즘이다. | 반면 Logistic Regression은 연속형 data를 input으로하여 이산형 output을 추정하는 알고리즘이다. | 즉 넣어주는 값의 형태는 동일하지만 도출되는 output의 형태가 다르다는 것이 두 알고리즘의 차이점이다.ref | | 왼쪽 그림은 초록색 또는 검은색의 연속적인 data를 쉽게 표현하는 선형,비선형 그래프를 추정하는 것이 목적이다. | 반면 오른쪽 그림은 0또는 1이라는 값으로 고양이 여부, 즉 binary한 값을 도출하는 알고리즘이다. | 여기서 input이 이미지로 이루어진 것처럼 보이지만 나중에 이미지는 컴퓨터가 계산할 수 있는 실수값으로 이루어진 어떤 tensor(다차원의 행렬로 보면 될 것 같다)값으로 변환되기 때문에 숫자로 이루어진 연속형 data로 보면 된다. | 이렇게 Logistic Regression (Binary Classification에 이용)입력된 data의 특징을 통해 0또는 1이라는 output의 값을 추정하는 것을 목표로 하는 알고리즘. 이를 위해 sigmoid라는 활성화 함수를 사용하게 된다. | | 간단히, 특정 범주에 속할 것인지에 대한 확률을 예측하는 것이기 때문에 Output이 반드기 0~1사이에 있어야하므로 sigmoid라는 활성화함수(스칼라값을 입력하면 스칼라값을 출력하는 함수)를 사용한다고 알아두자 | 예를 들어 고양이라고 생각하는 1에 해당하는 확률 값이 sigmoid를 통해 0.78이 나왔다면 컴퓨터는 0.78의 확률로 고양이라고 생각한다는 것이다. 마지막으로 Logistic Regression 알고리즘을 통해 추정된 yhat의 값이 정말 옳은 값인지 잘못된 예측인지 알아야 할 것이다. | 이러한 오차를 계산하기 위해 Cross Entropy가 사용됨 | | 이 방법을 통해 추정된 yaht의 값과 참값이 얼마나 다른지를 수학적으로 계산하여 하나의 숫자값으로 오차를 표현해준다. | 따라서 이 오차를 0으로 만드는 것이 Logistic Regression의 최종 목표이다. | . | . | 정리하자면 다음과 같다. | 오차를 줄이는 방향으로 알고리즘이 학습되어야 할 것이다. | . | . | . import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim # 재현성을 위하여 torch.manual_seed(1) # 사용될 data x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]] y_data = [[0],[0],[0],[1],[1],[1]] x_train = torch.FloatTensor(x_data) y_train = torch.FloatTensor(y_data) print(x_train.shape) print(y_train.shape) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy _distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs: C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll C: Users ehfus Anaconda3 envs dv2021 lib site-packages numpy .libs libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll warnings.warn(&#34;loaded more than 1 DLL from .libs:&#34; . torch.Size([6, 2]) torch.Size([6, 1]) . Computing the Hypothesis | . print(&#39;e^1 equals: &#39;,torch.exp(torch.FloatTensor([1]))) . e^1 equals: tensor([2.7183]) . | . W = torch.zeros((2,1), requires_grad = True) # gradient를 배우겠다. b = torch.zeros(1, requires_grad = True) # gradient를 배우겠다. # 지금은 일단 0으로 줬음 hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b))) # x_train.matmul(W) = torch.matmul(x,W) print(hypothesis) print(hypothesis.shape) . tensor([[0.5000], [0.5000], [0.5000], [0.5000], [0.5000], [0.5000]], grad_fn=&lt;MulBackward0&gt;) torch.Size([6, 1]) . print(&#39;1/(1+e^{-1}) = &#39; , torch.sigmoid(torch.FloatTensor([1]))) . 1/(1+e^{-1}) = tensor([0.7311]) . 사실은 위 셀처럼 제공되어지고 있으니, 아래와 같이 간단히 써볼 수 있겠다. | . hypothesis = torch.sigmoid(x_train.matmul(W) + b) print(hypothesis) print(hypothesis.shape) . tensor([[0.5000], [0.5000], [0.5000], [0.5000], [0.5000], [0.5000]], grad_fn=&lt;SigmoidBackward0&gt;) torch.Size([6, 1]) . 값이 동일하게 나옴을 알 수 있다. | . . Computing the Cost Function | 위 사진에서 H(x)는 P(x = 1; W)로 표현할 수 있겠다. | . | 우리는 hypothesis와 y_train의 오차를 알고싶다. | . print(hypothesis) print(y_train) . tensor([[0.5000], [0.5000], [0.5000], [0.5000], [0.5000], [0.5000]], grad_fn=&lt;SigmoidBackward0&gt;) tensor([[0.], [0.], [0.], [1.], [1.], [1.]]) . 일단 한 개의 요소에 대해서만 계산해보자 | . -(y_train[0] * torch.log(hypothesis[0]) + (1 - y_train[0]) * torch.log(1 - hypothesis[0])) . tensor([0.6931], grad_fn=&lt;NegBackward0&gt;) . 아래 사진을 참고해보자 | | . 전체 sample에 대해 표현해보자 | . losses = -(y_train*torch.log(hypothesis) + (1-y_train)*torch.log(1-hypothesis)) print(losses) . tensor([[0.6931], [0.6931], [0.6931], [0.6931], [0.6931], [0.6931]], grad_fn=&lt;NegBackward0&gt;) . cost = losses.mean() print(cost) . tensor(0.6931, grad_fn=&lt;MeanBackward0&gt;) . 이 모든 것을 한 번에 해결해보자 | . F.binary_cross_entropy(hypothesis, y_train) . tensor(0.6931, grad_fn=&lt;BinaryCrossEntropyBackward0&gt;) . 동일한 값이 나옴을 알 수 있다. | . . Whole Training Procedure | . W = torch.zeros((2,1), requires_grad=True) b = torch.zeros(1, requires_grad=True) # optimizer 설정 optimizer = optim.SGD([W,b], lr=1) # SGD를 이용하여 learning rate=1인 상태로 W,b를 학습 nb_epochs = 1000 for epoch in range(nb_epochs + 1) : # cost 계산 hypothesis = torch.sigmoid(x_train.matmul(W) + b) cost = F.binary_cross_entropy(hypothesis, y_train) # cost로 H(x) 개선 optimizer.zero_grad() cost.backward() optimizer.step() # 100번마다 로그 출력 if epoch % 100 == 0 : print(&#39;Epoch{:4d}/{} Cost : {:.6f}&#39;.format(epoch, nb_epochs, cost.item())) . Epoch 0/1000 Cost : 0.693147 Epoch 100/1000 Cost : 0.134722 Epoch 200/1000 Cost : 0.080643 Epoch 300/1000 Cost : 0.057900 Epoch 400/1000 Cost : 0.045300 Epoch 500/1000 Cost : 0.037261 Epoch 600/1000 Cost : 0.031672 Epoch 700/1000 Cost : 0.027556 Epoch 800/1000 Cost : 0.024394 Epoch 900/1000 Cost : 0.021888 Epoch1000/1000 Cost : 0.019852 . cost값이 점점 줄어듦을 알 수 있다. | . . Evlauation | . hypothesis = torch.sigmoid(x_train.matmul(W) +b) print(hypothesis[:5]) . tensor([[2.7648e-04], [3.1608e-02], [3.8977e-02], [9.5622e-01], [9.9823e-01]], grad_fn=&lt;SliceBackward0&gt;) . 사실은 x_train이 아니라 x_test인 게 더 정확하다. | 간단히 해석해보면 순서대로 x=1일 확률을 의미한다. | . prediction = hypothesis &gt;= torch.FloatTensor([0.5]) print(prediction[:5]) # 예측 print(y_train[:5]) # 실제 정답 . tensor([[False], [False], [False], [ True], [ True]]) tensor([[0.], [0.], [0.], [1.], [1.]]) . 잘 예측했음을 알 수 있다. | . correct_prediction = prediction.float() == y_train print(correct_prediction) . tensor([[True], [True], [True], [True], [True], [True]]) . 5개에 대해선 동일함을 알 수 있다. | . . Higher Implementation with Class | . class BinaryClassifier(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(8,1) self.sigmoid = nn.Sigmoid() def forward(self, x): return self.sigmoid(self.linear(x)) . model = BinaryClassifier() . | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/01/28/intro.html",
            "relUrl": "/2022/01/28/intro.html",
            "date": " • Jan 28, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "2022/01/27/THU",
            "content": "Simple Linear Regression 하나의 정보로부터 하나의 결론을 짓는 모델이었다. 다음과 같다. | $H(x) = W(x) + b$ | 하지만 대부분의 경우 좀 더 복잡한 예측을 하기 위해선 다양한 정보가 필요하다. | 이를 위해 Multivariate Linear Regression을 알아보자 | . | Multivariate Linear Regression 복수의 정보가 존재할 때 어떻게 하나의 추측값을 계산할 수 있는지? | 예를 들어, 만약 쪽지시험들의 성적이 73,80,75점일때, 이 학생의 기말고사 점수가 몇점일지 예측해보자 | . | . import torch x_train = torch.FloatTensor([[73,80,75], [93,88,93], [89,91,90], [96,98,100], [73,66,70]]) y_train = torch.FloatTensor([[125],[185],[180],[196],[142]]) . Hypothesis Function은 인공신경망의 구조를 나타내는데 이번에도 동일하게 $H(x) = W(x) + b$를 이용하여 표현한다. 하지만 simple linear regression에서는 x에 하나의 정보밖에 없어서 x를 1x1 vector로 표현했다면 이번에는 x에 3개의 정보가 있으므로 아래와 같이 나타낼 수 있다. | | 즉 x를 3x1 vector로 나타낸다. | 그렇다면 이 Hypothesis function을 PyTorch에서 어떻게 계산할 수 있을까 | 단순한 hypothesis 정의를 이용하여 아래와 같이 작성할 수 있을 것이다. | | 하지만 x에 3개의 정보가 있을 때 이렇게 나열하는 게 가능할 수 있겠지만 더 많은 양의 정보를 x가 가지고 있다면 hypothesis를 계산하는 이 한줄은 점점 길어질 것이다. | 따라서 우리는 PyTorch에서 제공해주는 matmul이라는 함수를 사용하면 된다. | 코드는 아래와 같다.hypothesis = x_train.matmul(W) + b . | Multivariate Linear Regression의 Cost function은 Simple Linear Regression과 마찬가지로 MSE를 사용하며 계산 방식역시 동일하다. | 또한 Multivariate Linear Regression의 학습방식 또한 Gradient Descent with torch.optim로서 동일하다. | | 이제 완성된 코드를 한 번 작성해보자 | . import torch x_train = torch.FloatTensor([[73,80,75], [93,88,93], [89,91,90], [96,98,100], [73,66,70]]) y_train = torch.FloatTensor([[125],[185],[180],[196],[142]]) # 모델 초기화 W = torch.zeros((3,1), requires_grad=True) b = torch.zeros(1, requires_grad=True) # optimizer 설정 import torch.optim as optim optimizer = optim.SGD([W,b], lr = 1e-5) . nb_epochs = 20 for epoch in range(nb_epochs+1): # H(x) 계산 hypothesis = x_train.matmul(W) + b # cost 계산 cost = torch.mean((hypothesis - y_train)**2) # cost로 H(x)계산 optimizer.zero_grad() cost.backward() optimizer.step() print(&#39;Epoch {:4d}/{} hypothesis: {} Cost {:.6f}&#39;.format(epoch, nb_epochs, hypothesis.squeeze().detach(),cost.item())) . Epoch 0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost 28166.000000 Epoch 1/20 hypothesis: tensor([65.3835, 78.5927, 77.4353, 84.3257, 59.9476]) Cost 8919.982422 Epoch 2/20 hypothesis: tensor([101.9877, 122.5950, 120.7879, 131.5363, 93.5114]) Cost 2887.348145 Epoch 3/20 hypothesis: tensor([122.4795, 147.2313, 145.0590, 157.9675, 112.3039]) Cost 996.406433 Epoch 4/20 hypothesis: tensor([133.9505, 161.0253, 158.6470, 172.7651, 122.8264]) Cost 403.667480 Epoch 5/20 hypothesis: tensor([140.3712, 168.7492, 166.2539, 181.0495, 128.7189]) Cost 217.844818 Epoch 6/20 hypothesis: tensor([143.9643, 173.0745, 170.5123, 185.6873, 132.0192]) Cost 159.569305 Epoch 7/20 hypothesis: tensor([145.9744, 175.4972, 172.8959, 188.2836, 133.8682]) Cost 141.273163 Epoch 8/20 hypothesis: tensor([147.0982, 176.8546, 174.2299, 189.7369, 134.9047]) Cost 135.508194 Epoch 9/20 hypothesis: tensor([147.7258, 177.6156, 174.9762, 190.5503, 135.4863]) Cost 133.671143 Epoch 10/20 hypothesis: tensor([148.0756, 178.0428, 175.3936, 191.0054, 135.8133]) Cost 133.065277 Epoch 11/20 hypothesis: tensor([148.2699, 178.2830, 175.6268, 191.2600, 135.9977]) Cost 132.845520 Epoch 12/20 hypothesis: tensor([148.3771, 178.4185, 175.7569, 191.4022, 136.1022]) Cost 132.746689 Epoch 13/20 hypothesis: tensor([148.4356, 178.4955, 175.8292, 191.4816, 136.1620]) Cost 132.685730 Epoch 14/20 hypothesis: tensor([148.4667, 178.5396, 175.8692, 191.5258, 136.1968]) Cost 132.636658 Epoch 15/20 hypothesis: tensor([148.4826, 178.5654, 175.8911, 191.5503, 136.2177]) Cost 132.591431 Epoch 16/20 hypothesis: tensor([148.4900, 178.5809, 175.9028, 191.5637, 136.2306]) Cost 132.547455 Epoch 17/20 hypothesis: tensor([148.4925, 178.5906, 175.9090, 191.5710, 136.2392]) Cost 132.503815 Epoch 18/20 hypothesis: tensor([148.4924, 178.5971, 175.9119, 191.5748, 136.2453]) Cost 132.460098 Epoch 19/20 hypothesis: tensor([148.4908, 178.6018, 175.9130, 191.5766, 136.2500]) Cost 132.416672 Epoch 20/20 hypothesis: tensor([148.4883, 178.6055, 175.9132, 191.5774, 136.2540]) Cost 132.373291 . cost가 점점 작아짐을 알 수 있다. | H(x)도 점점 y에 가까워짐을 알 수 있다. | Learning rate에 따라 발산할 수도 있다. | . . W와 b를 일일히 작성해주는 것은 번거로운 일이 될 수 있다. | 따라서 PyTorch에서 제공해주는 nn.Module을 상속해서 모델을 생성하자 | . # 아래는 Full code이다. x_train = torch.FloatTensor([[73,80,75], [93,88,93], [89,91,90], [96,98,100], [73,66,70]]) y_train = torch.FloatTensor([[125],[185],[180],[196],[142]]) import torch.nn as nn class MultivariateLinearRegressionModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(3,1) def forward(self,x): return self.linear(x) # 모델 초기화 model = MultivariateLinearRegressionModel() # optimizer 설정 optimizer = optim.SGD([W,b],lr=1e-5) import torch.nn.functional as F # cost 계산 cost = F.mse_loss(prediction, y_train) nb_epochs = 20 for epoch in range(nb_epochs+1): # H(x) 계산 hypothesis = model(x_train) # cost 계산 cost = F.mse_loss(prediction, y_train) # cost로 H(x)계산 optimizer.zero_grad() cost.backward() optimizer.step() print(&#39;Epoch {:4d}/{} hypothesis: {} Cost {:.6f}&#39;.format(epoch, nb_epochs, hypothesis.squeeze().detach(),cost.item())) . nn.linear (3,1) 입력 차원 = 3 | 출력 차원 = 1 | . | Hypothesis 계산은 forward에서 진행된다. | Gradient 계산은 Pytorch가 알아서 진행해준다. backward() | . . 또한 Pytorch에서는 다양한 cost function을 제공한다. | . import torch.nn.functional as F # cost 계산 cost = F.mse_loss(prediction, y_train) . 이렇게 사용하면 쉽게 다른 loss와 교체 가능하다. (l1_loss, smooth_l1_loss 등 ...) | 그런데 여기서 prediction이 정의되지 않았다고 함... | . 지금까지 적은 양의 데이터를 가지고 학습했다. | 하지만 딥러닝은 많은 양의 데이터와 함께할 때 빛을 발한다. | PyTorch에서는 많은 양의 데이터를 어떻게 다룰까? | . . 복잡한 머신러닝 모델을 학습하려면 엄청난 양의 데이터가 필요하다. | 대부분 dataset은 적어도 수십만 개의 데이터를 제공한다. | 엄청난 양의 데이터를 한 번에 학습시킬 수 없다 너무 느리다 | 하드웨어적으로 불가능하다. | . | 그렇다면 일부분의 데이터로만 학습하면 어떨까? 이렇게 해서 나온 아이디어가 Minibatch Gradient Descent이다 | 전체 데이터를 균일하게 나눠서 학습하자 | 아래 사진을 참고해보자 | | 보다 작은 단위인 Minibatch로 나누어서 Minibatch하나하나 학습하는 것이다. | 각 Minibatch에 있는 cost만 계산한 후에 Gradient descent 할 수 있기 때문에 컴퓨터에 무리가 덜 가게 된다. | 한 번에 Gradient descent를 하지 않기 때문에 업데이트를 좀 더 빠르게 할 수 있다 | 그렇지만 모델의 cost를 계산할 때 전체 데이터를 사용하지 않기 때문에 잘못된 방향으로 업데이트를 할 수도 있다. | 기존 Gradient descent처럼 매끄럽게 cost가 줄어들지 않고 좀 더 거칠게 줄어들게 된다. (각각 좌우의 그래프이다.) | | 이제 실제 dataset을 minibatch로 쪼개는 데에 사용되는 PyTorch Dataset과 module에 대해 알아보자 | . | . | . torch.utils.data.Dataset 상속 | __len__() 이 dataset의 총 data 수 | . | __getitem__() 어떠한 인덱스 idx르르 받았을 때, 그에 상응하는 입출력 데이터 반환 | . | . 이렇게 dataset을 만들었다면, PyTorch에서 module로 제공해주는 DataLoader를 사용할 수 있다. | | instance를 만드려면 두 개의 parameter를 지정해주어야 한다. | batch_size = 2 각 minibatch의 크기 | 통상적으로 2의 제곱수로 설정한다. | . | shuffle = True Epoch마다 dataset을 섞어서 데이터가 학습되는 순서를 바꾼다. | 이 옵션을 설정함으로써 우리의 모델이 dataset의 순서를 외우지 못하게 방지할 수 있으므로 권장하는 옵션이다. | . | . Full Code with Dataset and DataLoader | | enumerate(dataloader) minibatch 인덱스와 데이터를 받음 | . | len(dataloader) 한 epoch당 minibatch 개수 | . | . 지금까지 하나 또는 여러 개의 입력으로부터 어떤 숫자 하나를 예측하는 모델을 만들었다. | 다음시간엔 이렇게 숫자 하나를 예측하는 모델이 아니라 어떤 입력을 받았을 때 그것을 분류하는 모델에 대해서 알아보자 | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/01/27/intro.html",
            "relUrl": "/2022/01/27/intro.html",
            "date": " • Jan 27, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "2022/01/26/WED",
            "content": "PyTorch를 이용해서 Linear Regression을 작성해보자 . Data definition 공부한 시간과 점수와의 상관관계에 대해 알아보자 | | 학습 시간이 1,2,3일때를 Training dataset이라 한다. | 학습이 끝난 후 이 모델이 얼마나 잘 작동하는지 판별하기 위해 사용하는 data를 Test dataset이라 한다. | 이때 4시간 공부했을 때 점수는 몇점일까? | 본격적으로 코딩해보자 | . | . 모델을 학습시키기 위한 data는 torch.tensor를 이용한다. | 이때 입력과 출력은 각기 다른 dataset에 입력해준다. | . import torch x_train = torch.FloatTensor([[1],[2],[3]]) # 모델을 학습시키기 위한 입력 dataset y_train = torch.FloatTensor([[2],[4],[6]]) # 모델을 학습시키기 위한 출력 dataset . 입출력은 x,y로 구분한다. | 우리의 모델인 Hypothesis를 구현해보자 | Linear Regression은 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일이다. | 이러한 직선 $y$는 $Wx + b$로 나타낼 수 있다. | 이때 $W$는 Weight $b$는 Bias이다. | 그렇다면 이러한 Hypothesis를 정의하려면 W와 b를 먼저 정의해야 한다. | 일단 Weight와 Bias를 0으로 초기화해보자, 즉 어떤 입력을 받더라도 0을 예측할 것이다. | 이 W와 b를 학습시키는 게 우리의 목적이므로 requires_grad=True라고 입력해줌으로써 학습할 것이라고 명시해주는 것이다. | . W = torch.zeros(1, requires_grad = True) # Hypothesis 초기화 b = torch.zeros(1, requires_grad = True) # Hypothesis 초기화 hypothesis = x_train * W + b . 이렇게 W와 b를 정의하면 hypothesis는 $Wx + b$ 이렇게 간단한 곱과 합으로 나타낼 수 있다. | 이제 문제와 모델 정의가 모두 끝났으니 학습을 시작해보자 | 학습을 하려면 일단 우리의 모델이 얼마나 정답과 근사한지 알아야 한다. | . | 우리의 예측값과 실제 training dataset의 y값의 차이를 제곱해서 평균을 내는 것이다. | 위 수식을 PyTorch로 구현해보자 | . cost = torch.mean((hypothesis - y_train)**2) . MSE를 구했다. | 이 계산된 loss를 이용해서 모델을 개선시킬 차례이다. | . import torch.optim as optim optimizer = optim.SGD([W,b], lr = 0.01) # Optimizer를 정의해준다. # 우리의 모델에서 학습시킬 변수는 Weight와 Bias이기 때문에 이 2개를 list로 # 만들어서 입력해준뒤 적당한 learning rate도 입력해준다. optimizer.zero_grad() # gradient를 초기화 cost.backward() # gradient를 계산 optimizer.step() # step을 이용하여 계산된 gradient의 방향대로 gradient를 개선 . 이제 학습을 원하는만큼 for문을 반복해준다. | . nb_epochs = 1000 for epoch in range(1, nb_epochs + 1): hypothesis = x_train * W + b cost = torch.mean((hypothesis - y_train)**2) optimizer.zero_grad() # gradient를 초기화 cost.backward() # gradient를 계산 optimizer.step() # step을 이용하여 계산된 gradient의 방향대로 gradient를 개선 . 이렇게 반복적으로 학습하면 W와 b가 각각 하나의 최적의 수로 수렴하게 된다. | . W . tensor([1.9709], requires_grad=True) . b . tensor([0.0663], requires_grad=True) . W*4+b . tensor([7.9497], grad_fn=&lt;AddBackward0&gt;) . 8에 근접함을 알 수 있다. | . . 그렇다면 이렇게 cost를 줄이는 Gradient Descent에 대해 알아보자 | | Hypothesis 함수는 인공신경망의 구조로 나타내는데 주어진 input x에 대해 어떤 output y를 예측할지 알려주며 위와 같이 H(x)로 나타낸다. | b가 삭제된 더 간단한 모델에 대해 알아보자. 즉, W만 학습하면 된다. | . 위 train dataset은 입력과 출력이 동일하므로 H(x)=x가 정확한 모델일 것이다. 즉 W=1이 가장 좋은 숫자이다. | 반대로 W가 어떤 1이 아닌 값에서 시작할 때 학습의 목표는 W를 1로 수렴시키는 것이다. | W가 1에 가까울수록 더 정확한 모델이 되는 것이다. | 그렇다면 어떤 모델이 주어졌을 때 그것이 좋고 나쁨을 어떻게 평가할 수 있을까? 여기서 우리는 cost function을 정의할 수 있겠다. | cost function은 모델의 예측값이 실제 데이터와 얼마나 다른지를 나타내는 값으로 잘 학습된 모델일수록 낮은 cost를 가질 것이다. | 우리의 예제에서는 w가 1일 때 모든 데이터가 정확히 들어맞기 때문에 이때 cost가 0이다 | 그리고 w가 1에서 멀어질수록 예측값과 실제 데이터가 달라지므로 cost가 높아질 것이다. | | . | linear regression에서 사용되는 cost function은 MSE(예측값과 실제값의 차이를 제곱한 것의 평균)이다. | 우리가 원하는 cost function을 최소화하는 것이다. | 그러기 위해선 일단 위의 w-cost 그래프를 보자 | 기울기가 음수일 때는 W가 더 커져야 하고 기울기가 양수일 땐 W가 더 작아져야 한다. | 또한 기울기가 가파를수록 cost가 큰 것이니 w를 많이 바꿔야 하고 기울기가 완만할 땐 기울기가 가파를 때에 비해 w를 조금만 바꾸면 된다. | 우리는 이 기울기를 gradient라고 한다. | 이 gradient를 계산하기 위해선 미분을 해야하는데 cost function은 결국 w에 대한 2차 함수이기 때문에 간단한 미분 방정식을 통해 계산할 수 있다. | | 아까 설명했듯 gradient 즉 기울기가 양수일 때는 w를 줄이고 기울기가 음수일 때는 w를 늘려야 한다. | | 이러한 방법이 Gradient Descent이다. | . | . x_train = torch.FloatTensor([[1],[2],[3]]) y_train = torch.FloatTensor([[1],[2],[3]]) # 모델 초기화 W = torch.zeros(1) # learning rate 설정 lr = 0.1 nb_epochs = 10 for epoch in range(nb_epochs + 1): # H(x) 계산 hypothesis = x_train * W # cost gradient 계산 cost = torch.mean((hypothesis - y_train)**2) gradient = torch.sum((W * x_train - y_train)*x_train) print(&#39;Epoch {:4d}/{} W: {:.3f}, Cost: {:.6f}&#39;.format(epoch, nb_epochs,W.item(), cost.item())) # cost gradient로 H(x) 개선 W-=lr*gradient . Epoch 0/10 W: 0.000, Cost: 4.666667 Epoch 1/10 W: 1.400, Cost: 0.746666 Epoch 2/10 W: 0.840, Cost: 0.119467 Epoch 3/10 W: 1.064, Cost: 0.019115 Epoch 4/10 W: 0.974, Cost: 0.003058 Epoch 5/10 W: 1.010, Cost: 0.000489 Epoch 6/10 W: 0.996, Cost: 0.000078 Epoch 7/10 W: 1.002, Cost: 0.000013 Epoch 8/10 W: 0.999, Cost: 0.000002 Epoch 9/10 W: 1.000, Cost: 0.000000 Epoch 10/10 W: 1.000, Cost: 0.000000 . Epoch이 증가할수록 W가 1에 수렴하고 Cost역시 줄어듦을 알 수 있다. | gradient descesnt를 더 편리하게 할 수 있도록 torch.optim을 이용할 수 있다. | . import torch.optim as optim optimizer = optim.SGD([W,b], lr = 0.01) # Optimizer를 정의해준다. # 우리의 모델에서 학습시킬 변수는 Weight와 Bias이기 때문에 이 2개를 list로 # 만들어서 입력해준뒤 적당한 learning rate도 입력해준다. optimizer.zero_grad() # gradient를 0으로 초기화 cost.backward() # gradient를 계산 optimizer.step() # step을 이용하여 계산된 gradient의 방향대로 gradient를 개선, 즉 실행한다. . | 이와 같이 이용할 수 있겠다. | . 지금까지 우리는 하나의 정보로부터 하나의 정보를 추측하는 모델을 만들었다. 예를 들어 한 학생읭 수업 참여도를 알 때 점수를 추측할 수 있는 모델 같은 게 있을 수 있다. 하지만 좋은 추측을 하기 위해선 정보 양이 많이 필요하다. | 예를 들어 한 학생의 점수를 추측할 때, 쪽지시험 하나의 성적보다 그 수업 때 진행된 모든 쪽지시험의 점수를 알면 좋듯 많은 정보는 추측의 질을 높여준다. | . | . | . 다음시간엔 여러개의 정보로부터 모델을 만들어보자 | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/01/26/intro.html",
            "relUrl": "/2022/01/26/intro.html",
            "date": " • Jan 26, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "2022/01/13/THU",
            "content": "View(Reshape) . import numpy as np import torch t=np.array([[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]) ft=torch.FloatTensor(t) print(ft.shape) . torch.Size([2, 2, 3]) . t . array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]]) . print(ft.view([-1,3])) # view사용해서 모양 바꾸자 print(ft.view([-1,3]).shape) . tensor([[ 0., 1., 2.], [ 3., 4., 5.], [ 6., 7., 8.], [ 9., 10., 11.]]) torch.Size([4, 3]) . 두개의 차원으로 변경할 건데 앞 차원은 모르겠고 뒷 차원은 세개의 element를 가질래 | . print(ft.view([-1,1,3])) print(ft.view([-1,1,3]).shape) . tensor([[[ 0., 1., 2.]], [[ 3., 4., 5.]], [[ 6., 7., 8.]], [[ 9., 10., 11.]]]) torch.Size([4, 1, 3]) . 세개의 차원으로 변경할 건데 첫번째 차원은 아직 모르겠고 두번째 차원과 세번째 차원은 각각 1과3으로 변경해줘 | . Squeeze . ft=torch.FloatTensor([[0],[1],[2]]) print(ft) print(ft.shape) . tensor([[0.], [1.], [2.]]) torch.Size([3, 1]) . print(ft.squeeze()) print(ft.squeeze().shape) . tensor([0., 1., 2.]) torch.Size([3]) . 차원이 줄어들었음 | 1만 압축해주는 것 같음 | . print(ft.squeeze(dim=0)) print(ft.squeeze(dim=1)) # 해당 차원이 1일 때만! . tensor([[0.], [1.], [2.]]) tensor([0., 1., 2.]) . Unsqueeze . ft = torch.Tensor([0,1,2]) print(ft.shape) . torch.Size([3]) . 첫번째 차원에 1을 넣자 | . print(ft.unsqueeze(0)) print(ft.unsqueeze(0).shape) . tensor([[0., 1., 2.]]) torch.Size([1, 3]) . print(ft.view(1,-1)) print(ft.view(1,-1).shape) . tensor([[0., 1., 2.]]) torch.Size([1, 3]) . 두번째 차원에 1을 넣자 | . print(ft.unsqueeze(1)) print(ft.unsqueeze(1).shape) . tensor([[0.], [1.], [2.]]) torch.Size([3, 1]) . -1=(dim=1) | . print(ft.unsqueeze(-1)) print(ft.unsqueeze(-1).shape) . tensor([[0.], [1.], [2.]]) torch.Size([3, 1]) . Type Casting . lt = torch.LongTensor([1,2,3,4]) print(lt) . tensor([1, 2, 3, 4]) . print(lt.float()) . tensor([1., 2., 3., 4.]) . bool형일 때 | . bt=torch.ByteTensor([True,True,True]) print(bt) . tensor([1, 1, 1], dtype=torch.uint8) . print(bt.long()) print(bt.float()) . tensor([1, 1, 1]) tensor([1., 1., 1.]) . Concatenate . x=torch.FloatTensor([[1,2],[3,4]]) y=torch.FloatTensor([[5,6],[7,8]]) . print(torch.cat([x,y], dim=0)) print(torch.cat([x,y], dim=1)) . tensor([[1., 2.], [3., 4.], [5., 6.], [7., 8.]]) tensor([[1., 2., 5., 6.], [3., 4., 7., 8.]]) . Stacking . x=torch.FloatTensor([1,4]) y=torch.FloatTensor([2,5]) z=torch.FloatTensor([3,6]) . print(torch.stack([x,y,z])) print(torch.stack([x,y,z],dim=1)) . tensor([[1., 4.], [2., 5.], [3., 6.]]) tensor([[1., 2., 3.], [4., 5., 6.]]) . print(torch.cat([x.unsqueeze(0),y.unsqueeze(0),z.unsqueeze(0)],dim=0)) . tensor([[1., 4.], [2., 5.], [3., 6.]]) . Ones and Zeros . x=torch.FloatTensor([[0,1,2],[2,1,0]]) print(torch.ones_like(x)) print(torch.zeros_like(x)) . tensor([[1., 1., 1.], [1., 1., 1.]]) tensor([[0., 0., 0.], [0., 0., 0.]]) . In-place Operation . x=torch.FloatTensor([[1,2],[3,4]]) . print(x.mul(2)) print(x) print(x.mul_(2)) print(x) . tensor([[2., 4.], [6., 8.]]) tensor([[1., 2.], [3., 4.]]) tensor([[2., 4.], [6., 8.]]) tensor([[2., 4.], [6., 8.]]) . 즉 언더바를 통해 inplace=True 효과! | .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/01/13/intro.html",
            "relUrl": "/2022/01/13/intro.html",
            "date": " • Jan 13, 2022"
        }
        
    
  
    
        ,"post21": {
            "title": "2022/01/12/WED",
            "content": "import torch . t=torch.FloatTensor([0.,1.,2.,3.,4.,5.,6.]) print(t) . tensor([0., 1., 2., 3., 4., 5., 6.]) . print(t.dim()) print(t.shape) print(t.size()) print(t[0],t[1],t[-1]) . 1 torch.Size([7]) torch.Size([7]) tensor(0.) tensor(1.) tensor(6.) . 그 외에도 slicing도 ndarray처럼 사용 가능 | 2차원 3차원도 ndarray처럼 사용 가능 | . Broadcasting . m1 = torch.FloatTensor([[3,3]]) m2 = torch.FloatTensor([[2,2]]) print(m1+m2) . tensor([[5., 5.]]) . 이렇게 같은 크기뿐만 아니라 Broadcasting을 통해 | . m1 = torch.FloatTensor([[1,2]]) m2 = torch.FloatTensor([[3]]) print(m1+m2) . tensor([[4., 5.]]) . 이렇게 크기가 동일하지 않아도 pytorch가 자동으로 동일한 size로 변환하여 연산 수행 가능 | . m1 = torch.FloatTensor([[1,2]]) m2 = torch.FloatTensor([[3],[4]]) print(m1+m2) . tensor([[4., 5.], [5., 6.]]) . print(m1.shape) . torch.Size([1, 2]) . m1 . tensor([[1., 2.]]) . print(m2.shape) . torch.Size([2, 1]) . m2 . tensor([[3.], [4.]]) . 이렇게 행렬 모양이 다르더라도 m1과 m2를 각각 2x2행렬로 변경하여 덧셈 수행하는 기능도 가능하다 | 이런 Broadcasting 기능은 자동으로 수행되기 때문에 잘못 사용하지 않게 유의하자 | . m1 = torch.FloatTensor([[1,2],[3,4]]) m2 = torch.FloatTensor([[3],[4]]) print(m1*m2) print(m1.mul(m2)) . tensor([[ 3., 6.], [12., 16.]]) tensor([[ 3., 6.], [12., 16.]]) . 이때 m2가 Broadcasting되면서 우리가 일반적으로 알고 있는 행렬 연산 수행과는 상이하게 진행됨 | 우리가 알고 있는 행렬 연산을 하기 위해서는 | . m1 = torch.FloatTensor([[1,2],[3,4]]) m2 = torch.FloatTensor([[3],[4]]) print(m1.matmul(m2)) . tensor([[11.], [25.]]) . 이렇게 해야한다. | . t = torch.FloatTensor([1,2]) print(t.mean()) . tensor(1.5000) . t = torch.FloatTensor([[1,2],[3,4]]) print(t.mean(dim=0)) # dim=0을 없애겠다. (2x2) -&gt; (1x2) print(t.mean(dim=1)) # dim=1을 없애겠다. (2x2) -&gt; (2x1) print(t.mean(dim=-1)) . tensor([2., 3.]) tensor([1.5000, 3.5000]) tensor([1.5000, 3.5000]) . t = torch.FloatTensor([[1,2],[3,4]]) print(t) . tensor([[1., 2.], [3., 4.]]) . print(t.sum()) print(t.sum(dim=0)) print(t.sum(dim=1)) print(t.sum(dim=-1)) . tensor(10.) tensor([4., 6.]) tensor([3., 7.]) tensor([3., 7.]) . t = torch.FloatTensor([[3,2],[1,4]]) print(t) . tensor([[3., 2.], [1., 4.]]) . print(t.max()) . tensor(4.) . print(t.max(dim=0)) # dim=0 제외하고 각 열에서의 max와 그 때의 index값을 알려줌 print(t.max(dim=0)[0]) # max값 print(t.max(dim=0)[1]) # max값의 index 즉, argmax . torch.return_types.max( values=tensor([3., 4.]), indices=tensor([0, 1])) tensor([3., 4.]) tensor([0, 1]) . print(t.max(dim=1)) print(t.max(dim=1)[0]) print(t.max(dim=1)[1]) . torch.return_types.max( values=tensor([3., 4.]), indices=tensor([0, 1])) tensor([3., 4.]) tensor([0, 1]) .",
            "url": "https://rhkrehtjd.github.io/INTROdl/2022/01/12/intro.html",
            "relUrl": "/2022/01/12/intro.html",
            "date": " • Jan 12, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://rhkrehtjd.github.io/INTROdl/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rhkrehtjd.github.io/INTROdl/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}