{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a012e564-7aba-4cf8-a7f7-6a49f236b45f",
   "metadata": {},
   "source": [
    "# 소프트맥스, MNIST Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f07d30-b91a-4158-92d3-de5889f387a0",
   "metadata": {},
   "source": [
    "- 소프트맥스 함수\n",
    "  - 분류에서 사용한다. \n",
    "  - 소프트맥스의 출력은 모든 입력 신호로부터 화살표를 받는다.\n",
    "  - 소프트맥스의 함수의 분모에서 볼 수 있듯, 촐력층의 각 뉴런이 모든 입력 신호에서 영향을 받기 때문이다. \n",
    "  - 이상의 소프트맥스 함수를 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5481b6-9689-48ef-9ede-ba0f836a7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ehfus\\Anaconda3\\envs\\dv2021\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ehfus\\Anaconda3\\envs\\dv2021\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\ehfus\\Anaconda3\\envs\\dv2021\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([0.3,2.9,4])\n",
    "exp_a = np.exp(a)\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6046d-1dbd-4d1b-8cc5-f3ae99c0f459",
   "metadata": {},
   "source": [
    "- 위 논리 흐름을 파이썬 함수로 정의하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b827788-6c81-4023-a308-d8cc23cd6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a9b8b-7d4b-4dfb-9ad4-984e1de59869",
   "metadata": {},
   "source": [
    "- 소프트맥스 함수 구현시 주의할 점\n",
    "  - 위에서 정의한 softmax() 함수의 코드는 컴퓨터로 계산할 때 결함이 있다.\n",
    "    - 바로 오버플로 문제이다. 소프트맥스 함수는 지수 함수를 사용하는데, 지수함수란 것이 쉽게 아주 큰 값을 내지만 컴퓨터는 다룰 수 있는 범위가 한정되어 있어 수치가 커짐에 따라 결과 수치가 불안정해질 수 있다. \n",
    "    - 해결책 : 오버플로를 막기 위해 입력 신호 중 최댓값을 이용하여 지수 함수에서 빼준다.\n",
    "    - 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a0154c-b639-4aa9-9742-344151311ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "a = np.array([1010,1000,990])\n",
    "print(np.exp(a) / np.sum(np.exp(a))) \n",
    "\n",
    "c = np.max(a)\n",
    "\n",
    "np.exp(a-c) / np.sum(np.exp(a-c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e1daf-e653-4dec-8f18-77cf73afdf40",
   "metadata": {},
   "source": [
    "- 위에서 볼 수 있듯, 아무런 조치 없이 그냥 계산하면 nan이 반환된다.\n",
    "- 하지만 입력 신호 중 최댓값을 빼주면 올바르게 계싼할 수 있다.\n",
    "- 이를 바탕으로 소프트맥스 함수를 다시 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6162a000-7937-4961-ab1c-589d86a06774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c) # 이게 오버플로 대책이다.\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343fe9a-c5b8-4610-b2ca-ab29fdff7b0f",
   "metadata": {},
   "source": [
    "- 소프트맥스 함수의 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbff0d1-b313-4117-9a5d-14ef4f789c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3,2.9,4])\n",
    "y = softmax(a)\n",
    "print(y)\n",
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1c0b9-375b-46f3-8f0c-12d9b85b90f9",
   "metadata": {},
   "source": [
    "- 즉, 소프트맥스 함수의 출력은 0에서 1사이의 실수이다. (그럴 수 밖에 없는 것이 소프트맥스 함수를 살펴보면 1을 넘을 수 없다)\n",
    "- 출력의 총합은 1이며 소프트맥스 함수의 중요한 성질이 된다.\n",
    "  - 이 성질 덕분에 소프트맥스 함수의 출력을 확률로 정의할 수 있다. \n",
    "  - 즉, 소프트맥스 함수를 이용함으로써 문제를 확률적(통계적)으로 대응할 수 있게 되는것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe1251-df4d-4595-910f-75a1a26801cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d187f5-75a4-4def-ab31-bef829db31a3",
   "metadata": {},
   "source": [
    "- 출력층의 뉴런 수 정하기\n",
    "  - 출력층의 뉴런 수는 풀려는 문제에 맞게 적절히 정해야 한다. \n",
    "  - 분류에서는 분류하고 싶은 클래스 수로 설정하는 것이 일반적이다.\n",
    "     - 예를 들어 입력 이미지를 숫자 0부터 9 중 하나로 분류하는 문제라면 출력층의 뉴런을 10개로 설정한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e3538-4cb2-446c-a5e9-08eee5da8d15",
   "metadata": {},
   "source": [
    "- 손글씨 숫자 인식\n",
    "  - 이번 절에서는 이미 학습된 매개변수(가중치, 편향(임계값))를 사용하여 학습 과정은 생략하고 추론 과정만 구현한다.\n",
    "  - 이 추론 과정을 신경망의 순전파(forward propagation)라고도 한다. \n",
    "    - 머신러닝과 마찬가지로 신경망도 두 단계를 거쳐 문제를 해결한다. 먼저 훈련 데이터 즉, 학습 데이터를 사용해 가중치 매개변수를 학습하고 추론 단계에서는 앞서 학습한 매개변수를 사용하여 입력 데이터를 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1c57a-89dc-43f8-b5b3-2e3651338908",
   "metadata": {},
   "source": [
    "- MNIST data set\n",
    "  - 손글씨 숫자 이미지 집합\n",
    "  - MNIST의 이미지 데이터는 28 $\\times$ 28 크기의 회색조 이미지이며 각 픽셀은 0에서 255까지의 값을 취한다. 각 이미지에는 또한 7,2,1과 같이 그 이미지가 실제 의미하는 숫자가 레이블로 붙어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4492ef2b-0287-4e9f-b50a-154f5f88be48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir) # 부모 디렉토리의 파일을 가져올 수 있도록 설정\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train),(x_test, t_test) = \\\n",
    "load_mnist(flatten = True, normalize = False)\n",
    "\n",
    "# 각 데이터 형상 출력해보자\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e31ff-b39f-4d3c-b3f5-41c7d8629b19",
   "metadata": {},
   "source": [
    "- 첫 번째 인수인 normalize는 입력 이미지의 픽셀값을 0~1 사이의 값으로 정규화할지를 정한다. \n",
    "- flatten은 입력 이미지를 평탄하게, 즉 1차원 배열로 만들지를 정한다. \n",
    "  - False로 설정하면 입력 이미지를 1 x 28 x 28의 3차원 배열로, True로 설정하면 784개의 원소로 이루어진 1차원 배열로 저장한다. \n",
    "\n",
    "---\n",
    "- 참고) 파이썬에는 pickle이라는 편리한 기능이 있다. 이는 프로그램 실행 중에 특정 객체를 파일로 저장하는 기능이다. 저장해준 pickle 파일을 로드하면 실행 당시의 객체를 즉시 복원할 수 있다. MNIST 데이터셋을 읽는 load_mnist() 함수에서도 (2 번째 이후의 읽기 시에) pickle을 이용한다.\n",
    "  - pickle 덕분에 MNIST 데이터를 순식간에 준비할 수 있는 것이다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10160b-6f12-4e25-8c28-5b017609e678",
   "metadata": {},
   "source": [
    "- MNIST 이미지를 화면으로 불러보도록 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b32210-6302-4bc7-a773-3038b138368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)  # 5\n",
    "\n",
    "print(img.shape)  # (784,)\n",
    "img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "print(img.shape)  # (28, 28)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a96d3-2785-4948-b3e6-1560788f43fb",
   "metadata": {},
   "source": [
    "- 주의\n",
    "  - flatten=True로 설정해 읽어 들인 이미지는 1차원 넘파이 배열로 저장돼 있다. 그래서 이미지를 표시할 땐 원래 형상인 28 x 28 크기로 다시 변형해야 한다. reshape() 메서드에 원하는 형상을 인수로 지정하면 넘파이 배열의 형상을 바꿀 수 있다.\n",
    "  - 또한 넘파이로 저장된 이미지 데이터를 PIL용 데이터 객체로 변환해야 하며, 이 변환은 Image.fromarray()가 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46cc52-f672-4570-ad91-e7e433cc4ebb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a2f41-d359-44b5-9d83-10e8582e75cf",
   "metadata": {},
   "source": [
    "- 신경망의 추론 처리\n",
    "  - 드디어 이 MNIST 데이터셋을 가지고 추론을 수행하는 신경망을 구현해보자\n",
    "  - 이 신경망은 입력층 뉴런을 784(28x28)개, 출력층 뉴련을 10개로 구성한다. \n",
    "  - 한편, 은닉층은 총 두 개로, 첫 번째 은닉층에는 50개의 뉴런을 두 번째 은닉층에는 100개의 뉴런을 배치한다. 여기서 50과 100은 임의로 정한 값이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c50e32e-6e29-412c-9845-344b58071a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 \n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataset.mnist import load_mnist\n",
    "from common.functions import sigmoid, softmax\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, w1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, w2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, w3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adda345-bc1f-4f26-b540-d9b69bb98ec6",
   "metadata": {},
   "source": [
    "- init_network()에서는 pickle 파일인 sample_weight.pkl에 저장된 학습된 가중치 매개변수를 읽는다. 이 파일에는 가중치와 편향 매개변수가 딕셔너리 변수로 저장되어 있다.\n",
    "- 이제 이 세 함수를 이용해 신경망에 의한 추론을 수행해보고, 정확도(분류가 얼마나 올바른가)도 평가해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f25954-226d-4127-868a-2462e7c17b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534bd79-d386-4624-8a28-c487a5dba4e0",
   "metadata": {},
   "source": [
    "- 또한 이 예에서는 load_mnist 함수의 인수인 normalize를 True로 설정했다. 이처럼 데이터를 특정 범위로 변환하는 처리를 정규화라 하고, 신경망의 입력 데이터에 특정 변환을 가하는 것을 전처리라 한다. 여기에서는 입력 이미지 데이터에 대한 전처리 작업으로 정규화를 수행한 셈이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3ef84-0255-42ea-9f8f-c86d4b8ef5b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ba4f5-54fd-49f4-bc5a-08f78eddd46b",
   "metadata": {},
   "source": [
    "- 배치처리 \n",
    "  - 입력 데이터와 가중치 매개변수의 형상에 주의하여 조금 전 구현을 다시 살펴보자\n",
    "  - 우선 앞서 구현한 신경망 각 층의 가중치 형상을 출력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e651d7d2-0178-470c-ac29-c47ee88a4573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(784,)\n",
      "(784, 50)\n",
      "(50, 100)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "x,_ = get_data()\n",
    "network = init_network()\n",
    "W1,W2,W3 = network['W1'], network['W2'], network['W3']\n",
    "\n",
    "print(x.shape)\n",
    "print(x[0].shape)\n",
    "print(W1.shape) #1\n",
    "print(W2.shape) #2\n",
    "print(W3.shape) #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489cf232-3284-4240-b1ce-84f87d5a24a7",
   "metadata": {},
   "source": [
    "- 이 결과에서 다차원 배열의 대응하는 차원의 수가 일치함을 확인할 수 있다. \n",
    "  - (교재 102p를 참고해보자)\n",
    "- 이는 이미지 데이터 1장만 입력했을 때의 데이터 처리 흐름이다. \n",
    "  - 그렇다면 이미지 여러 장을 한 번에 입력하는 경우를 생각해보자\n",
    "    - 가령 이미지 100개를 묶어 predict() 함수에 한 번에 넘기는 경우가 있다고 해보자. \n",
    "    - x의 형상을 100x784fh qkRNjtj 100장 분량의 데이터를 하나의 입력 데이터로 표현하면 될 것이다. \n",
    "    - 이때 입력 데이터의 형상은 100x784, 출력 데이터의 형상은 100x10이 된다.\n",
    "    - 이는 100장 분량의 입력 데이터의 결과가 한 번에 출력됨을 나타낸다. \n",
    "    - 가령 x[0]과 y[0]에는 0번째 이미지와 그 추론 결과가 저장되는 식이다.\n",
    "    - 이처럼 하나로 묶은 입력 데이터를 배치(batch)라고 한다. 즉, 묶음을 의미하며 이미지가 지폐처럼 다발로 묶여 있다고 생각하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ee30f-b721-4004-bd73-ccc470f4d0a7",
   "metadata": {},
   "source": [
    "- 배치 처리를 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb3e85fd-5e18-4ea8-b0d7-98d1d183e66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1) # 100x10이라는 다차원에서 0번째 차원말고 1번째 차원에 접근하겠다. #??????????????\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006fe21-d962-4f85-adff-1a9accf29745",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bdd8d59-a5eb-49b1-940c-e851297f0e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "#??????????????????의 부연설명\n",
    "x = np.array([[3,2,1],[4,5,6]])\n",
    "y = np.argmax(x,axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1e868-4fcd-4024-aa7c-c2482d00b0d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02da5ad-e56a-4bac-a232-d4db4c232b3d",
   "metadata": {},
   "source": [
    "- 마지막으로 배치 단위로 분류한 결과를 실제 답과 비교한다. 이를 위해 ==연사자를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cf8aff3-5757-41f4-b806-e79d2c2cd1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1,2,1,0])\n",
    "t = np.array([1,2,0,0])\n",
    "print(y==t)\n",
    "np.sum(y==t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b746802-3673-4be2-b5a2-531feebd3fcc",
   "metadata": {},
   "source": [
    "- 이런 식으로 구현하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010255d5-299e-4e82-bf76-778722a53a9a",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa870d-e303-4c32-99fc-a8f4603b412e",
   "metadata": {},
   "source": [
    "> ### Conclusion\n",
    "      \n",
    "      이번 장에서는 신경망의 순전파를 살펴봤다. 이번 장에서 설명한 신경망은 각 층의 뉴런들이 다음 층의 뉴런으로 신호를 전달한다는 점에서 앞 장의 퍼셉트론과 같다. 하지만 다름 뉴런으로 갈 때, 신호를 변화시키는 활성화 함수에 큰 차이가 있었다. 신경망에서는 매끄럽게 변화하는 시그모이드 함수를, 퍼셉트론에서는 갑자기 변화하는 계단 함수를 활성화 함수로 사용했다. 이 차이가 신경망 학습에 중요하다. 다음 장에서 더욱 알아보도록 하자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
